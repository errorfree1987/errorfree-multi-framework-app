import os, json, datetime, secrets
from pathlib import Path
from typing import Dict, List
from io import BytesIO
import base64

import streamlit as st
import pdfplumber
from docx import Document
from openai import OpenAI
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase.cidfonts import UnicodeCIDFont


PDF_FONT_NAME = "Helvetica"
PDF_FONT_REGISTERED = False
PDF_TTF_PATH = os.getenv("PDF_TTF_PATH")  # Optional: path to a Unicode TTF font for PDF export


def ensure_pdf_font():
    """Register a Unicode-capable font for PDF export to avoid black boxes / garbled text."""
    global PDF_FONT_NAME, PDF_FONT_REGISTERED
    if PDF_FONT_REGISTERED:
        return

    try:
        try:
            pdfmetrics.registerFont(UnicodeCIDFont("STSong-Light"))
            PDF_FONT_NAME = "STSong-Light"
        except Exception:
            if PDF_TTF_PATH and Path(PDF_TTF_PATH).exists():
                pdfmetrics.registerFont(TTFont("ErrorFreeUnicode", PDF_TTF_PATH))
                PDF_FONT_NAME = "ErrorFreeUnicode"
            else:
                PDF_FONT_NAME = "Helvetica"
    except Exception:
        PDF_FONT_NAME = "Helvetica"
    finally:
        PDF_FONT_REGISTERED = True


# =========================
# Company multi-tenant support
# =========================

COMPANY_FILE = Path("companies.json")


def load_companies() -> dict:
    if not COMPANY_FILE.exists():
        return {}
    try:
        return json.loads(COMPANY_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


def save_companies(data: dict):
    try:
        COMPANY_FILE.write_text(
            json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8"
        )
    except Exception:
        pass


# =========================
# Accounts
# =========================

ACCOUNTS = {
    "admin@errorfree.com": {"password": "1111", "role": "admin"},
    "dr.chiu@errorfree.com": {"password": "2222", "role": "pro"},
    "test@errorfree.com": {"password": "3333", "role": "pro"},
}

GUEST_FILE = Path("guest_accounts.json")


def load_guest_accounts() -> Dict[str, Dict]:
    if not GUEST_FILE.exists():
        return {}
    try:
        return json.loads(GUEST_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


def save_guest_accounts(data: Dict[str, Dict]):
    try:
        GUEST_FILE.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
    except Exception:
        pass


# =========================
# Framework definitions (external JSON)
# =========================

FRAMEWORK_FILE = Path("frameworks.json")


def load_frameworks() -> Dict[str, Dict]:
    """Load framework definitions from an external JSON file."""
    if not FRAMEWORK_FILE.exists():
        return {}
    try:
        return json.loads(FRAMEWORK_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


FRAMEWORKS: Dict[str, Dict] = load_frameworks()

# =========================
# State persistence & usage tracking (4A)
# =========================

STATE_FILE = Path("user_state.json")
DOC_TRACK_FILE = Path("user_docs.json")
USAGE_FILE = Path("usage_stats.json")  # ä½¿ç”¨é‡çµ±è¨ˆ


def load_doc_tracking() -> Dict[str, List[str]]:
    if not DOC_TRACK_FILE.exists():
        return {}
    try:
        return json.loads(DOC_TRACK_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


def save_doc_tracking(data: Dict[str, List[str]]):
    try:
        DOC_TRACK_FILE.write_text(
            json.dumps(data, ensure_ascii=False), encoding="utf-8"
        )
    except Exception:
        pass


def load_usage_stats() -> Dict[str, Dict]:
    if not USAGE_FILE.exists():
        return {}
    try:
        return json.loads(USAGE_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


def save_usage_stats(data: Dict[str, Dict]):
    try:
        USAGE_FILE.write_text(
            json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8"
        )
    except Exception:
        pass


def record_usage(user_email: str, framework_key: str, kind: str):
    """
    kind: 'analysis', 'followup', 'download'
    """
    if not user_email:
        return
    data = load_usage_stats()
    user_entry = data.get(user_email, {})
    fw_map = user_entry.get("frameworks", {})
    fw_entry = fw_map.get(
        framework_key,
        {
            "analysis_runs": 0,
            "followups": 0,
            "downloads": 0,
        },
    )
    if kind == "analysis":
        fw_entry["analysis_runs"] = fw_entry.get("analysis_runs", 0) + 1
    elif kind == "followup":
        fw_entry["followups"] = fw_entry.get("followups", 0) + 1
    elif kind == "download":
        fw_entry["downloads"] = fw_entry.get("downloads", 0) + 1

    fw_map[framework_key] = fw_entry
    user_entry["frameworks"] = fw_map
    user_entry["last_used"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    data[user_email] = user_entry
    save_usage_stats(data)


def save_state_to_disk():
    data = {
        "user_email": st.session_state.get("user_email"),
        "user_role": st.session_state.get("user_role"),
        "is_authenticated": st.session_state.get("is_authenticated", False),
        "lang": st.session_state.get("lang", "zh"),
        "zh_variant": st.session_state.get("zh_variant", "tw"),
        "usage_date": st.session_state.get("usage_date"),
        "usage_count": st.session_state.get("usage_count", 0),
        "last_doc_text": st.session_state.get("last_doc_text", ""),
        "last_doc_name": st.session_state.get("last_doc_name", ""),
        "document_type": st.session_state.get("document_type"),
        "reference_history": st.session_state.get("reference_history", []),
        "ref_pending": st.session_state.get("ref_pending", False),
        "framework_states": st.session_state.get("framework_states", {}),
        "selected_framework_key": st.session_state.get("selected_framework_key"),
        "current_doc_id": st.session_state.get("current_doc_id"),
        "company_code": st.session_state.get("company_code"),
        "show_admin": st.session_state.get("show_admin", False),
    }
    try:
        STATE_FILE.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
    except Exception:
        pass


def restore_state_from_disk():
    if not STATE_FILE.exists():
        return
    try:
        data = json.loads(STATE_FILE.read_text(encoding="utf-8"))
    except Exception:
        return
    for k, v in data.items():
        if k not in st.session_state:
            st.session_state[k] = v


# =========================
# OpenAI client & model selection
# =========================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None


def resolve_model_for_user(role: str) -> str:
    if role in ["admin", "pro"]:
        return "gpt-5.1"
    if role == "free":
        return "gpt-4.1-mini"
    return "gpt-5.1"


# =========================
# Language helpers (ç°¡é«” / ç¹é«”)
# =========================

def zh(tw: str, cn: str = None) -> str:
    """Return zh text by variant when lang == 'zh'. Default variant is 'tw'."""
    if st.session_state.get("lang") != "zh":
        return tw
    if st.session_state.get("zh_variant", "tw") == "cn" and cn is not None:
        return cn
    return tw


# =========================
# File reading
# =========================

def ocr_image_to_text(file_bytes: bytes, filename: str) -> str:
    """Use OpenAI vision model to perform OCR on an image and return plain text."""
    if client is None:
        return "[Error] OPENAI_API_KEY å°šæœªè¨­å®šï¼Œç„¡æ³•é€²è¡Œåœ–ç‰‡ OCRã€‚"

    fname = filename.lower()
    img_format = "png" if fname.endswith(".png") else "jpeg"

    role = st.session_state.get("user_role", "free")
    model_name = resolve_model_for_user(role)

    b64_data = base64.b64encode(file_bytes).decode("utf-8")

    lang = st.session_state.get("lang", "zh")
    if lang == "zh":
        prompt = (
            "è«‹å°‡é€™å¼µåœ–ç‰‡ä¸­çš„æ‰€æœ‰å¯è¦‹æ–‡å­—å®Œæ•´è½‰æˆç´”æ–‡å­—ï¼Œ"
            "ä¿æŒåŸæœ¬çš„æ®µè½èˆ‡æ›è¡Œã€‚ä¸è¦åŠ ä¸Šä»»ä½•èªªæ˜æˆ–ç¸½çµï¼Œåªè¼¸å‡ºæ–‡å­—å…§å®¹ã€‚"
        )
    else:
        prompt = (
            "Transcribe all visible text in this image into plain text. "
            "Preserve paragraphs and line breaks. Do not add any commentary or summary."
        )

    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": prompt},
                        {
                            "type": "input_image",
                            "image": {"data": b64_data, "format": img_format},
                        },
                    ],
                }
            ],
            max_output_tokens=2000,
        )
        text = response.output_text or ""
        return text.strip()
    except Exception as e:
        return f"[åœ–ç‰‡ OCR æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}]"


def read_file_to_text(uploaded_file) -> str:
    if uploaded_file is None:
        return ""
    name = uploaded_file.name.lower()
    try:
        if name.endswith(".pdf"):
            text_pages: List[str] = []
            with pdfplumber.open(uploaded_file) as pdf:
                for page in pdf.pages:
                    t = page.extract_text() or ""
                    text_pages.append(t)
            return "\n".join(text_pages)
        elif name.endswith(".docx"):
            doc = Document(uploaded_file)
            return "\n".join(p.text for p in doc.paragraphs)
        elif name.endswith(".txt"):
            return uploaded_file.read().decode("utf-8", errors="ignore")
        elif name.endswith((".jpg", ".jpeg", ".png")):
            file_bytes = uploaded_file.read()
            if not file_bytes:
                return "[è®€å–åœ–ç‰‡æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼šç©ºæª”æ¡ˆ]"
            return ocr_image_to_text(file_bytes, uploaded_file.name)
        else:
            return ""
    except Exception as e:
        return f"[è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}]"


# =========================
# Core LLM logic (keep wrapper as-is)
# =========================

def run_llm_analysis(framework_key: str, language: str, document_text: str, model_name: str) -> str:
    if framework_key not in FRAMEWORKS:
        return f"[Error] Framework '{framework_key}' not found in frameworks.json."

    fw = FRAMEWORKS[framework_key]
    system_prompt = fw["wrapper_zh"] if language == "zh" else fw["wrapper_en"]
    prefix = "ä»¥ä¸‹æ˜¯è¦åˆ†æçš„æ–‡ä»¶å…§å®¹ï¼š\n\n" if language == "zh" else "Here is the document to analyze:\n\n"
    user_prompt = prefix + (document_text or "")

    if client is None:
        return "[Error] OPENAI_API_KEY å°šæœªè¨­å®šï¼Œç„¡æ³•é€£ç·šè‡³ OpenAIã€‚"

    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_output_tokens=2500,
        )
        return response.output_text
    except Exception as e:
        return f"[å‘¼å« OpenAI API æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}]"


def _openai_simple(system_prompt: str, user_prompt: str, model_name: str, max_output_tokens: int) -> str:
    if client is None:
        return "[Error] OPENAI_API_KEY å°šæœªè¨­å®šï¼Œç„¡æ³•é€£ç·šè‡³ OpenAIã€‚"
    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_output_tokens=max_output_tokens,
        )
        return (response.output_text or "").strip()
    except Exception as e:
        return f"[å‘¼å« OpenAI API æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}]"


def _chunk_text(text: str, chunk_size: int = 12000, overlap: int = 600) -> List[str]:
    """Used ONLY for reference summarization to control token size."""
    if not text:
        return []
    text = text.replace("\r\n", "\n").replace("\r", "\n").strip()
    n = len(text)
    chunks = []
    start = 0
    while start < n:
        end = min(n, start + chunk_size)
        chunks.append(text[start:end])
        if end >= n:
            break
        start = max(0, end - overlap)
    return chunks


def summarize_reference_text(language: str, ref_name: str, ref_text: str, model_name: str) -> str:
    """Compress reference doc into a faithful structured summary (not framework analysis)."""
    chunks = _chunk_text(ref_text, chunk_size=12000, overlap=600)
    if not chunks:
        return ""

    if language == "zh":
        sys = "ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„æ–‡ä»¶æ‘˜è¦åŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯å¿ å¯¦å£“ç¸®å…§å®¹ï¼Œä¸è¦ç™¼æ˜ä¸å­˜åœ¨çš„è³‡è¨Šã€‚"
        def one_chunk_prompt(i: int, total: int, c: str) -> str:
            return (
                f"è«‹å°‡ä»¥ä¸‹åƒè€ƒæ–‡ä»¶å…§å®¹åšæ‘˜è¦ï¼ˆç¬¬ {i}/{total} æ®µï¼‰ï¼Œä¿ç•™ï¼š\n"
                "1) é‡è¦å®šç¾©/ç¯„åœ\n2) é—œéµè¦æ±‚/é™åˆ¶/æ•¸å€¼\n3) ä»»ä½•ä¾‹å¤–/å‰æ\n4) å¯èƒ½å½±éŸ¿åˆ¤æ–·çš„æ¢æ¬¾\n\n"
                f"ã€åƒè€ƒæ–‡ä»¶ã€‘{ref_name}\nã€å…§å®¹ã€‘\n{c}"
            )
        reduce_sys = "ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„æ‘˜è¦æ•´åˆåŠ©æ‰‹ã€‚è«‹åˆä½µå¤šæ®µæ‘˜è¦ï¼Œå»é‡ä½†ä¸æ¼æ‰é—œéµè¦æ±‚èˆ‡é™åˆ¶ã€‚"
        def reduce_prompt(t: str) -> str:
            return (
                "è«‹æŠŠä»¥ä¸‹å¤šæ®µæ‘˜è¦æ•´åˆç‚ºä¸€ä»½ã€åƒè€ƒæ–‡ä»¶ç¸½æ‘˜è¦ã€ï¼Œçµæ§‹åŒ–è¼¸å‡ºï¼š\n"
                "A. å®šç¾©/ç¯„åœ\nB. ä¸»è¦è¦æ±‚/é™åˆ¶\nC. ä¾‹å¤–/å‰æ\nD. å¯èƒ½å½±éŸ¿åˆ¤æ–·çš„æ¢æ¬¾\n\n"
                f"ã€åƒè€ƒæ–‡ä»¶ã€‘{ref_name}\nã€å¤šæ®µæ‘˜è¦ã€‘\n{t}"
            )
    else:
        sys = "You are a careful document summarization assistant. Summarize faithfully and do not hallucinate."
        def one_chunk_prompt(i: int, total: int, c: str) -> str:
            return (
                f"Summarize the following reference document chunk ({i}/{total}). Preserve:\n"
                "1) definitions/scope\n2) key requirements/constraints/values\n3) exceptions/prereqs\n4) clauses that affect decisions\n\n"
                f"[Reference] {ref_name}\n[Content]\n{c}"
            )
        reduce_sys = "You consolidate summaries. Merge, dedupe, keep key constraints."
        def reduce_prompt(t: str) -> str:
            return (
                "Consolidate chunk summaries into ONE reference master summary with sections:\n"
                "A. Definitions/Scope\nB. Requirements/Constraints\nC. Exceptions/Prereqs\nD. Decision-impacting clauses\n\n"
                f"[Reference] {ref_name}\n[Chunk summaries]\n{t}"
            )

    partials = []
    total = len(chunks)
    for i, c in enumerate(chunks, start=1):
        partials.append(_openai_simple(sys, one_chunk_prompt(i, total, c), model_name, max_output_tokens=900))

    current = partials[:]
    while len(current) > 1:
        nxt = []
        batch_size = 8
        for i in range(0, len(current), batch_size):
            joined = "\n\n---\n\n".join(current[i:i + batch_size])
            nxt.append(_openai_simple(reduce_sys, reduce_prompt(joined), model_name, max_output_tokens=1100))
        current = nxt

    return current[0].strip()


def build_relevance_file(language: str, framework_key: str, document_type: str, main_analysis: str, ref_summaries: List[Dict]) -> str:
    """Create a system-generated comparison file: main analysis vs reference summaries."""
    fw = FRAMEWORKS.get(framework_key, {})
    fw_name = fw.get("name_zh", framework_key) if language == "zh" else fw.get("name_en", framework_key)

    if language == "zh":
        lines = [
            "ã€ç›¸é—œæ€§å°ç…§æ–‡ä»¶ï¼ˆç”±ç³»çµ±ç”Ÿæˆï¼Œç”¨æ–¼å¾ŒçºŒç›¸é—œæ€§åˆ†æï¼‰ã€‘",
            f"- æ–‡ä»¶é¡å‹ï¼š{document_type or 'ï¼ˆæœªé¸æ“‡ï¼‰'}",
            f"- åˆ†ææ¡†æ¶ï¼š{fw_name}",
            "",
            "==============================",
            "ä¸€ã€ä¸»æ–‡ä»¶åˆ†æçµæœï¼ˆè¦é»ï¼Œç”¨æ–¼å°ç…§ï¼‰",
            "==============================",
            main_analysis or "",
            "",
            "==============================",
            "äºŒã€åƒè€ƒæ–‡ä»¶æ‘˜è¦ï¼ˆç”¨æ–¼å°ç…§ï¼‰",
            "==============================",
        ]
        for i, r in enumerate(ref_summaries, start=1):
            lines.append(f"\n--- åƒè€ƒæ–‡ä»¶ {i}: {r.get('name','(unknown)')} ---\n")
            lines.append(r.get("summary", "") or "")
        return "\n".join(lines)
    else:
        lines = [
            "[Relevance Comparison File (system-generated)]",
            f"- Document Type: {document_type or '(not selected)'}",
            f"- Framework: {fw_name}",
            "",
            "==============================",
            "1) Main analysis (for comparison)",
            "==============================",
            main_analysis or "",
            "",
            "==============================",
            "2) Reference summaries (for comparison)",
            "==============================",
        ]
        for i, r in enumerate(ref_summaries, start=1):
            lines.append(f"\n--- Reference {i}: {r.get('name','(unknown)')} ---\n")
            lines.append(r.get("summary", "") or "")
        return "\n".join(lines)


def derive_relevance_points(language: str, relevance_file_text: str, model_name: str) -> str:
    """Extract compact relevance focus points (fast, token-efficient)."""
    if language == "zh":
        sys = "ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„å°ç…§åŠ©æ‰‹ã€‚è«‹æ‰¾å‡ºä¸»æ–‡ä»¶åˆ†æçµæœèˆ‡åƒè€ƒæ–‡ä»¶ä¹‹é–“ã€çœŸæ­£éœ€è¦å°ç…§ã€çš„é»ã€‚ä¸å¾—æœæ’°ã€‚"
        user = (
            "è«‹å¾ä»¥ä¸‹ã€ç›¸é—œæ€§å°ç…§æ–‡ä»¶ã€ä¸­æŠ½å–ï¼š\n"
            "1) æ”¯æŒä¸»æ–‡ä»¶çµè«–çš„åƒè€ƒä¾æ“šï¼ˆé€æ¢ï¼‰\n"
            "2) èˆ‡ä¸»æ–‡ä»¶çµè«–è¡çª/ä¸ä¸€è‡´çš„åƒè€ƒä¾æ“šï¼ˆé€æ¢ï¼‰\n"
            "3) ä¸»æ–‡ä»¶å¯èƒ½éºæ¼ã€ä½†åƒè€ƒæ–‡ä»¶æåˆ°çš„é‡è¦è¦æ±‚/é™åˆ¶ï¼ˆé€æ¢ï¼‰\n"
            "4) éœ€è¦æ¾„æ¸…çš„é—œéµå•é¡Œï¼ˆé€æ¢ï¼‰\n\n"
            "è¼¸å‡ºè«‹ç”¨ Markdownï¼Œä¸¦åœ¨æ¯æ¢å¾Œé¢æ¨™è¨»å°æ‡‰çš„åƒè€ƒæ–‡ä»¶åç¨±ã€‚\n\n"
            f"{relevance_file_text}"
        )
    else:
        sys = "You are a careful comparison assistant. Identify only what truly needs comparison. No hallucinations."
        user = (
            "From the following relevance comparison file, extract:\n"
            "1) reference support for the main conclusions\n"
            "2) contradictions/inconsistencies\n"
            "3) important requirements present in references but missing in main\n"
            "4) clarification questions\n\n"
            "Output in Markdown. Each bullet must cite which reference name it came from.\n\n"
            f"{relevance_file_text}"
        )
    return _openai_simple(sys, user, model_name, max_output_tokens=1600)


def build_final_integration_input(language: str, document_type: str, framework_key: str, main_analysis: str, relevance_points: str) -> str:
    """Step 7 input: integrate Step 5 + Step 6, then produce final consolidated result under the SAME framework."""
    fw = FRAMEWORKS.get(framework_key, {})
    fw_name = fw.get("name_zh", framework_key) if language == "zh" else fw.get("name_en", framework_key)

    if language == "zh":
        return "\n".join(
            [
                "ã€æœ€çµ‚æ•´åˆåˆ†æè¼¸å…¥ï¼ˆæ­¥é©Ÿä¸ƒï¼‰ã€‘",
                f"- æ–‡ä»¶é¡å‹ï¼š{document_type or 'ï¼ˆæœªé¸æ“‡ï¼‰'}",
                f"- åˆ†ææ¡†æ¶ï¼š{fw_name}",
                "",
                "==============================",
                "ä¸€ã€æ­¥é©Ÿäº”ï¼šä¸»æ–‡ä»¶é›¶éŒ¯èª¤æ¡†æ¶åˆ†æçµæœ",
                "==============================",
                main_analysis or "",
                "",
                "==============================",
                "äºŒã€æ­¥é©Ÿå…­ï¼šåƒè€ƒæ–‡ä»¶ç›¸é—œæ€§åˆ†æé‡é»",
                "==============================",
                relevance_points or "",
                "",
                "ã€ä»»å‹™ã€‘",
                "è«‹ä½ ç”¨åŒä¸€å€‹é›¶éŒ¯èª¤æ¡†æ¶ï¼Œæ•´åˆä¸Šè¿°å…©ä»½å…§å®¹ï¼Œè¼¸å‡ºã€æœ€çµ‚æˆå“åˆ†æå ±å‘Šã€ã€‚",
                "è¦æ±‚ï¼š",
                "1) ä¸è¦åªæ˜¯æŠŠå…©ä»½å…§å®¹è²¼åœ¨ä¸€èµ·ï¼›è¦åšæ•´åˆã€å»é‡ã€è£œå¼·ã€‚",
                "2) å¿…é ˆæ˜ç¢ºæŒ‡å‡ºï¼šå“ªäº›çµè«–è¢«åƒè€ƒæ–‡ä»¶æ”¯æŒã€å“ªäº›å­˜åœ¨è¡çªã€å“ªäº›æ˜¯ä¸»æ–‡ä»¶éºæ¼ä½†åƒè€ƒæ–‡ä»¶è¦æ±‚çš„é …ç›®ã€‚",
                "3) ç”¢å‡ºå¯åŸ·è¡Œçš„ä¿®æ­£/è£œä»¶/æ¾„æ¸…å•é¡Œæ¸…å–®ã€‚",
            ]
        )
    else:
        return "\n".join(
            [
                "[Final Integration Input (Step 7)]",
                f"- Document type: {document_type or '(not selected)'}",
                f"- Framework: {fw_name}",
                "",
                "==============================",
                "1) Step 5: Main document framework analysis",
                "==============================",
                main_analysis or "",
                "",
                "==============================",
                "2) Step 6: Reference relevance key points",
                "==============================",
                relevance_points or "",
                "",
                "[Task]",
                "Using the same framework, integrate the above into a FINAL consolidated report:",
                "1) Integrate and dedupe; do not merely concatenate.",
                "2) Clearly state what is supported by references, what conflicts, and what is missing in main but required by references.",
                "3) Provide actionable fixes / addenda / clarification questions.",
            ]
        )


# =========================
# Follow-up Q&A
# =========================

def run_followup_qa(
    framework_key: str,
    language: str,
    document_text: str,
    analysis_output: str,
    user_question: str,
    model_name: str,
    extra_text: str = "",
) -> str:
    if framework_key not in FRAMEWORKS:
        return f"[Error] Framework '{framework_key}' not found in frameworks.json."

    fw = FRAMEWORKS[framework_key]

    if language == "zh":
        system_prompt = (
            "You are an Error-Free consultant familiar with framework: "
            + fw["name_zh"]
            + ". You already produced a full analysis. Now answer follow-up "
            "questions based on the original document and previous analysis. "
            "Focus on extra insights, avoid repeating the full report."
        )
    else:
        system_prompt = (
            "You are an Error-Free consultant for framework: "
            + fw["name_en"]
            + ". You already produced a full analysis. Answer follow-up "
            "questions based on document + previous analysis, without "
            "recreating the full report."
        )

    doc_excerpt = (document_text or "")[:8000]
    analysis_excerpt = (analysis_output or "")[:8000]
    extra_excerpt = extra_text[:4000] if extra_text else ""

    blocks = [
        "Original document excerpt:\n" + doc_excerpt,
        "Previous analysis excerpt:\n" + analysis_excerpt,
        "User question:\n" + user_question,
    ]
    if extra_excerpt:
        blocks.append("Extra reference:\n" + extra_excerpt)

    user_content = "\n\n".join(blocks)

    if client is None:
        return "[Error] OPENAI_API_KEY å°šæœªè¨­å®šã€‚"

    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content},
            ],
            max_output_tokens=2000,
        )
        return response.output_text
    except Exception as e:
        return f"[å‘¼å« OpenAI API æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}]"


# =========================
# Report formatting / exports
# =========================

def clean_report_text(text: str) -> str:
    replacements = {"â– ": "-", "â€¢": "-", "â€“": "-", "â€”": "-"}
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text


def build_full_report(lang: str, framework_key: str, state: Dict) -> str:
    analysis_output = state.get("analysis_output", "")
    followups = state.get("followup_history", [])
    fw = FRAMEWORKS.get(framework_key, {})
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    email = st.session_state.get("user_email", "unknown")

    name_zh = fw.get("name_zh", framework_key)
    name_en = fw.get("name_en", framework_key)

    if lang == "zh":
        header = [
            f"{BRAND_TITLE_ZH} å ±å‘Šï¼ˆåˆ†æ + Q&Aï¼‰",
            f"{BRAND_SUBTITLE_ZH}",
            f"ç”¢ç”Ÿæ™‚é–“ï¼š{now}",
            f"ä½¿ç”¨è€…å¸³è™Ÿï¼š{email}",
            f"ä½¿ç”¨æ¡†æ¶ï¼š{name_zh}",
            "",
            "==============================",
            "ä¸€ã€åˆ†æçµæœ",
            "==============================",
            analysis_output,
        ]
        if followups:
            header += [
                "",
                "==============================",
                "äºŒã€å¾ŒçºŒå•ç­”ï¼ˆQ&Aï¼‰",
                "==============================",
            ]
            for i, (q, a) in enumerate(followups, start=1):
                header.append(f"[Q{i}] {q}")
                header.append(f"[A{i}] {a}")
                header.append("")
    else:
        header = [
            f"{BRAND_TITLE_EN} Report (Analysis + Q&A)",
            f"{BRAND_SUBTITLE_EN}",
            f"Generated: {now}",
            f"User: {email}",
            f"Framework: {name_en}",
            "",
            "==============================",
            "1. Analysis",
            "==============================",
            analysis_output,
        ]
        if followups:
            header += [
                "",
                "==============================",
                "2. Follow-up Q&A",
                "==============================",
            ]
            for i, (q, a) in enumerate(followups, start=1):
                header.append(f"[Q{i}] {q}")
                header.append(f"[A{i}] {a}")
                header.append("")

    return clean_report_text("\n".join(header))


def build_whole_report(lang: str, framework_states: Dict[str, Dict]) -> str:
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    email = st.session_state.get("user_email", "unknown")

    lines: List[str] = []
    if lang == "zh":
        lines.extend(
            [
                f"{BRAND_TITLE_ZH} ç¸½å ±å‘Šï¼ˆå…¨éƒ¨æ¡†æ¶ï¼‰",
                f"{BRAND_SUBTITLE_ZH}",
                f"ç”¢ç”Ÿæ™‚é–“ï¼š{now}",
                f"ä½¿ç”¨è€…å¸³è™Ÿï¼š{email}",
                "",
                "==============================",
            ]
        )
    else:
        lines.extend(
            [
                f"{BRAND_TITLE_EN} Consolidated Report (All frameworks)",
                f"{BRAND_SUBTITLE_EN}",
                f"Generated: {now}",
                f"User: {email}",
                "",
                "==============================",
            ]
        )

    for fw_key in FRAMEWORKS.keys():
        state = framework_states.get(fw_key)
        if not state or not state.get("analysis_output"):
            continue

        fw = FRAMEWORKS.get(fw_key, {})
        name_zh = fw.get("name_zh", fw_key)
        name_en = fw.get("name_en", fw_key)

        if lang == "zh":
            lines.append(f"â— æ¡†æ¶ï¼š{name_zh}")
            lines.append("------------------------------")
            lines.append("ä¸€ã€åˆ†æçµæœ")
        else:
            lines.append(f"â— Framework: {name_en}")
            lines.append("------------------------------")
            lines.append("1. Analysis")

        lines.append(state.get("analysis_output", ""))

        followups = state.get("followup_history", [])
        if followups:
            if lang == "zh":
                lines.append("")
                lines.append("äºŒã€å¾ŒçºŒå•ç­”ï¼ˆQ&Aï¼‰")
            else:
                lines.append("")
                lines.append("2. Follow-up Q&A")

            for i, (q, a) in enumerate(followups, start=1):
                lines.append(f"[Q{i}] {q}")
                lines.append(f"[A{i}] {a}")
                lines.append("")

        lines.append("")
        lines.append("================================")
        lines.append("")

    if not lines:
        return ""

    return clean_report_text("\n".join(lines))


def build_docx_bytes(text: str) -> bytes:
    doc = Document()
    for line in text.split("\n"):
        doc.add_paragraph(line)
    buf = BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.getvalue()


def build_pdf_bytes(text: str) -> bytes:
    buf = BytesIO()
    ensure_pdf_font()
    c = canvas.Canvas(buf, pagesize=letter)
    width, height = letter

    margin_x = 40
    margin_y = 40
    line_height = 14
    max_width = width - 2 * margin_x

    try:
        c.setFont(PDF_FONT_NAME, 11)
    except Exception:
        c.setFont("Helvetica", 11)

    y = height - margin_y

    for raw_line in text.split("\n"):
        safe_line = raw_line.replace("\t", "    ")
        if not safe_line:
            y -= line_height
            if y < margin_y:
                c.showPage()
                try:
                    c.setFont(PDF_FONT_NAME, 11)
                except Exception:
                    c.setFont("Helvetica", 11)
                y = height - margin_y
            continue

        line = safe_line
        while line:
            try:
                if pdfmetrics.stringWidth(line, PDF_FONT_NAME, 11) <= max_width:
                    segment = line
                    line = ""
                else:
                    cut = len(line)
                    while (
                        cut > 0
                        and pdfmetrics.stringWidth(line[:cut], PDF_FONT_NAME, 11) > max_width
                    ):
                        cut -= 1
                    space_pos = line.rfind(" ", 0, cut)
                    if space_pos > 0:
                        cut = space_pos
                    segment = line[:cut].rstrip()
                    line = line[cut:].lstrip()
            except Exception:
                segment = line[:120]
                line = line[120:]

            c.drawString(margin_x, y, segment)
            y -= line_height
            if y < margin_y:
                c.showPage()
                try:
                    c.setFont(PDF_FONT_NAME, 11)
                except Exception:
                    c.setFont("Helvetica", 11)
                y = height - margin_y

    c.save()
    buf.seek(0)
    return buf.getvalue()


def build_pptx_bytes(text: str) -> bytes:
    try:
        from pptx import Presentation
    except Exception:
        return build_docx_bytes("404: Not Found")

    prs = Presentation()
    title_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_layout)
    if slide.shapes.title is not None:
        slide.shapes.title.text = "404: Not Found"
    if len(slide.placeholders) > 1:
        try:
            slide.placeholders[1].text = "PPTX export is not available in this version."
        except Exception:
            pass

    buf = BytesIO()
    prs.save(buf)
    buf.seek(0)
    return buf.getvalue()


# =========================
# Dashboards (unchanged)
# =========================

def company_admin_dashboard():
    companies = load_companies()
    code = st.session_state.get("company_code")
    email = st.session_state.get("user_email")

    if not code or code not in companies:
        lang = st.session_state.get("lang", "zh")
        st.error(zh("æ‰¾ä¸åˆ°å…¬å¸ä»£ç¢¼ï¼Œè«‹è¯çµ¡ç³»çµ±ç®¡ç†å“¡", "æ‰¾ä¸åˆ°å…¬å¸ä»£ç ï¼Œè¯·è”ç³»ç³»ç»Ÿç®¡ç†å‘˜") if lang == "zh" else "Company code not found. Please contact system admin.")
        return

    entry = companies[code]
    admins = entry.get("admins", [])
    if email not in admins:
        lang = st.session_state.get("lang", "zh")
        st.error(zh("æ‚¨æ²’æœ‰æ­¤å…¬å¸çš„ç®¡ç†è€…æ¬Šé™", "æ‚¨æ²¡æœ‰æ­¤å…¬å¸çš„ç®¡ç†è€…æƒé™") if lang == "zh" else "You are not an admin for this company.")
        return

    lang = st.session_state.get("lang", "zh")
    company_name = entry.get("company_name") or code
    content_access = entry.get("content_access", False)

    st.title((zh(f"å…¬å¸ç®¡ç†å¾Œå° - {company_name}", f"å…¬å¸ç®¡ç†åå° - {company_name}") if lang == "zh" else f"Company Admin Dashboard - {company_name}"))
    st.markdown("---")

    st.subheader(zh("å…¬å¸è³‡è¨Š", "å…¬å¸ä¿¡æ¯") if lang == "zh" else "Company Info")
    st.write((zh("å…¬å¸ä»£ç¢¼ï¼š", "å…¬å¸ä»£ç ï¼š") if lang == "zh" else "Company Code: ") + code)
    if lang == "zh":
        st.write(zh("å¯æŸ¥çœ‹å…§å®¹ï¼š", "å¯æŸ¥çœ‹å†…å®¹ï¼š") + (zh("æ˜¯", "æ˜¯") if content_access else zh("å¦", "å¦")))
    else:
        st.write("Can view content: " + ("Yes" if content_access else "No"))

    st.markdown("---")
    st.subheader(zh("å­¸ç”Ÿ / ä½¿ç”¨è€…åˆ—è¡¨", "å­¦å‘˜ / ç”¨æˆ·åˆ—è¡¨") if lang == "zh" else "Users in this company")

    users = entry.get("users", [])
    doc_tracking = load_doc_tracking()
    usage_stats = load_usage_stats()

    if not users:
        st.info(zh("ç›®å‰å°šæœªæœ‰ä»»ä½•å­¸ç”Ÿè¨»å†Š", "ç›®å‰å°šæœªæœ‰ä»»ä½•å­¦å‘˜æ³¨å†Œ") if lang == "zh" else "No users registered for this company yet.")
    else:
        for u in users:
            docs = doc_tracking.get(u, [])
            st.markdown(f"**{u}**")
            st.write((zh("ä¸Šå‚³æ–‡ä»¶æ•¸ï¼š", "ä¸Šä¼ æ–‡ä»¶æ•°ï¼š") if lang == "zh" else "Uploaded documents: ") + str(len(docs)))

            u_stats = usage_stats.get(u)
            if not u_stats:
                st.caption(zh("å°šç„¡åˆ†æè¨˜éŒ„", "å°šæ— åˆ†æè®°å½•") if lang == "zh" else "No analysis usage recorded yet.")
            else:
                if content_access:
                    st.write((zh("æœ€å¾Œä½¿ç”¨æ™‚é–“ï¼š", "æœ€åä½¿ç”¨æ—¶é—´ï¼š") if lang == "zh" else "Last used: ") + u_stats.get("last_used", "-"))
                    fw_map = u_stats.get("frameworks", {})
                    for fw_key, fw_data in fw_map.items():
                        fw_name = FRAMEWORKS.get(fw_key, {}).get("name_zh", fw_key) if lang == "zh" else FRAMEWORKS.get(fw_key, {}).get("name_en", fw_key)
                        st.markdown(
                            f"- {fw_name}ï¼š{zh('åˆ†æ', 'åˆ†æ')} {fw_data.get('analysis_runs', 0)} {zh('æ¬¡', 'æ¬¡')}ï¼Œ"
                            f"{zh('è¿½å•', 'è¿½é—®')} {fw_data.get('followups', 0)} {zh('æ¬¡', 'æ¬¡')}ï¼Œ"
                            f"{zh('ä¸‹è¼‰', 'ä¸‹è½½')} {fw_data.get('downloads', 0)} {zh('æ¬¡', 'æ¬¡')}"
                            if lang == "zh"
                            else f"- {fw_name}: analysis {fw_data.get('analysis_runs', 0)} times, follow-ups {fw_data.get('followups', 0)} times, downloads {fw_data.get('downloads', 0)} times"
                        )
                else:
                    st.caption(zh("ï¼ˆåƒ…é¡¯ç¤ºä½¿ç”¨é‡ç¸½æ•¸ï¼Œæœªå•Ÿç”¨å…§å®¹æª¢è¦–æ¬Šé™ï¼‰", "ï¼ˆä»…æ˜¾ç¤ºä½¿ç”¨é‡æ€»æ•°ï¼Œæœªå¯ç”¨å†…å®¹æŸ¥çœ‹æƒé™ï¼‰") if lang == "zh" else "(Only aggregate usage visible; content access disabled.)")

            st.markdown("---")


def admin_dashboard():
    lang = st.session_state.get("lang", "zh")
    st.title("Admin Dashboard â€” Error-FreeÂ®")
    st.markdown("---")

    st.subheader(zh("ğŸ“Œ Guest å¸³è™Ÿåˆ—è¡¨", "ğŸ“Œ Guest è´¦å·åˆ—è¡¨") if lang == "zh" else "ğŸ“Œ Guest accounts")
    guests = load_guest_accounts()
    if not guests:
        st.info(zh("ç›®å‰æ²’æœ‰ Guest å¸³è™Ÿã€‚", "ç›®å‰æ²¡æœ‰ Guest è´¦å·ã€‚") if lang == "zh" else "No guest accounts yet.")
    else:
        for email, acc in guests.items():
            st.markdown(f"**{email}** â€” password: `{acc.get('password')}` (role: {acc.get('role')})")
            st.markdown("---")

    st.subheader(zh("ğŸ“ Guest æ–‡ä»¶ä½¿ç”¨ç‹€æ³", "ğŸ“ Guest æ–‡ä»¶ä½¿ç”¨æƒ…å†µ") if lang == "zh" else "ğŸ“ Guest document usage")
    doc_tracking = load_doc_tracking()
    if not doc_tracking:
        st.info(zh("å°šç„¡ Guest ä¸Šå‚³è¨˜éŒ„ã€‚", "å°šæ—  Guest ä¸Šä¼ è®°å½•ã€‚") if lang == "zh" else "No guest uploads recorded yet.")
    else:
        for email, docs in doc_tracking.items():
            st.markdown(f"**{email}** â€” {zh('ä¸Šå‚³æ–‡ä»¶æ•¸ï¼š', 'ä¸Šä¼ æ–‡ä»¶æ•°ï¼š')}{len(docs)} / 3" if lang == "zh" else f"**{email}** â€” uploaded documents: {len(docs)} / 3")
            for d in docs:
                st.markdown(f"- {d}")
            st.markdown("---")

    st.subheader(zh("ğŸ§© æ¨¡çµ„åˆ†æèˆ‡è¿½å•ç‹€æ³ (Session-based)", "ğŸ§© æ¨¡å—åˆ†æä¸è¿½é—®æƒ…å†µ (Session-based)") if lang == "zh" else "ğŸ§© Framework state (current session)")
    fs = st.session_state.get("framework_states", {})
    if not fs:
        st.info(zh("å°šç„¡ Framework åˆ†æè¨˜éŒ„", "å°šæ—  Framework åˆ†æè®°å½•") if lang == "zh" else "No framework analysis yet.")
    else:
        for fw_key, state in fs.items():
            fw_name = FRAMEWORKS.get(fw_key, {}).get("name_zh", fw_key) if lang == "zh" else FRAMEWORKS.get(fw_key, {}).get("name_en", fw_key)
            st.markdown(f"### â–¶ {fw_name}")
            st.write(f"{zh('åˆ†æå®Œæˆï¼š', 'åˆ†æå®Œæˆï¼š')}{state.get('analysis_done')}" if lang == "zh" else f"Analysis done: {state.get('analysis_done')}")
            st.write(f"{zh('è¿½å•æ¬¡æ•¸ï¼š', 'è¿½é—®æ¬¡æ•°ï¼š')}{len(state.get('followup_history', []))}" if lang == "zh" else f"Follow-up count: {len(state.get('followup_history', []))}")
            st.write(f"{zh('å·²ä¸‹è¼‰å ±å‘Šï¼š', 'å·²ä¸‹è½½æŠ¥å‘Šï¼š')}{state.get('download_used')}" if lang == "zh" else f"Downloaded report: {state.get('download_used')}")
            st.markdown("---")

    st.subheader(zh("ğŸ¢ å…¬å¸ä½¿ç”¨é‡ç¸½è¦½", "ğŸ¢ å…¬å¸ä½¿ç”¨é‡æ€»è§ˆ") if lang == "zh" else "ğŸ¢ Company usage overview")
    companies = load_companies()
    usage_stats = load_usage_stats()

    if not companies:
        st.info(zh("ç›®å‰å°šæœªå»ºç«‹ä»»ä½•å…¬å¸ã€‚", "ç›®å‰å°šæœªå»ºç«‹ä»»ä½•å…¬å¸ã€‚") if lang == "zh" else "No companies registered yet.")
    else:
        doc_tracking = load_doc_tracking()
        for code, entry in companies.items():
            company_name = entry.get("company_name") or code
            users = entry.get("users", [])
            content_access = entry.get("content_access", False)

            total_docs = 0
            total_analysis = 0
            total_followups = 0
            total_downloads = 0

            for u in users:
                total_docs += len(doc_tracking.get(u, []))
                u_stats = usage_stats.get(u, {})
                fw_map = u_stats.get("frameworks", {})
                for fw_data in fw_map.values():
                    total_analysis += fw_data.get("analysis_runs", 0)
                    total_followups += fw_data.get("followups", 0)
                    total_downloads += fw_data.get("downloads", 0)

            st.markdown(f"### {company_name} (code: {code})")
            st.write(f"{zh('å­¸ç”Ÿ / ä½¿ç”¨è€…æ•¸ï¼š', 'å­¦å‘˜ / ç”¨æˆ·æ•°ï¼š')}{len(users)}" if lang == "zh" else f"Users: {len(users)}")
            st.write(f"{zh('ç¸½ä¸Šå‚³æ–‡ä»¶æ•¸ï¼š', 'æ€»ä¸Šä¼ æ–‡ä»¶æ•°ï¼š')}{total_docs}" if lang == "zh" else f"Total uploaded documents: {total_docs}")
            st.write(f"{zh('ç¸½åˆ†ææ¬¡æ•¸ï¼š', 'æ€»åˆ†ææ¬¡æ•°ï¼š')}{total_analysis}" if lang == "zh" else f"Total analysis runs: {total_analysis}")
            st.write(f"{zh('ç¸½è¿½å•æ¬¡æ•¸ï¼š', 'æ€»è¿½é—®æ¬¡æ•°ï¼š')}{total_followups}" if lang == "zh" else f"Total follow-ups: {total_followups}")
            st.write(f"{zh('ç¸½ä¸‹è¼‰æ¬¡æ•¸ï¼š', 'æ€»ä¸‹è½½æ¬¡æ•°ï¼š')}{total_downloads}" if lang == "zh" else f"Total downloads: {total_downloads}")
            st.write((zh("content_accessï¼š", "content_accessï¼š") if lang == "zh" else "content_access: ") + (zh("å•Ÿç”¨", "å¯ç”¨") if content_access else zh("é—œé–‰", "å…³é—­")) if lang == "zh" else "content_access: " + ("enabled" if content_access else "disabled"))
            st.markdown("---")

    st.subheader(zh("ğŸ” å…¬å¸å…§å®¹æª¢è¦–æ¬Šé™è¨­å®š", "ğŸ” å…¬å¸å†…å®¹æŸ¥çœ‹æƒé™è®¾ç½®") if lang == "zh" else "ğŸ” Company content access settings")
    if not companies:
        st.info(zh("å°šç„¡å…¬å¸å¯è¨­å®šã€‚", "å°šæ— å…¬å¸å¯è®¾ç½®ã€‚") if lang == "zh" else "No companies to configure.")
    else:
        for code, entry in companies.items():
            label = f"{entry.get('company_name') or code} ({code})"
            key = f"content_access_{code}"
            current_val = entry.get("content_access", False)
            st.checkbox(label + (zh(" â€” å¯æª¢è¦–å­¸ç”Ÿåˆ†æä½¿ç”¨é‡", " â€” å¯æŸ¥çœ‹å­¦å‘˜åˆ†æä½¿ç”¨é‡") if lang == "zh" else " â€” can view user usage details"), value=current_val, key=key)

        if st.button(zh("å„²å­˜å…¬å¸æ¬Šé™è¨­å®š", "ä¿å­˜å…¬å¸æƒé™è®¾ç½®") if lang == "zh" else "Save company access settings"):
            for code, entry in companies.items():
                key = f"content_access_{code}"
                new_val = bool(st.session_state.get(key, entry.get("content_access", False)))
                entry["content_access"] = new_val
                companies[code] = entry
            save_companies(companies)
            st.success(zh("å·²æ›´æ–°å…¬å¸æ¬Šé™è¨­å®šã€‚", "å·²æ›´æ–°å…¬å¸æƒé™è®¾ç½®ã€‚") if lang == "zh" else "Company settings updated.")


if "show_admin" not in st.session_state:
    st.session_state.show_admin = False


def admin_router() -> bool:
    if st.session_state.show_admin:
        role = st.session_state.get("user_role")
        if role == "company_admin":
            company_admin_dashboard()
        else:
            admin_dashboard()
        if st.button(zh("è¿”å›åˆ†æé é¢", "è¿”å›åˆ†æé¡µé¢") if st.session_state.get("lang", "zh") == "zh" else "Back to analysis"):
            st.session_state.show_admin = False
            save_state_to_disk()
            st.rerun()
        return True
    return False


# =========================
# Branding
# =========================

BRAND_TITLE_EN = "Error-FreeÂ® Intelligence Engine"
BRAND_TAGLINE_EN = "An AI-enhanced intelligence engine that helps organizations analyze risks, prevent errors, and make better decisions."
BRAND_SUBTITLE_EN = "Pioneered and refined by Dr. Chiuâ€™s Error-FreeÂ® team since 1987."

BRAND_TITLE_ZH = zh("é›¶éŒ¯èª¤æ™ºèƒ½å¼•æ“", "é›¶é”™è¯¯æ™ºèƒ½å¼•æ“")
BRAND_TAGLINE_ZH = zh("ä¸€å¥— AI å¼·åŒ–çš„æ™ºèƒ½å¼•æ“ï¼Œå”åŠ©å…¬å¸æˆ–çµ„ç¹”é€²è¡Œé¢¨éšªåˆ†æã€é é˜²éŒ¯èª¤ï¼Œä¸¦æå‡æ±ºç­–å“è³ªã€‚", "ä¸€å¥— AI å¼ºåŒ–çš„æ™ºèƒ½å¼•æ“ï¼ŒååŠ©å…¬å¸æˆ–ç»„ç»‡è¿›è¡Œé£é™©åˆ†æã€é¢„é˜²é”™è¯¯ï¼Œå¹¶æå‡å†³ç­–å“è´¨ã€‚")
BRAND_SUBTITLE_ZH = zh("é‚±åšå£«é›¶éŒ¯èª¤åœ˜éšŠè‡ª 1987 å¹´èµ·é ˜å…ˆç ”ç™¼ä¸¦æŒçºŒæ·±åŒ–è‡³ä»Šã€‚", "é‚±åšå£«é›¶é”™è¯¯å›¢é˜Ÿè‡ª 1987 å¹´èµ·é¢†å…ˆç ”å‘å¹¶æŒç»­æ·±åŒ–è‡³ä»Šã€‚")

LOGO_PATH = "assets/errorfree_logo.png"


def language_selector():
    current_lang = st.session_state.get("lang", "zh")
    current_variant = st.session_state.get("zh_variant", "tw")

    if current_lang == "en":
        index = 0
    else:
        index = 1 if current_variant == "cn" else 2

    choice = st.radio("Language / èªè¨€", ("English", "ä¸­æ–‡ç®€ä½“", "ä¸­æ–‡ç¹é«”"), index=index)

    if choice == "English":
        st.session_state.lang = "en"
        if "zh_variant" not in st.session_state:
            st.session_state.zh_variant = "tw"
    else:
        st.session_state.lang = "zh"
        st.session_state.zh_variant = "cn" if choice == "ä¸­æ–‡ç®€ä½“" else "tw"


# =========================
# Main app
# =========================

def main():
    st.set_page_config(page_title=BRAND_TITLE_EN, layout="wide")
    restore_state_from_disk()

    defaults = [
        ("user_email", None),
        ("user_role", None),
        ("is_authenticated", False),
        ("lang", "zh"),
        ("zh_variant", "tw"),
        ("usage_date", None),
        ("usage_count", 0),
        ("last_doc_text", ""),
        ("last_doc_name", ""),
        ("document_type", None),
        ("reference_history", []),
        ("ref_pending", False),
        ("framework_states", {}),
        ("selected_framework_key", None),
        ("current_doc_id", None),
        ("company_code", None),
        ("show_admin", False),
    ]
    for k, v in defaults:
        if k not in st.session_state:
            st.session_state[k] = v

    if st.session_state.selected_framework_key is None and FRAMEWORKS:
        st.session_state.selected_framework_key = list(FRAMEWORKS.keys())[0]

    doc_tracking = load_doc_tracking()

    with st.sidebar:
        lang = st.session_state.lang

        language_selector()
        lang = st.session_state.lang

        if st.session_state.is_authenticated and st.session_state.user_role in ["admin", "pro", "company_admin"]:
            if st.button("ç®¡ç†å¾Œå° Admin Dashboard"):
                st.session_state.show_admin = True
                save_state_to_disk()
                st.rerun()

        st.markdown("---")
        if st.session_state.is_authenticated:
            st.subheader(zh("å¸³è™Ÿè³‡è¨Š", "è´¦å·ä¿¡æ¯") if lang == "zh" else "Account")
            st.write(f"Emailï¼š{st.session_state.user_email}")
            if st.button(zh("ç™»å‡º", "é€€å‡ºç™»å½•") if lang == "zh" else "Logout"):
                st.session_state.user_email = None
                st.session_state.user_role = None
                st.session_state.is_authenticated = False
                st.session_state.framework_states = {}
                st.session_state.last_doc_text = ""
                st.session_state.last_doc_name = ""
                st.session_state.document_type = None
                st.session_state.reference_history = []
                st.session_state.ref_pending = False
                st.session_state.current_doc_id = None
                save_state_to_disk()
                st.rerun()
        else:
            st.subheader(zh("å°šæœªç™»å…¥", "å°šæœªç™»å½•") if lang == "zh" else "Not Logged In")
            if lang == "zh":
                st.markdown(
                    "- " + zh("ä¸Šæ–¹ï¼šå…§éƒ¨å“¡å·¥ / æœƒå“¡ç™»å…¥ã€‚", "ä¸Šæ–¹ï¼šå†…éƒ¨å‘˜å·¥ / ä¼šå‘˜ç™»å½•ã€‚") + "\n"
                    "- " + zh("ä¸­é–“ï¼šå…¬å¸ç®¡ç†è€…ï¼ˆä¼æ¥­ç«¯çª—å£ï¼‰ç™»å…¥ / è¨»å†Šã€‚", "ä¸­é—´ï¼šå…¬å¸ç®¡ç†è€…ï¼ˆä¼ä¸šç«¯çª—å£ï¼‰ç™»å½• / æ³¨å†Œã€‚") + "\n"
                    "- " + zh("ä¸‹æ–¹ï¼šå­¸ç”Ÿ / å®¢æˆ¶çš„ Guest è©¦ç”¨ç™»å…¥ / è¨»å†Šã€‚", "ä¸‹æ–¹ï¼šå­¦å‘˜ / å®¢æˆ·çš„ Guest è¯•ç”¨ç™»å½• / æ³¨å†Œã€‚")
                )
            else:
                st.markdown(
                    "- Top: internal Error-Free employees / members.\n"
                    "- Middle: **Company Admins** for each client company.\n"
                    "- Bottom: students / end-users using **Guest trial accounts**."
                )

    # ======= Login screen =======
    if not st.session_state.is_authenticated:
        lang = st.session_state.lang

        if Path(LOGO_PATH).exists():
            st.image(LOGO_PATH, width=260)

        title = BRAND_TITLE_ZH if lang == "zh" else BRAND_TITLE_EN
        tagline = BRAND_TAGLINE_ZH if lang == "zh" else BRAND_TAGLINE_EN
        subtitle = BRAND_SUBTITLE_ZH if lang == "zh" else BRAND_SUBTITLE_EN

        st.title(title)
        st.write(tagline)
        st.caption(subtitle)
        st.markdown("---")

        if lang == "zh":
            st.markdown(
                zh(
                    "æœ¬ç³»çµ±é‹ç”¨ AI æå‡å¯©é–±æµç¨‹çš„é€Ÿåº¦èˆ‡å»£åº¦ï¼Œå”åŠ©åœ˜éšŠæ›´æ—©ä¸”æ›´æœ‰æ•ˆåœ°è­˜åˆ¥æ½›åœ¨é¢¨éšªèˆ‡ä¸å¯æ¥å—çš„éŒ¯èª¤ï¼Œé™ä½ä¼æ¥­æå¤±çš„å¯èƒ½æ€§ã€‚æœ€çµ‚æ±ºç­–ä»ç”±å…·å‚™å°ˆæ¥­çŸ¥è­˜ã€ç¶“é©—èˆ‡æƒ…å¢ƒåˆ¤æ–·èƒ½åŠ›çš„äººå“¡è² è²¬ï¼›AI çš„è§’è‰²åœ¨æ–¼è¼”åŠ©ã€å¼·åŒ–èˆ‡æé†’ï¼Œè€Œéå–ä»£äººé¡çš„åˆ¤æ–·ã€‚",
                    "æœ¬ç³»ç»Ÿè¿ç”¨ AI æå‡å®¡é˜…æµç¨‹çš„é€Ÿåº¦ä¸å¹¿åº¦ï¼ŒååŠ©å›¢é˜Ÿæ›´æ—©ä¸”æ›´æœ‰æ•ˆåœ°è¯†åˆ«æ½œåœ¨é£é™©ä¸ä¸å¯æ¥å—çš„é”™è¯¯ï¼Œé™ä½ä¼ä¸šæŸå¤±çš„å¯èƒ½æ€§ã€‚æœ€ç»ˆå†³ç­–ä»ç”±å…·å¤‡ä¸“ä¸šçŸ¥è¯†ã€ç»éªŒä¸æƒ…å¢ƒåˆ¤æ–­èƒ½åŠ›çš„äººå‘˜è´Ÿè´£ï¼›AI çš„è§’è‰²åœ¨äºè¾…åŠ©ã€å¼ºåŒ–ä¸æé†’ï¼Œè€Œéå–ä»£äººç±»çš„åˆ¤æ–­ã€‚",
                )
            )
        else:
            st.markdown(
                "AI is used to enhance the speed and breadth of the review processâ€”helping teams identify potential risks and unacceptable errors earlier and more efficiently. "
                "Final decisions, however, remain the responsibility of human experts, who apply professional judgment, experience, and contextual understanding. "
                "The role of AI is to assist, augment, and alertâ€”not to replace human decision-making."
            )

        st.markdown("---")

        st.markdown(("### " + zh("å…§éƒ¨å“¡å·¥ / æœƒå“¡ç™»å…¥", "å†…éƒ¨å‘˜å·¥ / ä¼šå‘˜ç™»å½•")) if lang == "zh" else "### Internal Employee / Member Login")
        emp_email = st.text_input("Email", key="emp_email")
        emp_pw = st.text_input(zh("å¯†ç¢¼", "å¯†ç ") if lang == "zh" else "Password", type="password", key="emp_pw")
        if st.button(zh("ç™»å…¥", "ç™»å½•") if lang == "zh" else "Login", key="emp_login_btn"):
            account = ACCOUNTS.get(emp_email)
            if account and account["password"] == emp_pw:
                st.session_state.user_email = emp_email
                st.session_state.user_role = account["role"]
                st.session_state.is_authenticated = True
                save_state_to_disk()
                st.rerun()
            else:
                st.error(zh("å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤", "è´¦å·æˆ–å¯†ç é”™è¯¯") if lang == "zh" else "Invalid email or password")

        st.markdown("---")

        st.markdown(("### " + zh("å…¬å¸ç®¡ç†è€…ï¼ˆä¼æ¥­çª—å£ï¼‰", "å…¬å¸ç®¡ç†è€…ï¼ˆä¼ä¸šçª—å£ï¼‰")) if lang == "zh" else "### Company Admin (Client-side)")
        col_ca_signup, col_ca_login = st.columns(2)

        with col_ca_signup:
            st.markdown("**" + (zh("å…¬å¸ç®¡ç†è€…è¨»å†Š", "å…¬å¸ç®¡ç†è€…æ³¨å†Œ") if lang == "zh" else "Company Admin Signup") + "**")
            ca_new_email = st.text_input(zh("ç®¡ç†è€…è¨»å†Š Email", "ç®¡ç†è€…æ³¨å†Œ Email") if lang == "zh" else "Admin signup email", key="ca_new_email")
            ca_new_pw = st.text_input(zh("è¨­å®šç®¡ç†è€…å¯†ç¢¼", "è®¾ç½®ç®¡ç†è€…å¯†ç ") if lang == "zh" else "Set admin password", type="password", key="ca_new_pw")
            ca_company_code = st.text_input("å…¬å¸ä»£ç¢¼ Company Code", key="ca_company_code")

            if st.button(zh("å»ºç«‹ç®¡ç†è€…å¸³è™Ÿ", "å»ºç«‹ç®¡ç†è€…è´¦å·") if lang == "zh" else "Create Company Admin Account", key="ca_signup_btn"):
                if not ca_new_email or not ca_new_pw or not ca_company_code:
                    st.error(zh("è«‹å®Œæ•´å¡«å¯«ç®¡ç†è€…è¨»å†Šè³‡è¨Š", "è¯·å®Œæ•´å¡«å†™ç®¡ç†è€…æ³¨å†Œä¿¡æ¯") if lang == "zh" else "Please fill all admin signup fields")
                else:
                    companies = load_companies()
                    guests = load_guest_accounts()
                    if ca_company_code not in companies:
                        st.error(zh("å…¬å¸ä»£ç¢¼ä¸å­˜åœ¨ï¼Œè«‹å…ˆå‘ç³»çµ±ç®¡ç†å“¡å»ºç«‹å…¬å¸", "å…¬å¸ä»£ç ä¸å­˜åœ¨ï¼Œè¯·å…ˆå‘ç³»ç»Ÿç®¡ç†å‘˜å»ºç«‹å…¬å¸") if lang == "zh" else "Company code not found. Please ask the system admin to create it.")
                    elif ca_new_email in ACCOUNTS or ca_new_email in guests:
                        st.error(zh("æ­¤ Email å·²è¢«ä½¿ç”¨", "æ­¤ Email å·²è¢«ä½¿ç”¨") if lang == "zh" else "This email is already in use")
                    else:
                        guests[ca_new_email] = {"password": ca_new_pw, "role": "company_admin", "company_code": ca_company_code}
                        save_guest_accounts(guests)

                        entry = companies[ca_company_code]
                        admins = entry.get("admins", [])
                        if ca_new_email not in admins:
                            admins.append(ca_new_email)
                        entry["admins"] = admins
                        if "company_name" not in entry:
                            entry["company_name"] = ""
                        if "content_access" not in entry:
                            entry["content_access"] = False
                        companies[ca_company_code] = entry
                        save_companies(companies)

                        st.success(zh("å…¬å¸ç®¡ç†è€…å¸³è™Ÿå·²å»ºç«‹", "å…¬å¸ç®¡ç†è€…è´¦å·å·²å»ºç«‹") if lang == "zh" else "Company admin account created")

        with col_ca_login:
            st.markdown("**" + (zh("å…¬å¸ç®¡ç†è€…ç™»å…¥", "å…¬å¸ç®¡ç†è€…ç™»å½•") if lang == "zh" else "Company Admin Login") + "**")
            ca_email = st.text_input(zh("ç®¡ç†è€… Email", "ç®¡ç†è€… Email") if lang == "zh" else "Admin Email", key="ca_email")
            ca_pw = st.text_input(zh("ç®¡ç†è€…å¯†ç¢¼", "ç®¡ç†è€…å¯†ç ") if lang == "zh" else "Admin Password", type="password", key="ca_pw")
            if st.button(zh("ç®¡ç†è€…ç™»å…¥", "ç®¡ç†è€…ç™»å½•") if lang == "zh" else "Login as Company Admin", key="ca_login_btn"):
                guests = load_guest_accounts()
                acc = guests.get(ca_email)
                if acc and acc.get("password") == ca_pw and acc.get("role") == "company_admin":
                    st.session_state.user_email = ca_email
                    st.session_state.user_role = "company_admin"
                    st.session_state.company_code = acc.get("company_code")
                    st.session_state.is_authenticated = True
                    save_state_to_disk()
                    st.rerun()
                else:
                    st.error(zh("ç®¡ç†è€…å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤", "ç®¡ç†è€…è´¦å·æˆ–å¯†ç é”™è¯¯") if lang == "zh" else "Invalid company admin credentials")

        st.markdown("---")

        st.markdown("### " + (zh("Guest è©¦ç”¨å¸³è™Ÿ", "Guest è¯•ç”¨è´¦å·") if lang == "zh" else "Guest Trial Accounts"))
        col_guest_signup, col_guest_login = st.columns(2)

        with col_guest_signup:
            st.markdown("**" + (zh("Guest è©¦ç”¨è¨»å†Š", "Guest è¯•ç”¨æ³¨å†Œ") if lang == "zh" else "Guest Signup") + "**")
            new_guest_email = st.text_input(zh("è¨»å†Š Email", "æ³¨å†Œ Email") if lang == "zh" else "Email for signup", key="new_guest_email")
            guest_company_code = st.text_input(zh("å…¬å¸ä»£ç¢¼ Company Code", "å…¬å¸ä»£ç  Company Code") if lang == "zh" else "Company Code", key="guest_company_code")

            if st.button(zh("å–å¾— Guest å¯†ç¢¼", "è·å– Guest å¯†ç ") if lang == "zh" else "Generate Guest Password", key="guest_signup_btn"):
                if not new_guest_email:
                    st.error(zh("è«‹è¼¸å…¥ Email", "è¯·è¾“å…¥ Email") if lang == "zh" else "Please enter an email")
                elif not guest_company_code:
                    st.error(zh("è«‹è¼¸å…¥å…¬å¸ä»£ç¢¼", "è¯·è¾“å…¥å…¬å¸ä»£ç ") if lang == "zh" else "Please enter your Company Code")
                else:
                    guests = load_guest_accounts()
                    companies = load_companies()
                    if guest_company_code not in companies:
                        st.error(zh("å…¬å¸ä»£ç¢¼ä¸å­˜åœ¨ï¼Œè«‹å‘è¬›å¸«æˆ–å…¬å¸çª—å£ç¢ºèª", "å…¬å¸ä»£ç ä¸å­˜åœ¨ï¼Œè¯·å‘è®²å¸ˆæˆ–å…¬å¸çª—å£ç¡®è®¤") if lang == "zh" else "Invalid Company Code. Please check with your instructor or admin.")
                    elif new_guest_email in guests or new_guest_email in ACCOUNTS:
                        st.error(zh("Email å·²å­˜åœ¨", "Email å·²å­˜åœ¨") if lang == "zh" else "Email already exists")
                    else:
                        pw = "".join(secrets.choice("0123456789") for _ in range(8))
                        guests[new_guest_email] = {"password": pw, "role": "free", "company_code": guest_company_code}
                        save_guest_accounts(guests)

                        entry = companies[guest_company_code]
                        users = entry.get("users", [])
                        if new_guest_email not in users:
                            users.append(new_guest_email)
                        entry["users"] = users
                        if "company_name" not in entry:
                            entry["company_name"] = entry.get("company_name", "")
                        if "content_access" not in entry:
                            entry["content_access"] = False
                        companies[guest_company_code] = entry
                        save_companies(companies)

                        st.success((zh(f"Guest å¸³è™Ÿå·²å»ºç«‹ï¼å¯†ç¢¼ï¼š{pw}", f"Guest è´¦å·å·²å»ºç«‹ï¼å¯†ç ï¼š{pw}") if lang == "zh" else f"Guest account created! Password: {pw}"))

        with col_guest_login:
            st.markdown("**" + (zh("Guest è©¦ç”¨ç™»å…¥", "Guest è¯•ç”¨ç™»å½•") if lang == "zh" else "Guest Login") + "**")
            g_email = st.text_input("Guest Email", key="g_email")
            g_pw = st.text_input(zh("å¯†ç¢¼", "å¯†ç ") if lang == "zh" else "Password", type="password", key="g_pw")
            if st.button(zh("ç™»å…¥ Guest", "ç™»å½• Guest") if lang == "zh" else "Login as Guest", key="guest_login_btn"):
                guests = load_guest_accounts()
                g_acc = guests.get(g_email)
                if g_acc and g_acc.get("password") == g_pw:
                    st.session_state.company_code = g_acc.get("company_code")
                    st.session_state.user_email = g_email
                    st.session_state.user_role = "free"
                    st.session_state.is_authenticated = True
                    save_state_to_disk()
                    st.rerun()
                else:
                    st.error(zh("å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤", "è´¦å·æˆ–å¯†ç é”™è¯¯") if lang == "zh" else "Invalid guest credentials")

        return  # login page end

    # ======= Main app (logged in) =======
    if admin_router():
        return

    lang = st.session_state.lang

    if Path(LOGO_PATH).exists():
        st.image(LOGO_PATH, width=260)

    st.title(BRAND_TITLE_ZH if lang == "zh" else BRAND_TITLE_EN)
    st.write(BRAND_TAGLINE_ZH if lang == "zh" else BRAND_TAGLINE_EN)
    st.caption(BRAND_SUBTITLE_ZH if lang == "zh" else BRAND_SUBTITLE_EN)
    st.markdown("---")

    user_email = st.session_state.user_email
    user_role = st.session_state.user_role
    is_guest = user_role == "free"
    model_name = resolve_model_for_user(user_role)

    # Step 1: upload review doc
    st.subheader(zh("æ­¥é©Ÿä¸€ï¼šä¸Šå‚³å¯©é–±æ–‡ä»¶", "æ­¥éª¤ä¸€ï¼šä¸Šä¼ å®¡é˜…æ–‡ä»¶") if lang == "zh" else "Step 1: Upload Review Document")
    st.caption(zh("æé†’ï¼šä¸€æ¬¡åªèƒ½ä¸Šè¼‰ 1 ä»½æ–‡ä»¶é€²è¡Œå®Œæ•´å…§å®¹åˆ†æã€‚", "æé†’ï¼šä¸€æ¬¡åªèƒ½ä¸Šä¼  1 ä»½æ–‡ä»¶è¿›è¡Œå®Œæ•´å†…å®¹åˆ†æã€‚") if lang == "zh" else "Note: Only 1 document can be uploaded for a complete content analysis.")

    doc_locked = bool(st.session_state.get("last_doc_text"))

    if not doc_locked:
        uploaded = st.file_uploader(
            zh("è«‹ä¸Šå‚³ PDF / DOCX / TXT / åœ–ç‰‡", "è¯·ä¸Šä¼  PDF / DOCX / TXT / å›¾ç‰‡") if lang == "zh" else "Upload PDF / DOCX / TXT / Image",
            type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
            key="review_doc_uploader",
        )

        if uploaded is not None:
            doc_text = read_file_to_text(uploaded)
            if doc_text:
                if is_guest:
                    docs = doc_tracking.get(user_email, [])
                    if len(docs) >= 3 and st.session_state.current_doc_id not in docs:
                        st.error(zh("è©¦ç”¨å¸³è™Ÿæœ€å¤šä¸Šå‚³ 3 ä»½æ–‡ä»¶", "è¯•ç”¨è´¦å·æœ€å¤šä¸Šä¼  3 ä»½æ–‡ä»¶") if lang == "zh" else "Trial accounts may upload up to 3 documents only")
                    else:
                        if st.session_state.current_doc_id not in docs:
                            new_id = f"doc_{datetime.datetime.now().timestamp()}"
                            docs.append(new_id)
                            doc_tracking[user_email] = docs
                            st.session_state.current_doc_id = new_id
                            save_doc_tracking(doc_tracking)
                        st.session_state.last_doc_text = doc_text
                        st.session_state.last_doc_name = uploaded.name
                        save_state_to_disk()
                else:
                    st.session_state.current_doc_id = f"doc_{datetime.datetime.now().timestamp()}"
                    st.session_state.last_doc_text = doc_text
                    st.session_state.last_doc_name = uploaded.name
                    save_state_to_disk()
    else:
        shown_name = st.session_state.get("last_doc_name") or zh("ï¼ˆå·²ä¸Šå‚³ï¼‰", "ï¼ˆå·²ä¸Šä¼ ï¼‰")
        st.info(zh(f"å·²ä¸Šå‚³å¯©é–±æ–‡ä»¶ï¼š{shown_name}ã€‚å¦‚éœ€æ›´æ›æ–‡ä»¶ï¼Œè«‹ä½¿ç”¨ Reset documentã€‚", f"å·²ä¸Šä¼ å®¡é˜…æ–‡ä»¶ï¼š{shown_name}ã€‚å¦‚éœ€æ›´æ¢æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ Reset documentã€‚") if lang == "zh" else f"Review document uploaded: {shown_name}. To change it, please use Reset document.")

    # Step 2: Document Type Selection (Fix zh labels, keep value = English)
    st.subheader(zh("æ­¥é©ŸäºŒï¼šæ–‡ä»¶é¡å‹é¸æ“‡ï¼ˆå–®é¸ï¼‰", "æ­¥éª¤äºŒï¼šæ–‡ä»¶ç±»å‹é€‰æ‹©ï¼ˆå•é€‰ï¼‰") if lang == "zh" else "Step 2: Document Type Selection")
    st.caption(zh("å–®é¸", "å•é€‰") if lang == "zh" else "Single selection")

    DOC_TYPES = [
        "Conceptual Design",
        "Preliminary Design",
        "Final Design",
        "Equivalency Engineering Evaluation",
        "Root Cause Analysis",
        "Safety Analysis",
        "Specifications and Requirements",
        "Calculations and Analysis",
    ]

    DOC_TYPE_LABELS_ZH_TW = {
        "Conceptual Design": "æ¦‚å¿µè¨­è¨ˆ",
        "Preliminary Design": "åˆæ­¥è¨­è¨ˆ",
        "Final Design": "æœ€çµ‚è¨­è¨ˆ",
        "Equivalency Engineering Evaluation": "ç­‰æ•ˆå·¥ç¨‹è©•ä¼°",
        "Root Cause Analysis": "æ ¹æœ¬åŸå› åˆ†æ",
        "Safety Analysis": "å®‰å…¨åˆ†æ",
        "Specifications and Requirements": "è¦æ ¼èˆ‡éœ€æ±‚",
        "Calculations and Analysis": "è¨ˆç®—èˆ‡åˆ†æ",
    }
    DOC_TYPE_LABELS_ZH_CN = {
        "Conceptual Design": "æ¦‚å¿µè®¾è®¡",
        "Preliminary Design": "åˆæ­¥è®¾è®¡",
        "Final Design": "æœ€ç»ˆè®¾è®¡",
        "Equivalency Engineering Evaluation": "ç­‰æ•ˆå·¥ç¨‹è¯„ä¼°",
        "Root Cause Analysis": "æ ¹æœ¬åŸå› åˆ†æ",
        "Safety Analysis": "å®‰å…¨åˆ†æ",
        "Specifications and Requirements": "è§„æ ¼ä¸éœ€æ±‚",
        "Calculations and Analysis": "è®¡ç®—ä¸åˆ†æ",
    }

    if st.session_state.get("document_type") not in DOC_TYPES:
        st.session_state.document_type = DOC_TYPES[0]

    if lang == "zh":
        mapping = DOC_TYPE_LABELS_ZH_CN if st.session_state.get("zh_variant", "tw") == "cn" else DOC_TYPE_LABELS_ZH_TW
        labels = [mapping.get(x, x) for x in DOC_TYPES]
        label_to_value = {mapping.get(x, x): x for x in DOC_TYPES}
        value_to_label = {x: mapping.get(x, x) for x in DOC_TYPES}
        current_label = value_to_label.get(st.session_state.document_type, labels[0])

        picked_label = st.selectbox(
            zh("é¸æ“‡æ–‡ä»¶é¡å‹", "é€‰æ‹©æ–‡ä»¶ç±»å‹"),
            labels,
            index=labels.index(current_label) if current_label in labels else 0,
            key="document_type_select_zh",
        )
        st.session_state.document_type = label_to_value.get(picked_label, DOC_TYPES[0])
    else:
        st.session_state.document_type = st.selectbox(
            "Select document type",
            DOC_TYPES,
            index=DOC_TYPES.index(st.session_state.document_type),
            key="document_type_select",
        )
    save_state_to_disk()

    # Step 3: Reference docs (optional, one at a time)
    st.subheader(zh("æ­¥é©Ÿä¸‰ï¼šä¸Šå‚³åƒè€ƒæ–‡ä»¶ï¼ˆé¸å¡«ï¼‰", "æ­¥éª¤ä¸‰ï¼šä¸Šä¼ å‚è€ƒæ–‡ä»¶ï¼ˆé€‰å¡«ï¼‰") if lang == "zh" else "Step 3: Upload Reference Documents (optional)")

    st.caption(
        zh(
            "ä¸€æ¬¡åªèƒ½ä¸Šå‚³ 1 ä»½åƒè€ƒæ–‡ä»¶ã€‚ç¬¬ä¸€æ¬¡åˆ†æå¯ä¸Šå‚³ 1 ä»½ï¼›åˆ†æå®Œæˆå¾Œï¼Œå¯å†ä¸Šå‚³ç¬¬ 2 ä»½ï¼ˆä¾æ­¤é¡æ¨ï¼‰ï¼Œé¿å…åˆ†ææ™‚é–“éé•·æˆ–è¼¸å‡ºéŒ¯äº‚ã€‚",
            "ä¸€æ¬¡åªèƒ½ä¸Šä¼  1 ä»½å‚è€ƒæ–‡ä»¶ã€‚ç¬¬ä¸€æ¬¡åˆ†æå¯ä¸Šä¼  1 ä»½ï¼›åˆ†æå®Œæˆåï¼Œå¯å†ä¸Šä¼ ç¬¬ 2 ä»½ï¼ˆä¾æ­¤ç±»æ¨ï¼‰ï¼Œé¿å…åˆ†ææ—¶é—´è¿‡é•¿æˆ–è¾“å‡ºé”™ä¹±ã€‚",
        )
        if lang == "zh"
        else "You can upload only 1 reference document at a time. Upload 1 for the first analysis; after analysis completes, you may upload the 2nd (and so on) to avoid long runtimes or confused outputs."
    )

    if "reference_history" not in st.session_state:
        st.session_state.reference_history = []
    if "ref_pending" not in st.session_state:
        st.session_state.ref_pending = False

    if st.session_state.reference_history:
        st.markdown("**" + (zh("å·²ä¸Šå‚³åƒè€ƒæ–‡ä»¶ç´€éŒ„ï¼š", "å·²ä¸Šä¼ å‚è€ƒæ–‡ä»¶è®°å½•ï¼š") if lang == "zh" else "Reference documents uploaded:") + "**")
        for i, r in enumerate(st.session_state.reference_history, start=1):
            fname = r.get("name", f"ref_{i}")
            ext = r.get("ext", "").upper()
            st.markdown(f"- {i}. {fname}" + (f" ({ext})" if ext else ""))

    ref_disabled = bool(st.session_state.ref_pending)
    ref_uploader_key = f"ref_uploader_{len(st.session_state.reference_history)}"
    reference_file = st.file_uploader(
        zh("ä¸Šå‚³åƒè€ƒæ–‡ä»¶ï¼ˆPDF / DOCX / TXT / åœ–ç‰‡ï¼‰", "ä¸Šä¼ å‚è€ƒæ–‡ä»¶ï¼ˆPDF / DOCX / TXT / å›¾ç‰‡ï¼‰") if lang == "zh" else "Upload reference document (PDF / DOCX / TXT / Image)",
        type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
        key=ref_uploader_key,
        disabled=ref_disabled,
    )

    if ref_disabled:
        st.info(
            zh("å·²ä¸Šå‚³ 1 ä»½åƒè€ƒæ–‡ä»¶ï¼Œè«‹å…ˆå®Œæˆä¸€æ¬¡åˆ†æå¾Œå†ä¸Šå‚³ä¸‹ä¸€ä»½ã€‚", "å·²ä¸Šä¼  1 ä»½å‚è€ƒæ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆä¸€æ¬¡åˆ†æåå†ä¸Šä¼ ä¸‹ä¸€ä»½ã€‚")
            if lang == "zh"
            else "A reference document has been uploaded. Please run analysis once before uploading the next reference."
        )

    if reference_file is not None and not ref_disabled:
        ref_text = read_file_to_text(reference_file)
        if ref_text:
            name = reference_file.name
            ext = Path(name).suffix.lstrip(".")
            st.session_state.reference_history.append(
                {"name": name, "ext": ext, "text": ref_text, "uploaded_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
            )
            st.session_state.ref_pending = True
            save_state_to_disk()
            st.rerun()

    # Step 4: select framework
    st.subheader(zh("æ­¥é©Ÿå››ï¼šé¸æ“‡åˆ†ææ¡†æ¶ï¼ˆåƒ…å–®é¸ï¼‰", "æ­¥éª¤å››ï¼šé€‰æ‹©åˆ†ææ¡†æ¶ï¼ˆä»…å•é€‰ï¼‰") if lang == "zh" else "Step 4: Select Framework")
    st.caption(
        zh(
            "åƒ…å–®é¸ã€‚å¦‚éœ€åˆ†æä¸‹ä¸€å€‹ Frameworkï¼Œå»ºè­°å…ˆ Reset documentï¼ˆä¸€æ¬¡åˆ†æä¸€å€‹ Frameworkï¼‰ï¼Œé¿å…åˆ†ææ™‚é–“éé•·æˆ–è¼¸å‡ºéŒ¯äº‚ã€‚",
            "ä»…å•é€‰ã€‚å¦‚éœ€åˆ†æä¸‹ä¸€ä¸ª Frameworkï¼Œå»ºè®®å…ˆ Reset documentï¼ˆä¸€æ¬¡åˆ†æä¸€ä¸ª Frameworkï¼‰ï¼Œé¿å…åˆ†ææ—¶é—´è¿‡é•¿æˆ–è¾“å‡ºé”™ä¹±ã€‚",
        )
        if lang == "zh"
        else "Single selection only. To analyze the next framework, it is recommended to Reset document (one framework per run) to avoid long runtimes or confused outputs."
    )

    if not FRAMEWORKS:
        st.error(zh("å°šæœªåœ¨ frameworks.json ä¸­å®šç¾©ä»»ä½•æ¡†æ¶ã€‚", "å°šæœªåœ¨ frameworks.json ä¸­å®šä¹‰ä»»ä½•æ¡†æ¶ã€‚") if lang == "zh" else "No frameworks defined in frameworks.json.")
        return

    fw_keys = list(FRAMEWORKS.keys())
    fw_labels = [FRAMEWORKS[k]["name_zh"] if lang == "zh" else FRAMEWORKS[k]["name_en"] for k in fw_keys]
    key_to_label = dict(zip(fw_keys, fw_labels))
    label_to_key = dict(zip(fw_labels, fw_keys))

    current_fw_key = st.session_state.selected_framework_key or fw_keys[0]
    current_label = key_to_label.get(current_fw_key, fw_labels[0])

    selected_label = st.selectbox(
        zh("é¸æ“‡æ¡†æ¶", "é€‰æ‹©æ¡†æ¶") if lang == "zh" else "Select framework",
        fw_labels,
        index=fw_labels.index(current_label) if current_label in fw_labels else 0,
        key="framework_selectbox",
    )
    selected_key = label_to_key[selected_label]
    st.session_state.selected_framework_key = selected_key

    framework_states = st.session_state.framework_states
    if selected_key not in framework_states:
        framework_states[selected_key] = {
            "analysis_done": False,
            "analysis_output": "",
            "followup_history": [],
            "download_used": False,
            # New staged outputs:
            "step5_done": False,
            "step5_output": "",
            "step6_done": False,
            "step6_output": "",
            "step7_done": False,
            "step7_output": "",
        }
    else:
        # Backward compatibility for existing saved sessions
        state = framework_states[selected_key]
        for k, v in [
            ("step5_done", False),
            ("step5_output", ""),
            ("step6_done", False),
            ("step6_output", ""),
            ("step7_done", False),
            ("step7_output", ""),
        ]:
            if k not in state:
                state[k] = v

    save_state_to_disk()
    current_state = framework_states[selected_key]

    st.markdown("---")

    # =========================
    # Step 5 / 6 / 7 (always visible)
    # =========================

    st.subheader(zh("æ­¥é©Ÿäº”ï¼šå…ˆåˆ†æä¸»è¦æ–‡ä»¶ï¼ˆå¿«é€Ÿï¼‰", "æ­¥éª¤äº”ï¼šå…ˆåˆ†æä¸»è¦æ–‡ä»¶ï¼ˆå¿«é€Ÿï¼‰") if lang == "zh" else "Step 5: Analyze MAIN document first (fast)")
    st.caption(
        zh(
            "æ­¤æ­¥é©Ÿåªåˆ†æä¸»è¦æ–‡ä»¶ï¼Œä¸è™•ç†åƒè€ƒæ–‡ä»¶ï¼Œå…ˆå¿«é€Ÿç”¢ç”Ÿç¬¬ä¸€ä»½åˆ†æçµæœã€‚",
            "æ­¤æ­¥éª¤åªåˆ†æä¸»è¦æ–‡ä»¶ï¼Œä¸å¤„ç†å‚è€ƒæ–‡ä»¶ï¼Œå…ˆå¿«é€Ÿäº§ç”Ÿç¬¬ä¸€ä»½åˆ†æç»“æœã€‚",
        )
        if lang == "zh"
        else "This step analyzes ONLY the main document (no references) to produce a fast first result."
    )

    step5_can_run = (not current_state.get("step5_done", False))

    run_step5 = st.button(
        zh("Run analysisï¼ˆä¸»æ–‡ä»¶ï¼‰", "Run analysisï¼ˆä¸»æ–‡ä»¶ï¼‰") if lang == "zh" else "Run analysis (main only)",
        key="run_step5_btn",
        disabled=not step5_can_run,
    )

    # Reset button unchanged
    if not is_guest:
        if st.button(zh("é‡ç½®ï¼ˆæ–°æ–‡ä»¶ï¼‰", "é‡ç½®ï¼ˆæ–°æ–‡ä»¶ï¼‰") if lang == "zh" else "Reset document", key="reset_doc_btn"):
            st.session_state.framework_states = {}
            st.session_state.last_doc_text = ""
            st.session_state.last_doc_name = ""
            st.session_state.document_type = None
            st.session_state.reference_history = []
            st.session_state.ref_pending = False
            st.session_state.current_doc_id = None
            save_state_to_disk()
            st.rerun()

    if run_step5:
        if not st.session_state.last_doc_text:
            st.error(zh("è«‹å…ˆä¸Šå‚³å¯©é–±æ–‡ä»¶ï¼ˆStep 1ï¼‰", "è¯·å…ˆä¸Šä¼ å®¡é˜…æ–‡ä»¶ï¼ˆStep 1ï¼‰") if lang == "zh" else "Please upload a review document first (Step 1).")
        elif not st.session_state.get("document_type"):
            st.error(zh("è«‹å…ˆé¸æ“‡æ–‡ä»¶é¡å‹ï¼ˆStep 2ï¼‰", "è¯·å…ˆé€‰æ‹©æ–‡ä»¶ç±»å‹ï¼ˆStep 2ï¼‰") if lang == "zh" else "Please select a document type first (Step 2).")
        else:
            with st.spinner(zh("åˆ†æä¸­...ï¼ˆåƒ…ä¸»æ–‡ä»¶ï¼‰", "åˆ†æä¸­...ï¼ˆä»…ä¸»æ–‡ä»¶ï¼‰") if lang == "zh" else "Analyzing... (main only)"):
                # Step5: framework analysis on main-only (fast path)
                main_analysis_text = run_llm_analysis(
                    selected_key,
                    lang,
                    st.session_state.last_doc_text,
                    model_name,
                ) or ""
            current_state["step5_done"] = True
            current_state["step5_output"] = clean_report_text(main_analysis_text)
            save_state_to_disk()
            record_usage(user_email, selected_key, "analysis")
            st.success(zh("æ­¥é©Ÿäº”å®Œæˆï¼å·²ç”¢å‡ºä¸»æ–‡ä»¶ç¬¬ä¸€ä»½åˆ†æã€‚", "æ­¥éª¤äº”å®Œæˆï¼å·²äº§å‡ºä¸»æ–‡ä»¶ç¬¬ä¸€ä»½åˆ†æã€‚") if lang == "zh" else "Step 5 completed. Main analysis generated.")

    st.markdown("---")

    # Step 6 appears only if references exist (and step5 done)
    has_refs = bool(st.session_state.reference_history)
    step5_done = bool(current_state.get("step5_done", False))

    st.subheader(zh("æ­¥é©Ÿå…­ï¼šåƒè€ƒæ–‡ä»¶ç›¸é—œæ€§åˆ†æï¼ˆæœ‰ä¸Šå‚³åƒè€ƒæ–‡ä»¶æ‰æœƒå•Ÿç”¨ï¼‰", "æ­¥éª¤å…­ï¼šå‚è€ƒæ–‡ä»¶ç›¸å…³æ€§åˆ†æï¼ˆæœ‰ä¸Šä¼ å‚è€ƒæ–‡ä»¶æ‰ä¼šå¯ç”¨ï¼‰") if lang == "zh" else "Step 6: Reference relevance analysis (enabled only if references uploaded)")
    st.caption(
        zh(
            "åœ¨å·²å®Œæˆæ­¥é©Ÿäº”ä¸”æœ‰åƒè€ƒæ–‡ä»¶æ™‚ï¼ŒæŒ‰ä¸‹ Run analysis ç”¢ç”Ÿã€ç›¸é—œæ€§é‡é»ã€ï¼Œä»¥ä¾¿å¾ŒçºŒæœ€çµ‚æ•´åˆã€‚",
            "åœ¨å·²å®Œæˆæ­¥éª¤äº”ä¸”æœ‰å‚è€ƒæ–‡ä»¶æ—¶ï¼ŒæŒ‰ä¸‹ Run analysis äº§ç”Ÿâ€œç›¸å…³æ€§é‡ç‚¹â€ï¼Œä»¥ä¾¿åç»­æœ€ç»ˆæ•´åˆã€‚",
        )
        if lang == "zh"
        else "After Step 5, if references exist, click Run analysis to extract relevance key points for final integration."
    )

    step6_can_run = (step5_done and has_refs and (not current_state.get("step6_done", False)))
    run_step6 = st.button(
        zh("Run analysisï¼ˆç›¸é—œæ€§ï¼‰", "Run analysisï¼ˆç›¸å…³æ€§ï¼‰") if lang == "zh" else "Run analysis (relevance)",
        key="run_step6_btn",
        disabled=not step6_can_run,
    )

    if run_step6:
        with st.spinner(zh("åˆ†æä¸­...ï¼ˆç›¸é—œæ€§é‡é»æå–ï¼‰", "åˆ†æä¸­...ï¼ˆç›¸å…³æ€§é‡ç‚¹æå–ï¼‰") if lang == "zh" else "Analyzing... (extracting relevance points)"):
            # Summarize references first (token control)
            ref_summaries = []
            for r in st.session_state.reference_history:
                summary = summarize_reference_text(lang, r.get("name", "reference"), r.get("text", "") or "", model_name)
                ref_summaries.append({"name": r.get("name", "reference"), "summary": summary})

            relevance_file_text = build_relevance_file(
                lang,
                selected_key,
                st.session_state.document_type,
                current_state.get("step5_output", ""),
                ref_summaries,
            )
            relevance_points = derive_relevance_points(lang, relevance_file_text, model_name)

        current_state["step6_done"] = True
        current_state["step6_output"] = clean_report_text(relevance_points)
        save_state_to_disk()
        st.success(zh("æ­¥é©Ÿå…­å®Œæˆï¼å·²ç”¢å‡ºåƒè€ƒæ–‡ä»¶ç›¸é—œæ€§é‡é»ã€‚", "æ­¥éª¤å…­å®Œæˆï¼å·²äº§å‡ºå‚è€ƒæ–‡ä»¶ç›¸å…³æ€§é‡ç‚¹ã€‚") if lang == "zh" else "Step 6 completed. Relevance key points generated.")

    st.markdown("---")

    # Step 7 final integration (requires step5; if refs exist then step6 required)
    st.subheader(zh("æ­¥é©Ÿä¸ƒï¼šæœ€çµ‚æ•´åˆï¼ˆRun final analysisï¼‰", "æ­¥éª¤ä¸ƒï¼šæœ€ç»ˆæ•´åˆï¼ˆRun final analysisï¼‰") if lang == "zh" else "Step 7: Final integration (Run final analysis)")
    st.caption(
        zh(
            "ç”¨é›¶éŒ¯èª¤æ¡†æ¶æ•´åˆï¼šæ­¥é©Ÿäº”ï¼ˆä¸»æ–‡ä»¶åˆ†æï¼‰èˆ‡æ­¥é©Ÿå…­ï¼ˆç›¸é—œæ€§é‡é»ï¼‰ã€‚è‹¥æœªä¸Šå‚³åƒè€ƒæ–‡ä»¶ï¼Œå‰‡åªæ•´åˆæ­¥é©Ÿäº”ä¸¦è¼¸å‡ºæœ€çµ‚ç‰ˆæœ¬ã€‚",
            "ç”¨é›¶é”™è¯¯æ¡†æ¶æ•´åˆï¼šæ­¥éª¤äº”ï¼ˆä¸»æ–‡ä»¶åˆ†æï¼‰ä¸æ­¥éª¤å…­ï¼ˆç›¸å…³æ€§é‡ç‚¹ï¼‰ã€‚è‹¥æœªä¸Šä¼ å‚è€ƒæ–‡ä»¶ï¼Œåˆ™åªæ•´åˆæ­¥éª¤äº”å¹¶è¾“å‡ºæœ€ç»ˆç‰ˆæœ¬ã€‚",
        )
        if lang == "zh"
        else "Integrate Step 5 (main analysis) and Step 6 (relevance points) under the same framework. If no references, finalize using Step 5 only."
    )

    step6_done = bool(current_state.get("step6_done", False))
    step7_need_step6 = has_refs  # If references exist, require step6 first
    step7_can_run = (
        step5_done
        and (not current_state.get("step7_done", False))
        and ((not step7_need_step6) or step6_done)
    )

    run_step7 = st.button(
        zh("Run final analysisï¼ˆæœ€çµ‚æ•´åˆï¼‰", "Run final analysisï¼ˆæœ€ç»ˆæ•´åˆï¼‰") if lang == "zh" else "Run final analysis (final integration)",
        key="run_step7_btn",
        disabled=not step7_can_run,
    )

    if run_step7:
        with st.spinner(zh("åˆ†æä¸­...ï¼ˆæœ€çµ‚æ•´åˆï¼‰", "åˆ†æä¸­...ï¼ˆæœ€ç»ˆæ•´åˆï¼‰") if lang == "zh" else "Analyzing... (final integration)"):
            if has_refs and step6_done:
                final_input = build_final_integration_input(
                    lang,
                    st.session_state.document_type,
                    selected_key,
                    current_state.get("step5_output", ""),
                    current_state.get("step6_output", ""),
                )
            else:
                # No references: finalize based on step5 only, but keep final form.
                if lang == "zh":
                    final_input = "\n".join(
                        [
                            "ã€æœ€çµ‚æ•´åˆåˆ†æè¼¸å…¥ï¼ˆæ­¥é©Ÿä¸ƒï¼‰ã€‘",
                            f"- æ–‡ä»¶é¡å‹ï¼š{st.session_state.document_type or 'ï¼ˆæœªé¸æ“‡ï¼‰'}",
                            "",
                            "==============================",
                            "ä¸€ã€æ­¥é©Ÿäº”ï¼šä¸»æ–‡ä»¶é›¶éŒ¯èª¤æ¡†æ¶åˆ†æçµæœ",
                            "==============================",
                            current_state.get("step5_output", ""),
                            "",
                            "ã€ä»»å‹™ã€‘",
                            "è«‹ä½ ç”¨åŒä¸€å€‹é›¶éŒ¯èª¤æ¡†æ¶ï¼Œå°‡ä¸Šè¿°å…§å®¹æ•´ç†æˆã€æœ€çµ‚æˆå“åˆ†æå ±å‘Šã€ï¼šå»é‡ã€è£œå¼·ã€ä¸¦æä¾›å¯åŸ·è¡Œçš„ä¿®æ­£/æ¾„æ¸…å•é¡Œæ¸…å–®ã€‚",
                        ]
                    )
                else:
                    final_input = "\n".join(
                        [
                            "[Final Integration Input (Step 7)]",
                            f"- Document type: {st.session_state.document_type or '(not selected)'}",
                            "",
                            "==============================",
                            "1) Step 5: Main document framework analysis",
                            "==============================",
                            current_state.get("step5_output", ""),
                            "",
                            "[Task]",
                            "Using the same framework, rewrite the above into a FINAL deliverable report: dedupe, strengthen, and provide actionable fixes / clarification questions.",
                        ]
                    )

            final_output = run_llm_analysis(selected_key, lang, final_input, model_name) or ""

        current_state["step7_done"] = True
        current_state["step7_output"] = clean_report_text(final_output)

        # Build the final product (single analysis_output) for download + follow-ups
        if lang == "zh":
            prefix_lines = [
                "### åˆ†æç´€éŒ„ï¼ˆå¿…è®€ï¼‰",
                f"- æ–‡ä»¶é¡å‹ï¼ˆDocument Typeï¼‰ï¼š{st.session_state.document_type}",
                f"- æ¡†æ¶ï¼ˆFrameworkï¼‰ï¼š{FRAMEWORKS.get(selected_key, {}).get('name_zh', selected_key)}",
            ]
            if st.session_state.reference_history:
                prefix_lines.append("- åƒè€ƒæ–‡ä»¶ï¼ˆReference Documentsï¼‰ä¸Šå‚³ç´€éŒ„ï¼š")
                for i, r in enumerate(st.session_state.reference_history, start=1):
                    fname = r.get("name", f"ref_{i}")
                    ext = r.get("ext", "").upper()
                    prefix_lines.append(f"  {i}. {fname}" + (f" ({ext})" if ext else ""))
            else:
                prefix_lines.append("- åƒè€ƒæ–‡ä»¶ï¼ˆReference Documentsï¼‰ï¼šï¼ˆæœªä¸Šå‚³ï¼‰")
            prefix = "\n".join(prefix_lines) + "\n\n"

            combined_sections = [
                "==============================",
                "ï¼ˆæ­¥é©Ÿäº”ï¼‰ä¸»æ–‡ä»¶åˆ†æçµæœ",
                "==============================",
                current_state.get("step5_output", ""),
            ]
            if has_refs:
                combined_sections += [
                    "",
                    "==============================",
                    "ï¼ˆæ­¥é©Ÿå…­ï¼‰åƒè€ƒæ–‡ä»¶ç›¸é—œæ€§é‡é»",
                    "==============================",
                    current_state.get("step6_output", "") if current_state.get("step6_done") else "ï¼ˆå°šæœªåŸ·è¡Œæ­¥é©Ÿå…­ï¼‰",
                ]
            combined_sections += [
                "",
                "==============================",
                "ï¼ˆæ­¥é©Ÿä¸ƒï¼‰æœ€çµ‚æ•´åˆæˆå“",
                "==============================",
                current_state.get("step7_output", ""),
            ]
        else:
            prefix_lines = [
                "### Analysis Record",
                f"- Document Type: {st.session_state.document_type}",
                f"- Framework: {FRAMEWORKS.get(selected_key, {}).get('name_en', selected_key)}",
            ]
            if st.session_state.reference_history:
                prefix_lines.append("- Reference documents upload log:")
                for i, r in enumerate(st.session_state.reference_history, start=1):
                    fname = r.get("name", f"ref_{i}")
                    ext = r.get("ext", "").upper()
                    prefix_lines.append(f"  {i}. {fname}" + (f" ({ext})" if ext else ""))
            else:
                prefix_lines.append("- Reference documents: (none)")
            prefix = "\n".join(prefix_lines) + "\n\n"

            combined_sections = [
                "==============================",
                "(Step 5) Main analysis result",
                "==============================",
                current_state.get("step5_output", ""),
            ]
            if has_refs:
                combined_sections += [
                    "",
                    "==============================",
                    "(Step 6) Relevance key points",
                    "==============================",
                    current_state.get("step6_output", "") if current_state.get("step6_done") else "(Step 6 not run yet)",
                ]
            combined_sections += [
                "",
                "==============================",
                "(Step 7) Final integrated deliverable",
                "==============================",
                current_state.get("step7_output", ""),
            ]

        current_state["analysis_done"] = True
        current_state["analysis_output"] = clean_report_text(prefix + "\n".join(combined_sections))
        save_state_to_disk()
        st.session_state.ref_pending = False
        save_state_to_disk()
        st.success(zh("æ­¥é©Ÿä¸ƒå®Œæˆï¼å·²ç”¢å‡ºæœ€çµ‚æˆå“ã€‚", "æ­¥éª¤ä¸ƒå®Œæˆï¼å·²äº§å‡ºæœ€ç»ˆæˆå“ã€‚") if lang == "zh" else "Step 7 completed. Final deliverable generated.")

    # =========================
    # Results area (AFTER Step 7) â€” keep all together, ordered, no interleaving
    # =========================
    st.markdown("---")
    st.subheader(zh("åˆ†æçµæœï¼ˆä¾æ­¥é©Ÿæ’åˆ—ï¼‰", "åˆ†æç»“æœï¼ˆä¾æ­¥éª¤æ’åˆ—ï¼‰") if lang == "zh" else "Results (ordered by steps)")

    if current_state.get("step5_done"):
        st.markdown("### " + (zh("æ­¥é©Ÿäº”ï¼šä¸»æ–‡ä»¶åˆ†æçµæœ", "æ­¥éª¤äº”ï¼šä¸»æ–‡ä»¶åˆ†æç»“æœ") if lang == "zh" else "Step 5: Main analysis result"))
        st.markdown(current_state.get("step5_output", ""))

    if has_refs:
        st.markdown("### " + (zh("æ­¥é©Ÿå…­ï¼šç›¸é—œæ€§é‡é»", "æ­¥éª¤å…­ï¼šç›¸å…³æ€§é‡ç‚¹") if lang == "zh" else "Step 6: Relevance key points"))
        if current_state.get("step6_done"):
            st.markdown(current_state.get("step6_output", ""))
        else:
            st.info(zh("å°šæœªåŸ·è¡Œæ­¥é©Ÿå…­ã€‚", "å°šæœªæ‰§è¡Œæ­¥éª¤å…­ã€‚") if lang == "zh" else "Step 6 has not been run yet.")

    st.markdown("### " + (zh("æ­¥é©Ÿä¸ƒï¼šæœ€çµ‚æ•´åˆæˆå“", "æ­¥éª¤ä¸ƒï¼šæœ€ç»ˆæ•´åˆæˆå“") if lang == "zh" else "Step 7: Final deliverable"))
    if current_state.get("step7_done"):
        st.markdown(current_state.get("step7_output", ""))
    else:
        st.info(zh("å°šæœªåŸ·è¡Œæ­¥é©Ÿä¸ƒã€‚", "å°šæœªæ‰§è¡Œæ­¥éª¤ä¸ƒã€‚") if lang == "zh" else "Step 7 has not been run yet.")

    # =========================
    # Download / Q&A / whole report area (kept as original, below results)
    # =========================
    st.markdown("---")
    st.subheader(zh("â­ Analysis result + Download", "â­ Analysis result + Download") if lang == "zh" else "â­ Analysis result + Download")

    # Only show download if we have final analysis_output (analysis_done)
    if current_state.get("analysis_done") and current_state.get("analysis_output"):
        st.markdown("#### " + (zh("åˆ†æçµæœ", "åˆ†æç»“æœ") if lang == "zh" else "Analysis result"))
        st.markdown(current_state["analysis_output"])

        st.markdown("##### " + (zh("ä¸‹è¼‰å ±å‘Š", "ä¸‹è½½æŠ¥å‘Š") if lang == "zh" else "Download report"))
        st.caption(zh("å ±å‘ŠåªåŒ…å«åˆ†æèˆ‡ Q&Aï¼Œä¸å«åŸå§‹æ–‡ä»¶ã€‚", "æŠ¥å‘ŠåªåŒ…å«åˆ†æä¸ Q&Aï¼Œä¸å«åŸå§‹æ–‡ä»¶ã€‚") if lang == "zh" else "Report includes analysis + Q&A only (no original document).")

        if is_guest and current_state.get("download_used"):
            st.error(zh("å·²é”ä¸‹è¼‰æ¬¡æ•¸ä¸Šé™ï¼ˆ1 æ¬¡ï¼‰", "å·²è¾¾ä¸‹è½½æ¬¡æ•°ä¸Šé™ï¼ˆ1 æ¬¡ï¼‰") if lang == "zh" else "Download limit reached (1 time).")
        else:
            report = build_full_report(lang, selected_key, current_state)
            now_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

            with st.expander("Download"):
                fmt = st.radio(
                    zh("é¸æ“‡æ ¼å¼", "é€‰æ‹©æ ¼å¼") if lang == "zh" else "Select format",
                    ["Word (DOCX)", "PDF", "PowerPoint (PPTX)"],
                    key=f"fmt_{selected_key}",
                )

                data: bytes
                mime: str
                ext: str

                if fmt.startswith("Word"):
                    data = build_docx_bytes(report)
                    mime = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    ext = "docx"
                elif fmt.startswith("PDF"):
                    data = build_pdf_bytes(report)
                    mime = "application/pdf"
                    ext = "pdf"
                else:
                    try:
                        data = build_pptx_bytes(report)
                        mime = "application/vnd.openxmlformats-officedocument.presentationml.presentation"
                        ext = "pptx"
                    except Exception as e:
                        st.error((zh(f"PPTX åŒ¯å‡ºå¤±æ•—ï¼š{e}", f"PPTX å¯¼å‡ºå¤±è´¥ï¼š{e}") if lang == "zh" else f"PPTX export failed: {e}"))
                        data = b""
                        mime = "application/octet-stream"
                        ext = "pptx"

                if data:
                    clicked = st.download_button(
                        zh("é–‹å§‹ä¸‹è¼‰", "å¼€å§‹ä¸‹è½½") if lang == "zh" else "Download",
                        data=data,
                        file_name=f"errorfree_{selected_key}_{now_str}.{ext}",
                        mime=mime,
                        key=f"dl_{selected_key}_{ext}",
                    )
                    if clicked:
                        current_state["download_used"] = True
                        save_state_to_disk()
                        record_usage(user_email, selected_key, "download")
    else:
        st.info(zh("å°šæœªå®Œæˆæœ€çµ‚æ•´åˆï¼ˆæ­¥é©Ÿä¸ƒï¼‰ã€‚å®Œæˆå¾Œæ‰èƒ½ä¸‹è¼‰å®Œæ•´å ±å‘Šã€‚", "å°šæœªå®Œæˆæœ€ç»ˆæ•´åˆï¼ˆæ­¥éª¤ä¸ƒï¼‰ã€‚å®Œæˆåæ‰èƒ½ä¸‹è½½å®Œæ•´æŠ¥å‘Šã€‚") if lang == "zh" else "Final integration (Step 7) not completed yet. Complete it to enable full report download.")

    # Follow-up/Q&A (unchanged behavior, but only meaningful after final analysis exists)
    st.markdown("---")
    st.subheader(zh("å¾ŒçºŒæå•", "åç»­æé—®") if lang == "zh" else "Follow-up questions")

    if not current_state.get("analysis_output"):
        st.info(zh("è«‹å…ˆå®Œæˆæ­¥é©Ÿä¸ƒï¼Œç”¢å‡ºæœ€çµ‚æˆå“å¾Œå†é€²è¡Œè¿½å•ã€‚", "è¯·å…ˆå®Œæˆæ­¥éª¤ä¸ƒï¼Œäº§å‡ºæœ€ç»ˆæˆå“åå†è¿›è¡Œè¿½é—®ã€‚") if lang == "zh" else "Please complete Step 7 (final deliverable) before asking follow-up questions.")
    else:
        if is_guest and len(current_state.get("followup_history", [])) >= 3:
            st.error(zh("å·²é”è¿½å•ä¸Šé™ï¼ˆ3 æ¬¡ï¼‰", "å·²è¾¾è¿½é—®ä¸Šé™ï¼ˆ3 æ¬¡ï¼‰") if lang == "zh" else "Follow-up limit reached (3 times).")
        else:
            col_text, col_file = st.columns([3, 1])
            followup_key = f"followup_input_{selected_key}"

            with col_text:
                prompt_label = (f"{zh('é‡å°', 'é’ˆå¯¹')} {FRAMEWORKS[selected_key]['name_zh']} {zh('çš„è¿½å•', 'çš„è¿½é—®')}" if lang == "zh" else "Ask Error-FreeÂ® Intelligence Engine a follow-up?")
                prompt = st.text_area(prompt_label, key=followup_key, height=150)

            with col_file:
                extra_file = st.file_uploader(
                    zh("ğŸ“ ä¸Šå‚³åœ–ç‰‡/æ–‡ä»¶ï¼ˆé¸å¡«ï¼‰", "ğŸ“ ä¸Šä¼ å›¾ç‰‡/æ–‡ä»¶ï¼ˆé€‰å¡«ï¼‰") if lang == "zh" else "ğŸ“ Attach image/document (optional)",
                    type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
                    key=f"extra_{selected_key}",
                )
            extra_text = read_file_to_text(extra_file) if extra_file else ""

            if st.button(zh("é€å‡ºè¿½å•", "é€å‡ºè¿½é—®") if lang == "zh" else "Send follow-up", key=f"followup_btn_{selected_key}"):
                if prompt and prompt.strip():
                    with st.spinner(zh("æ€è€ƒä¸­...", "æ€è€ƒä¸­...") if lang == "zh" else "Thinking..."):
                        answer = run_followup_qa(
                            selected_key,
                            lang,
                            st.session_state.last_doc_text or "",
                            current_state.get("analysis_output", ""),
                            prompt,
                            model_name,
                            extra_text,
                        )
                    current_state["followup_history"].append((prompt, clean_report_text(answer)))
                    save_state_to_disk()
                    record_usage(user_email, selected_key, "followup")
                    st.rerun()

    save_state_to_disk()


if __name__ == "__main__":
    main()
