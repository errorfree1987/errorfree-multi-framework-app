import streamlit as st

# ===== Error-FreeÂ® Portal SSO (DEMO) =====
# ç›®çš„ï¼šå¾ Portal é€²ä¾†ä¸”å¸¶ portal_tokenï¼Œå°±ç›´æ¥æ”¾è¡Œï¼Œä¸é¡¯ç¤º Analyzer å…§å»ºç™»å…¥ã€‚
# æ³¨æ„ï¼šé€™æ˜¯ã€Œå‡ tokenã€æµç¨‹é©—è­‰ï¼›ä¸‹ä¸€æ­¥æœƒæ›æˆçœŸæ­£ä¸€æ¬¡æ€§ / å¯é©—è­‰ tokenã€‚
DEMO_EXPECTED_TOKEN = "demo-from-portal"

# è®€å–ç¶²å€åƒæ•¸ï¼ˆç›¸å®¹æ–°èˆŠ Streamlitï¼‰
try:
    qp = st.query_params
    portal_token = qp.get("portal_token", "")
    email = qp.get("email", "")
except Exception:
    qp = st.experimental_get_query_params()
    portal_token = qp.get("portal_token", [""])[0]
    email = qp.get("email", [""])[0]

# session_stateï¼šé¿å…æ¯æ¬¡äº’å‹•éƒ½é‡è·‘é©—è­‰
if "portal_authed" not in st.session_state:
    st.session_state["portal_authed"] = False

if not st.session_state["portal_authed"]:
    if portal_token == DEMO_EXPECTED_TOKEN:
        st.session_state["portal_authed"] = True
        st.session_state["portal_email"] = email or "unknown"
    else:
        st.error("è«‹å¾ Error-FreeÂ® Portal é€²å…¥æ­¤åˆ†ææ¡†æ¶ã€‚")
        st.stop()

with st.sidebar:
    st.caption("Portal SSO (DEMO)")
    st.write(f"Email: {st.session_state.get('portal_email', 'unknown')}")
# ===== End Portal SSO (DEMO) =====
import os, json, datetime, secrets

from pathlib import Path

from typing import Dict, List, Optional

from io import BytesIO

import base64



import streamlit as st

import streamlit.components.v1 as components

import pdfplumber

from docx import Document

from openai import OpenAI

from reportlab.pdfgen import canvas

from reportlab.lib.pagesizes import letter

from reportlab.pdfbase import pdfmetrics

from reportlab.pdfbase.ttfonts import TTFont

from reportlab.pdfbase.cidfonts import UnicodeCIDFont





PDF_FONT_NAME = "Helvetica"

PDF_FONT_REGISTERED = False

PDF_TTF_PATH = os.getenv("PDF_TTF_PATH")  # Optional: path to a Unicode TTF font for PDF export





def ensure_pdf_font():
    """Register a Unicode-capable font for PDF export to avoid black boxes / garbled text."""
    global PDF_FONT_NAME, PDF_FONT_REGISTERED
    if PDF_FONT_REGISTERED:
        return

    try:
        try:
            pdfmetrics.registerFont(UnicodeCIDFont("STSong-Light"))
            PDF_FONT_NAME = "STSong-Light"
        except Exception:
            if PDF_TTF_PATH and Path(PDF_TTF_PATH).exists():
                pdfmetrics.registerFont(TTFont("ErrorFreeUnicode", PDF_TTF_PATH))
                PDF_FONT_NAME = "ErrorFreeUnicode"
            else:
                PDF_FONT_NAME = "Helvetica"
    except Exception:
        PDF_FONT_NAME = "Helvetica"
    finally:
        PDF_FONT_REGISTERED = True





# =========================
# Company multi-tenant support
# =========================

COMPANY_FILE = Path("companies.json")


def load_companies() -> dict:
    if not COMPANY_FILE.exists():
        return {}
    try:
        return json.loads(COMPANY_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


def save_companies(data: dict):
    try:
        COMPANY_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception:
        pass





# =========================
# Accounts
# =========================

ACCOUNTS = {
    "admin@errorfree.com": {"password": "1111", "role": "admin"},
    "dr.chiu@errorfree.com": {"password": "2222", "role": "pro"},
    "test@errorfree.com": {"password": "3333", "role": "pro"},
}

GUEST_FILE = Path("guest_accounts.json")


def load_guest_accounts() -> Dict[str, Dict]:
    if not GUEST_FILE.exists():
        return {}
    try:
        return json.loads(GUEST_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


def save_guest_accounts(data: Dict[str, Dict]):
    try:
        GUEST_FILE.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
    except Exception:
        pass





# =========================
# Framework definitions (external JSON)
# =========================

FRAMEWORK_FILE = Path("frameworks.json")


def load_frameworks() -> Dict[str, Dict]:
    """Load framework definitions from an external JSON file."""
    if not FRAMEWORK_FILE.exists():
        return {}
    try:
        return json.loads(FRAMEWORK_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


FRAMEWORKS: Dict[str, Dict] = load_frameworks()



# =========================
# State persistence & usage tracking (4A)
# =========================

STATE_FILE = Path("user_state.json")
DOC_TRACK_FILE = Path("user_docs.json")
USAGE_FILE = Path("usage_stats.json")  # ä½¿ç”¨é‡çµ±è¨ˆ


def load_doc_tracking() -> Dict[str, List[str]]:
    if not DOC_TRACK_FILE.exists():
        return {}
    try:
        return json.loads(DOC_TRACK_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


def save_doc_tracking(data: Dict[str, List[str]]):
    try:
        DOC_TRACK_FILE.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
    except Exception:
        pass


def load_usage_stats() -> Dict[str, Dict]:
    if not USAGE_FILE.exists():
        return {}
    try:
        return json.loads(USAGE_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {}


def save_usage_stats(data: Dict[str, Dict]):
    try:
        USAGE_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception:
        pass


def record_usage(user_email: str, framework_key: str, kind: str):
    """
    kind: 'analysis', 'followup', 'download'
    """
    if not user_email:
        return
    data = load_usage_stats()
    user_entry = data.get(user_email, {})
    fw_map = user_entry.get("frameworks", {})
    fw_entry = fw_map.get(
        framework_key,
        {
            "analysis_runs": 0,
            "followups": 0,
            "downloads": 0,
        },
    )
    if kind == "analysis":
        fw_entry["analysis_runs"] = fw_entry.get("analysis_runs", 0) + 1
    elif kind == "followup":
        fw_entry["followups"] = fw_entry.get("followups", 0) + 1
    elif kind == "download":
        fw_entry["downloads"] = fw_entry.get("downloads", 0) + 1

    fw_map[framework_key] = fw_entry
    user_entry["frameworks"] = fw_map
    user_entry["last_used"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    data[user_email] = user_entry
    save_usage_stats(data)


def save_state_to_disk():
    data = {
        "user_email": st.session_state.get("user_email"),
        "user_role": st.session_state.get("user_role"),
        "is_authenticated": st.session_state.get("is_authenticated", False),
        "lang": st.session_state.get("lang", "zh"),
        "zh_variant": st.session_state.get("zh_variant", "tw"),
        "usage_date": st.session_state.get("usage_date"),
        "usage_count": st.session_state.get("usage_count", 0),
        "last_doc_text": st.session_state.get("last_doc_text", ""),
        "last_doc_name": st.session_state.get("last_doc_name", ""),
        "document_type": st.session_state.get("document_type"),
        "framework_states": st.session_state.get("framework_states", {}),
        "selected_framework_key": st.session_state.get("selected_framework_key"),
        "current_doc_id": st.session_state.get("current_doc_id"),
        "company_code": st.session_state.get("company_code"),
        "show_admin": st.session_state.get("show_admin", False),

        # Step 3 split references (æ›´æ­£2)
        "upstream_reference": st.session_state.get("upstream_reference"),
        "quote_current": st.session_state.get("quote_current"),
        "quote_history": st.session_state.get("quote_history", []),
        "quote_upload_nonce": st.session_state.get("quote_upload_nonce", 0),
            "review_upload_nonce": st.session_state.get("review_upload_nonce", 0),
            "upstream_upload_nonce": st.session_state.get("upstream_upload_nonce", 0),
        "quote_upload_finalized": st.session_state.get("quote_upload_finalized", False),
        "upstream_step6_done": st.session_state.get("upstream_step6_done", False),
        "upstream_step6_output": st.session_state.get("upstream_step6_output", ""),
        "quote_step6_done_current": st.session_state.get("quote_step6_done_current", False),

        # Step 7 history (re-run when new quote refs are analyzed)
        "step7_history": st.session_state.get("step7_history", []),
        "integration_history": st.session_state.get("integration_history", []),

        # Follow-up clear flag (fix StreamlitAPIException)
        "_pending_clear_followup_key": st.session_state.get("_pending_clear_followup_key"),
    }
    try:
        STATE_FILE.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
    except Exception:
        pass


def restore_state_from_disk():
    if not STATE_FILE.exists():
        return
    try:
        data = json.loads(STATE_FILE.read_text(encoding="utf-8"))
    except Exception:
        return
    for k, v in data.items():
        if k not in st.session_state:
            st.session_state[k] = v





# =========================
# OpenAI client & model selection
# =========================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None


def resolve_model_for_user(role: str) -> str:
    if role in ["admin", "pro", "company_admin"]:
        return "gpt-5.1"
    if role == "free":
        return "gpt-4.1-mini"
    return "gpt-5.1"





# =========================
# Language helpers
# =========================

def zh(tw: str, cn: str = None) -> str:
    """Return zh text by variant when lang == 'zh'. Default variant is 'tw'."""
    if st.session_state.get("lang") != "zh":
        return tw
    if st.session_state.get("zh_variant", "tw") == "cn" and cn is not None:
        return cn
    return tw





# =========================
# File reading
# =========================

def ocr_image_to_text(file_bytes: bytes, filename: str) -> str:
    """Use OpenAI vision model to perform OCR on an image and return plain text."""
    if client is None:
        return "[Error] OPENAI_API_KEY å°šæœªè¨­å®šï¼Œç„¡æ³•é€²è¡Œåœ–ç‰‡ OCRã€‚"

    fname = filename.lower()
    img_format = "png" if fname.endswith(".png") else "jpeg"

    role = st.session_state.get("user_role", "free")
    model_name = resolve_model_for_user(role)

    b64_data = base64.b64encode(file_bytes).decode("utf-8")

    lang = st.session_state.get("lang", "zh")
    if lang == "zh":
        prompt = (
            "è«‹å°‡é€™å¼µåœ–ç‰‡ä¸­çš„æ‰€æœ‰å¯è¦‹æ–‡å­—å®Œæ•´è½‰æˆç´”æ–‡å­—ï¼Œ"
            "ä¿æŒåŸæœ¬çš„æ®µè½èˆ‡æ›è¡Œã€‚ä¸è¦åŠ ä¸Šä»»ä½•èªªæ˜æˆ–ç¸½çµï¼Œåªè¼¸å‡ºæ–‡å­—å…§å®¹ã€‚"
        )
    else:
        prompt = (
            "Transcribe all visible text in this image into plain text. "
            "Preserve paragraphs and line breaks. Do not add any commentary or summary."
        )

    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": prompt},
                        {"type": "input_image", "image": {"data": b64_data, "format": img_format}},
                    ],
                }
            ],
            max_output_tokens=2000,
        )
        text_out = response.output_text or ""
        return text_out.strip()
    except Exception as e:
        return f"[åœ–ç‰‡ OCR æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}]"


def read_file_to_text(uploaded_file) -> str:
    if uploaded_file is None:
        return ""
    name = uploaded_file.name.lower()
    try:
        if name.endswith(".pdf"):
            text_pages: List[str] = []
            with pdfplumber.open(uploaded_file) as pdf:
                for page in pdf.pages:
                    t = page.extract_text() or ""
                    text_pages.append(t)
            return "\n".join(text_pages)
        elif name.endswith(".docx"):
            doc = Document(uploaded_file)
            return "\n".join(p.text for p in doc.paragraphs)
        elif name.endswith(".txt"):
            return uploaded_file.read().decode("utf-8", errors="ignore")
        elif name.endswith((".jpg", ".jpeg", ".png")):
            file_bytes = uploaded_file.read()
            if not file_bytes:
                return "[è®€å–åœ–ç‰‡æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼šç©ºæª”æ¡ˆ]"
            return ocr_image_to_text(file_bytes, uploaded_file.name)
        else:
            return ""
    except Exception as e:
        return f"[è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}]"





# =========================
# Core LLM logic (keep wrapper as-is)
# =========================

def run_llm_analysis(framework_key: str, language: str, document_text: str, model_name: str) -> str:
    # Diagnostics (do not leak key)
    st.session_state["_ef_last_openai_error"] = ""
    st.session_state["_ef_last_openai_error_type"] = ""

    if framework_key not in FRAMEWORKS:
        return f"[Error] Framework '{framework_key}' not found in frameworks.json."

    fw = FRAMEWORKS[framework_key]
    system_prompt = fw["wrapper_zh"] if language == "zh" else fw["wrapper_en"]
    prefix = "ä»¥ä¸‹æ˜¯è¦åˆ†æçš„æ–‡ä»¶å…§å®¹ï¼š\n\n" if language == "zh" else "Here is the document to analyze:\n\n"
    user_prompt = prefix + (document_text or "")

    if client is None:
        return "[Error] OPENAI_API_KEY å°šæœªè¨­å®šï¼Œç„¡æ³•é€£ç·šè‡³ OpenAIã€‚"

    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_output_tokens=2500,
        )
        return response.output_text
    except Exception as e:
        msg = str(e)
        low = msg.lower()
        err_type = "unknown"
        if ("insufficient_quota" in msg) or ("error code: 429" in low) or ("quota" in low):
            err_type = "quota_or_429"
        elif ("rate_limit" in low) or ("too many requests" in low):
            err_type = "rate_limit"
        elif ("invalid_api_key" in low) or ("api key" in low and "invalid" in low):
            err_type = "invalid_key"
        elif ("timed out" in low) or ("timeout" in low) or ("connection" in low):
            err_type = "network"
        st.session_state["_ef_last_openai_error_type"] = err_type
        st.session_state["_ef_last_openai_error"] = (msg[:240] + ("..." if len(msg) > 240 else ""))
        # Do NOT leak or guess billing/quota in the main output. Store details in diagnostics instead.
        return f"[OpenAI API ERROR: {err_type or 'unknown'}]"


def _openai_simple(system_prompt: str, user_prompt: str, model_name: str, max_output_tokens: int) -> str:
    # Diagnostics (do not leak key)
    st.session_state["_ef_last_openai_error"] = ""
    st.session_state["_ef_last_openai_error_type"] = ""

    if client is None:
        return "[Error] OPENAI_API_KEY å°šæœªè¨­å®šï¼Œç„¡æ³•é€£ç·šè‡³ OpenAIã€‚"
    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_output_tokens=max_output_tokens,
        )
        return (response.output_text or "").strip()
    except Exception as e:
        msg = str(e)
        low = msg.lower()
        err_type = "unknown"
        if ("insufficient_quota" in msg) or ("error code: 429" in low) or ("quota" in low):
            err_type = "quota_or_429"
        elif ("rate_limit" in low) or ("too many requests" in low):
            err_type = "rate_limit"
        elif ("invalid_api_key" in low) or ("api key" in low and "invalid" in low):
            err_type = "invalid_key"
        elif ("timed out" in low) or ("timeout" in low) or ("connection" in low):
            err_type = "network"
        st.session_state["_ef_last_openai_error_type"] = err_type
        st.session_state["_ef_last_openai_error"] = (msg[:240] + ("..." if len(msg) > 240 else ""))
        # Do NOT leak or guess billing/quota in the main output. Store details in diagnostics instead.
        return f"[OpenAI API ERROR: {err_type or 'unknown'}]"


def _chunk_text(text: str, chunk_size: int = 12000, overlap: int = 600) -> List[str]:
    """Used ONLY for reference summarization to control token size."""
    if not text:
        return []
    text = text.replace("\r\n", "\n").replace("\r", "\n").strip()
    n = len(text)
    chunks = []
    start = 0
    while start < n:
        end = min(n, start + chunk_size)
        chunks.append(text[start:end])
        if end >= n:
            break
        start = max(0, end - overlap)
    return chunks


def summarize_reference_text(language: str, ref_name: str, ref_text: str, model_name: str) -> str:
    """Compress reference doc into a faithful structured summary (not framework analysis)."""
    chunks = _chunk_text(ref_text, chunk_size=12000, overlap=600)
    if not chunks:
        return ""

    if language == "zh":
        sys = "ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„æ–‡ä»¶æ‘˜è¦åŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯å¿ å¯¦å£“ç¸®å…§å®¹ï¼Œä¸è¦ç™¼æ˜ä¸å­˜åœ¨çš„è³‡è¨Šã€‚"

        def one_chunk_prompt(i: int, total: int, c: str) -> str:
            return (
                f"è«‹å°‡ä»¥ä¸‹åƒè€ƒæ–‡ä»¶å…§å®¹åšæ‘˜è¦ï¼ˆç¬¬ {i}/{total} æ®µï¼‰ï¼Œä¿ç•™ï¼š\n"
                "1) é‡è¦å®šç¾©/ç¯„åœ\n2) é—œéµè¦æ±‚/é™åˆ¶/æ•¸å€¼\n3) ä»»ä½•ä¾‹å¤–/å‰æ\n4) å¯èƒ½å½±éŸ¿åˆ¤æ–·çš„æ¢æ¬¾\n\n"
                f"ã€åƒè€ƒæ–‡ä»¶ã€‘{ref_name}\nã€å…§å®¹ã€‘\n{c}"
            )

        reduce_sys = "ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„æ‘˜è¦æ•´åˆåŠ©æ‰‹ã€‚è«‹åˆä½µå¤šæ®µæ‘˜è¦ï¼Œå»é‡ä½†ä¸æ¼æ‰é—œéµè¦æ±‚èˆ‡é™åˆ¶ã€‚"

        def reduce_prompt(t: str) -> str:
            return (
                "è«‹æŠŠä»¥ä¸‹å¤šæ®µæ‘˜è¦æ•´åˆç‚ºä¸€ä»½ã€åƒè€ƒæ–‡ä»¶ç¸½æ‘˜è¦ã€ï¼Œçµæ§‹åŒ–è¼¸å‡ºï¼š\n"
                "A. å®šç¾©/ç¯„åœ\nB. ä¸»è¦è¦æ±‚/é™åˆ¶\nC. ä¾‹å¤–/å‰æ\nD. å¯èƒ½å½±éŸ¿åˆ¤æ–·çš„æ¢æ¬¾\n\n"
                f"ã€åƒè€ƒæ–‡ä»¶ã€‘{ref_name}\nã€å¤šæ®µæ‘˜è¦ã€‘\n{t}"
            )

    else:
        sys = "You are a careful document summarization assistant. Summarize faithfully and do not hallucinate."

        def one_chunk_prompt(i: int, total: int, c: str) -> str:
            return (
                f"Summarize the following reference document chunk ({i}/{total}). Preserve:\n"
                "1) definitions/scope\n2) key requirements/constraints/values\n3) exceptions/prereqs\n4) clauses that affect decisions\n\n"
                f"[Reference] {ref_name}\n[Content]\n{c}"
            )

        reduce_sys = "You consolidate summaries. Merge, dedupe, keep key constraints."

        def reduce_prompt(t: str) -> str:
            return (
                "Consolidate chunk summaries into ONE reference master summary with sections:\n"
                "A. Definitions/Scope\nB. Requirements/Constraints\nC. Exceptions/Prereqs\nD. Decision-impacting clauses\n\n"
                f"[Reference] {ref_name}\n[Chunk summaries]\n{t}"
            )

    partials = []
    total = len(chunks)
    for i, c in enumerate(chunks, start=1):
        partials.append(_openai_simple(sys, one_chunk_prompt(i, total, c), model_name, max_output_tokens=900))

    current = partials[:]
    while len(current) > 1:
        nxt = []
        batch_size = 8
        for i in range(0, len(current), batch_size):
            joined = "\n\n---\n\n".join(current[i : i + batch_size])
            nxt.append(_openai_simple(reduce_sys, reduce_prompt(joined), model_name, max_output_tokens=1100))
        current = nxt

    return current[0].strip()


def clean_report_text(text: str) -> str:
    replacements = {"â– ": "-", "â€¢": "-", "â€“": "-", "â€”": "-"}
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text





# =========================
# Step 6: Relevance analysis (æ›´æ­£2)
# =========================


def is_openai_error_output(text: str) -> bool:
    """Detect our placeholder error strings from OpenAI call failures."""
    if not text:
        return False
    t = str(text).strip()
    return t.startswith("[OpenAI API") or t.startswith("[OpenAI")

def render_openai_error(language: str) -> None:
    """Render a helpful OpenAI error without polluting step outputs."""
    err_type = st.session_state.get("_ef_last_openai_error_type", "")
    err_msg = st.session_state.get("_ef_last_openai_error", "")
    if language == "en":
        st.error("OpenAI API call failed. This is not an app logic error. Please check your OpenAI Project billing/usage and model access.")
        st.caption("Tip: In OpenAI dashboard, verify the key belongs to a Project with billing enabled and usage limits > 0. Then redeploy/restart.")
    else:
        st.error("OpenAI API å‘¼å«å¤±æ•—ã€‚é€™ä¸æ˜¯æµç¨‹é‚è¼¯éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥ OpenAI å°ˆæ¡ˆçš„ Billing/ç”¨é‡èˆ‡æ¨¡å‹æ¬Šé™ã€‚")
        st.caption("å»ºè­°ï¼šåˆ° OpenAI Dashboard ç¢ºèªæ­¤ API key æ‰€å±¬ Project å·²é–‹å•Ÿè¨ˆè²»ã€ç”¨é‡ä¸Šé™ > 0ï¼Œä¸”æœ‰æ¨¡å‹ä½¿ç”¨æ¬Šé™ï¼›ä¹‹å¾Œé‡å•Ÿ/é‡æ–°éƒ¨ç½²ã€‚")
    with st.expander("Diagnostics / è©³ç´°éŒ¯èª¤" if language == "en" else "Diagnostics / è©³ç´°éŒ¯èª¤", expanded=False):
        st.write(f"error_type: {err_type or 'unknown'}")
        if err_msg:
            st.code(err_msg)
        else:
            st.write("(no additional error details captured)")


def run_upstream_relevance(language: str, main_doc: str, upstream_doc: str, model_name: str) -> str:
    """Main reference relevance analysis: identify upstream document errors."""
    if language == "zh":
        sys = "ä½ æ˜¯ä¸€ä½åš´è¬¹çš„å·¥ç¨‹å¯©é–±é¡§å•ã€‚ä½ è¦æª¢æŸ¥ä¸»æ–‡ä»¶èˆ‡ä¸Šæ¸¸ä¸»è¦åƒè€ƒæ–‡ä»¶çš„ä¸€è‡´æ€§ï¼Œä¸å¾—æœæ’°ã€‚"
        user = (
            "ä»»å‹™ï¼šåšã€Main Reference Relevance Analysisï¼ˆä¸Šæ¸¸ç›¸é—œæ€§ï¼‰ã€ã€‚\n"
            "è«‹åªé‡å°ä¸‹åˆ—ä¸‰é¡ä¸€è‡´æ€§åšæª¢æŸ¥ä¸¦è¼¸å‡ºï¼š\n"
            "1) ç›®çš„ï¼ˆPurposeï¼‰ï¼šä¸»æ–‡ä»¶ç›®çš„æ˜¯å¦èˆ‡ä¸»è¦åƒè€ƒæ–‡ä»¶ä¸€è‡´æˆ–å¯æ¨å°ï¼›è‹¥ä¸ä¸€è‡´ï¼Œèªªæ˜å·®ç•°ã€‚\n"
            "2) éœ€æ±‚ï¼ˆRequirementsï¼‰ï¼šä¸»æ–‡ä»¶å¼•ç”¨/æ¡ç”¨çš„éœ€æ±‚æ˜¯å¦èˆ‡ä¸»è¦åƒè€ƒæ–‡ä»¶ä¸€è‡´ï¼›åˆ—å‡ºä¸ä¸€è‡´æˆ–ç¼ºæ¼ã€‚\n"
            "3) çµè«–ï¼ˆConclusionï¼‰ï¼šä¸»è¦åƒè€ƒæ–‡ä»¶çš„çµè«–æ˜¯å¦èˆ‡ä¸»æ–‡ä»¶çš„ç›®çš„/åˆ†æ/çµè«–è¡çªï¼›åˆ—å‡ºè¡çªé»ã€‚\n\n"
            "è¼¸å‡ºæ ¼å¼è¦æ±‚ï¼ˆMarkdownï¼‰ï¼š\n"
            "- æ‘˜è¦ï¼ˆ3~6é»ï¼‰\n"
            "- ä¸€è‡´æ€§æª¢æŸ¥è¡¨ï¼ˆç”¨è¡¨æ ¼å‘ˆç¾ï¼šæª¢æŸ¥é … / ä¸»æ–‡ä»¶è¦é» / åƒè€ƒæ–‡ä»¶è¦é» / æ˜¯å¦ä¸€è‡´ / èªªæ˜èˆ‡å»ºè­°ä¿®æ­£ï¼‰\n"
            "- Upstream document errors æ¸…å–®ï¼ˆé€æ¢ï¼Œå«åš´é‡åº¦å»ºè­°ï¼‰\n\n"
            f"ã€ä¸»æ–‡ä»¶ã€‘\n{(main_doc or '')[:18000]}\n\n"
            f"ã€ä¸»è¦åƒè€ƒæ–‡ä»¶ï¼ˆUpstreamï¼‰ã€‘\n{(upstream_doc or '')[:18000]}"
        )
    else:
        sys = "You are a rigorous engineering review consultant. Check consistency between the main document and the upstream main reference. Do not hallucinate."
        user = (
            "Task: Main Reference Relevance Analysis (upstream relevance).\n"
            "Check ONLY these consistency aspects and report findings:\n"
            "1) Purpose: main purpose consistent with or derivable from upstream purpose.\n"
            "2) Requirements: requirements used/quoted in main consistent with upstream; list mismatches or omissions.\n"
            "3) Conclusions: upstream conclusions must not conflict with the purpose/analysis/conclusions of main; list conflicts.\n\n"
            "Output in Markdown:\n"
            "- Executive summary (3-6 bullets)\n"
            "- Consistency check table (Item / Main / Upstream / Consistent? / Notes & Fix)\n"
            "- Upstream document errors list (with suggested severity)\n\n"
            f"[Main document]\n{(main_doc or '')[:18000]}\n\n"
            f"[Upstream main reference]\n{(upstream_doc or '')[:18000]}"
        )
    return _openai_simple(sys, user, model_name, max_output_tokens=1800)


def run_quote_relevance(language: str, main_doc: str, quote_ref_doc: str, model_name: str) -> str:
    """Quote reference relevance analysis: identify reference inconsistency errors."""
    if language == "zh":
        sys = "ä½ æ˜¯ä¸€ä½åš´è¬¹çš„æ–‡ä»¶æ ¸å°é¡§å•ã€‚ä½ è¦æª¢æŸ¥ä¸»æ–‡ä»¶ä¸­çš„å¼•ç”¨/å¼•è¿°æ˜¯å¦èˆ‡ã€å¼•ç”¨ä¾†æºï¼ˆQuote Referenceï¼‰ã€ä¸€è‡´ï¼Œä¸å¾—æœæ’°ã€‚"
        user = (
            "ä»»å‹™ï¼šåšã€Quote Reference Relevance Analysisï¼ˆå¼•ç”¨ä¸€è‡´æ€§ï¼‰ã€ã€‚\n"
            "è«‹ä¾åºå®Œæˆï¼š\n"
            "A) å¾ä¸»æ–‡ä»¶ä¸­æ‰¾å‡ºæ˜é¡¯çš„ã€å¼•ç”¨/å¼•è¿°/å¼•ç”¨æ¢æ¬¾/å¼•ç”¨æ•¸å€¼ã€ï¼ˆå¯ç”¨é—œéµå­—å¦‚ï¼šaccording to, as stated in, per, å¼•ç”¨, ä¾æ“š, åƒç…§, æ¢æ¬¾, è¦ç¯„ ç­‰ï¼‰ä¸¦åˆ—æˆæ¸…å–®ã€‚\n"
            "B) é€æ¢æ ¸å°ï¼šæ¯ä¸€æ¢å¼•ç”¨å…§å®¹æ˜¯å¦èƒ½åœ¨ Quote Reference æ–‡ä»¶ä¸­æ‰¾åˆ°å°æ‡‰ï¼›è‹¥æ‰¾ä¸åˆ°æˆ–è¡¨è¿°/æ•¸å€¼/æ¢ä»¶ä¸åŒï¼Œè¦–ç‚ºã€reference inconsistency errorã€ã€‚\n"
            "C) å°æ¯ä¸€æ¢ä¸ä¸€è‡´ï¼Œæä¾›ï¼šå·®ç•°é»ã€å¯èƒ½åŸå› ã€å»ºè­°ä¿®æ­£ï¼ˆä¸»æ–‡ä»¶è¦æ”¹ã€æˆ–è¦è£œå……å¼•ç”¨ã€æˆ–è¦æ›´æ›å¼•ç”¨ä¾†æºï¼‰ã€‚\n\n"
            "è¼¸å‡ºæ ¼å¼ï¼ˆMarkdownï¼‰ï¼š\n"
            "- æ‘˜è¦\n"
            "- å¼•ç”¨æ ¸å°è¡¨ï¼ˆè¡¨æ ¼ï¼šä¸»æ–‡ä»¶å¼•ç”¨ç‰‡æ®µ/ä¸»å¼µ / Quote Reference å°æ‡‰æ®µè½æˆ–é—œéµå¥ / ä¸€è‡´æ€§åˆ¤å®š / å·®ç•°èˆ‡å»ºè­°ä¿®æ­£ï¼‰\n"
            "- Reference inconsistency errorsï¼ˆé€æ¢ï¼‰\n\n"
            "æ³¨æ„ï¼šå¦‚æœä¸»æ–‡ä»¶æœ¬èº«æ²’æœ‰æ˜ç¢ºå¼•ç”¨å¯è¾¨è­˜ï¼Œè«‹æ˜ç¢ºèªªæ˜ä¸¦æ”¹ä»¥ã€å¯èƒ½å¼•ç”¨é»ã€åšä¿å®ˆæ ¸å°ï¼Œä¸è¦ç¡¬ç·¨ã€‚\n\n"
            f"ã€ä¸»æ–‡ä»¶ã€‘\n{(main_doc or '')[:18000]}\n\n"
            f"ã€Quote Reference æ–‡ä»¶ã€‘\n{(quote_ref_doc or '')[:18000]}"
        )
    else:
        sys = "You are a meticulous cross-checking consultant. Verify that quotes/citations in the main document are consistent with the Quote Reference document. Do not hallucinate."
        user = (
            "Task: Quote Reference Relevance Analysis (reference inconsistency).\n"
            "Steps:\n"
            "A) Identify explicit quotes/citations/claimed requirements/values in the main document (look for 'according to', 'as stated in', 'per', 'reference', etc.). List them.\n"
            "B) For each item, verify whether it exists in the Quote Reference document with matching meaning/values/conditions. If missing or different, mark as a 'reference inconsistency error'.\n"
            "C) For each inconsistency, provide the delta, possible cause, and recommended fix (edit main, add citation detail, or change the reference).\n\n"
            "Output in Markdown:\n"
            "- Summary\n"
            "- Quote check table (Main claim / Quote reference evidence / Consistent? / Delta & Fix)\n"
            "- Reference inconsistency errors list\n\n"
            "If the main document contains no identifiable quotes/citations, say so and perform a conservative 'possible quote points' check without inventing content.\n\n"
            f"[Main document]\n{(main_doc or '')[:18000]}\n\n"
            f"[Quote reference document]\n{(quote_ref_doc or '')[:18000]}"
        )
    return _openai_simple(sys, user, model_name, max_output_tokens=1800)





# =========================
# Step 8: Final Analysis (NEW) â€” Cross-Checking Analysis (12-11-2025)
# =========================

CROSS_CHECK_GUIDE_EN = """
Cross-Check Analysis (Guidance)

Purpose:
Perform a cross-check analysis of the results of an original identification analysis, to identify incorrect results
and summarize the correct results in a final report.

Error types:
- Omission errors
- Information errors
- Technical errors
- Alignment errors
- Reasoning errors

Key definitions:
- Review Document: document under review
- Review Framework: framework/prompt used to guide the original review
- Identification (Original) Analysis: original analysis results (SPVs, errors, LOPs, etc.)
- Cross-check Analysis: re-do and cross-check correctness of original results
- Matching item: identified in both original and cross-check, with same risk level
- Similar matching item: identified in both, but with different risk levels
- Non-matching item: identified in only one analysis (I-only / C-only)

Cross-check process (high level):
1) Obtain review document + framework + prompts + original results
2) Re-perform the original identification analysis (without referring to original)
3) Compare original vs cross-check results to classify:
   - Matching items
   - Similar matching items
   - I-only non-matching items
   - C-only non-matching items
4) Validate similar matching items (re-analyze risk level)
5) Validate non-matching I-only items (determine correctness; explain why one analysis is wrong)
6) Validate non-matching C-only items (determine correctness; explain why one analysis is wrong)
7) Prepare report of results with summary tables:
   - Table 1: Matching items (same risk)
   - Table 2: Similar matching items (different risk)
   - Table 3: I-only non-matching items (include which is correct + why)
   - Table 4: C-only non-matching items (include which is correct + why)
   - Table 5: Final validated list (after validation)
""".strip()


def run_step8_final_analysis(
    language: str,
    document_type: str,
    framework_name: str,
    step7_integration_output: str,
    model_name: str,
) -> str:
    """
    Step 8: Final Analysis
    Cross-check Step 7's integration analysis results and produce the FINAL deliverable report.
    """
    if language == "zh":
        sys = "ä½ æ˜¯ä¸€ä½åš´è¬¹çš„é›¶éŒ¯èª¤å¯©é–±é¡§å•èˆ‡äº¤å‰æ ¸å°ï¼ˆCross-checkï¼‰åˆ†æå¸«ã€‚ä½ å¿…é ˆä¾è¼¸å…¥å…§å®¹é€²è¡Œäº¤å‰æ ¸å°ï¼Œä¸å¾—æœæ’°ã€‚"
        user = (
            "ä»»å‹™ï¼šåŸ·è¡Œã€Step 8: Final Analysisã€ã€‚\n"
            "ä½ è¦ä¾ç…§ Cross-Checking Analysis çš„æ–¹æ³•ï¼Œå° Step 7ï¼ˆIntegration analysisï¼‰çš„è¼¸å‡ºé€²è¡Œäº¤å‰æ ¸å°ï¼Œæ‰¾å‡ºå¯èƒ½çš„éŒ¯èª¤çµæœï¼Œä¸¦è¼¸å‡ºæœ€çµ‚å¯äº¤ä»˜çš„ Final deliverableã€‚\n\n"
            "è«‹éµå®ˆï¼š\n"
            "1) å…ˆæŠŠ Step 7 çš„çµæœè¦–ç‚ºã€åŸå§‹è­˜åˆ¥/æ•´åˆçµæœï¼ˆOriginal resultsï¼‰ã€ã€‚\n"
            "2) ä½ è¦åšä¸€è¼ªã€Cross-checkã€ï¼šå°ç…§å…¶å…§éƒ¨ä¸€è‡´æ€§ã€é¢¨éšªåˆ†ç´šä¸€è‡´æ€§ã€å¼•ç”¨ä¸€è‡´æ€§ï¼ˆè‹¥ Step 7 æœ‰æåˆ°ä¸Šæ¸¸/å¼•ç”¨ä¸€è‡´æ€§çµæœï¼‰ï¼Œä¸¦å°‡çµæœåˆ†é¡æˆï¼šMatching / Similar Matching / I-only / C-onlyã€‚\n"
            "3) é‡å° Similar Matching / Non-matching åš validationï¼šæŒ‡å‡ºå“ªä¸€æ–¹ï¼ˆStep 7 çš„çµè«–æˆ– cross-check çš„çµè«–ï¼‰è¼ƒæ­£ç¢ºï¼Œä¸¦èªªæ˜åŸå› ï¼ˆå¯ç”¨ omission/information/technical/alignment/reasoning error è§’åº¦ï¼‰ã€‚\n"
            "4) æœ€çµ‚å ±å‘Šå¿…é ˆç”¨ 5 å€‹è¡¨æ ¼ï¼ˆTable 1~5ï¼‰è¼¸å‡ºï¼Œä¸¦åœ¨æœ€å¾Œæä¾›ï¼š\n"
            "   - æœ€çµ‚ã€Validated itemsã€æ¸…å–®ï¼ˆå¯å°æ‡‰ Table 5ï¼‰\n"
            "   - å„ªå…ˆç´šä¿®æ­£æ¸…å–®ï¼ˆP1/P2/P3ï¼‰\n"
            "   - éœ€è¦å‘å¯©é–±è€…/æ–‡ä»¶ä½œè€…æ¾„æ¸…çš„å•é¡Œæ¸…å–®\n\n"
            f"ã€æ–‡ä»¶é¡å‹ã€‘{document_type or 'ï¼ˆæœªé¸æ“‡ï¼‰'}\n"
            f"ã€ä½¿ç”¨æ¡†æ¶ã€‘{framework_name}\n\n"
            "ã€Cross-check æ–¹æ³•æŒ‡å¼•ï¼ˆæ‘˜è¦ï¼‰ã€‘\n"
            f"{CROSS_CHECK_GUIDE_EN}\n\n"
            "ã€Step 7ï¼šIntegration analysis è¼¸å‡ºï¼ˆOriginal resultsï¼‰ã€‘\n"
            f"{(step7_integration_output or '')[:18000]}\n"
        )
    else:
        sys = "You are a rigorous Error-Free consultant and cross-check analysis specialist. You must cross-check based on provided content; do not hallucinate."
        user = (
            "Task: Execute 'Step 8: Final Analysis'.\n"
            "Use the Cross-Checking Analysis method to cross-check the Step 7 (Integration analysis) output, identify incorrect results, and produce the final deliverable.\n\n"
            "Rules:\n"
            "1) Treat Step 7 output as the 'Original results'.\n"
            "2) Perform a cross-check pass and classify items as: Matching / Similar Matching / I-only / C-only.\n"
            "3) Validate Similar Matching and Non-matching items: decide which side is correct and explain why, using the error type lenses "
            "(omission / information / technical / alignment / reasoning).\n"
            "4) The final report MUST include five summary tables (Table 1~5), and end with:\n"
            "   - Final validated items list (Table 5)\n"
            "   - Prioritized fix list (P1/P2/P3)\n"
            "   - Clarification questions for reviewer/author\n\n"
            f"[Document type] {document_type or '(not selected)'}\n"
            f"[Framework] {framework_name}\n\n"
            "[Cross-check method guidance]\n"
            f"{CROSS_CHECK_GUIDE_EN}\n\n"
            "[Step 7 Integration analysis output (Original results)]\n"
            f"{(step7_integration_output or '')[:18000]}\n"
        )

    return _openai_simple(sys, user, model_name, max_output_tokens=2200)





# =========================
# Follow-up Q&A
# =========================

def run_followup_qa(
    framework_key: str,
    language: str,
    document_text: str,
    analysis_output: str,
    user_question: str,
    model_name: str,
    extra_text: str = "",
) -> str:
    if framework_key not in FRAMEWORKS:
        return f"[Error] Framework '{framework_key}' not found in frameworks.json."

    fw = FRAMEWORKS[framework_key]

    if language == "zh":
        system_prompt = (
            "You are an Error-Free consultant familiar with framework: "
            + fw["name_zh"]
            + ". You already produced a full analysis. Now answer follow-up "
            "questions based on the original document and previous analysis. "
            "Focus on extra insights, avoid repeating the full report."
        )
    else:
        system_prompt = (
            "You are an Error-Free consultant for framework: "
            + fw["name_en"]
            + ". You already produced a full analysis. Answer follow-up "
            "questions based on document + previous analysis, without "
            "recreating the full report."
        )

    doc_excerpt = (document_text or "")[:8000]
    analysis_excerpt = (analysis_output or "")[:8000]
    extra_excerpt = extra_text[:4000] if extra_text else ""

    blocks = [
        "Original document excerpt:\n" + doc_excerpt,
        "Previous analysis excerpt:\n" + analysis_excerpt,
        "User question:\n" + user_question,
    ]
    if extra_excerpt:
        blocks.append("Extra reference:\n" + extra_excerpt)

    user_content = "\n\n".join(blocks)

    if client is None:
        return "[Error] OPENAI_API_KEY å°šæœªè¨­å®šã€‚"

    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content},
            ],
            max_output_tokens=2000,
        )
        return response.output_text
    except Exception as e:
        msg = str(e)
        low = msg.lower()
        err_type = "unknown"
        if ("insufficient_quota" in msg) or ("error code: 429" in low) or ("quota" in low):
            err_type = "quota_or_429"
        elif ("rate_limit" in low) or ("too many requests" in low):
            err_type = "rate_limit"
        elif ("invalid_api_key" in low) or ("api key" in low and "invalid" in low):
            err_type = "invalid_key"
        elif ("timed out" in low) or ("timeout" in low) or ("connection" in low):
            err_type = "network"
        st.session_state["_ef_last_openai_error_type"] = err_type
        st.session_state["_ef_last_openai_error"] = (msg[:240] + ("..." if len(msg) > 240 else ""))
        # Do NOT leak or guess billing/quota in the main output. Store details in diagnostics instead.
        return f"[OpenAI API ERROR: {err_type or 'unknown'}]"





# =========================
# Report formatting / exports
# =========================

def build_full_report(lang: str, framework_key: str, state: Dict, include_followups: bool = True) -> str:
    analysis_output = state.get("analysis_output", "")
    followups = state.get("followup_history", []) if include_followups else []
    fw = FRAMEWORKS.get(framework_key, {})
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    email = st.session_state.get("user_email", "unknown")

    name_zh = fw.get("name_zh", framework_key)
    name_en = fw.get("name_en", framework_key)

    if lang == "zh":
        header = [
            f"{BRAND_TITLE_ZH} å ±å‘Šï¼ˆåˆ†æ" + (" + Q&A" if include_followups else "") + ")",
            f"{BRAND_SUBTITLE_ZH}",
            f"ç”¢ç”Ÿæ™‚é–“ï¼š{now}",
            f"ä½¿ç”¨è€…å¸³è™Ÿï¼š{email}",
            f"ä½¿ç”¨æ¡†æ¶ï¼š{name_zh}",
            "",
            "==============================",
            "ä¸€ã€åˆ†æçµæœ",
            "==============================",
            analysis_output,
        ]
        if include_followups and followups:
            header += [
                "",
                "==============================",
                "é™„éŒ„ï¼šå¾ŒçºŒå•ç­”ï¼ˆQ&Aï¼‰",
                "==============================",
            ]
            for i, (q, a) in enumerate(followups, start=1):
                header.append(f"[Q{i}] {q}")
                header.append(f"[A{i}] {a}")
                header.append("")
    else:
        header = [
            f"{BRAND_TITLE_EN} Report (Analysis" + (" + Q&A" if include_followups else "") + ")",
            f"{BRAND_SUBTITLE_EN}",
            f"Generated: {now}",
            f"User: {email}",
            f"Framework: {name_en}",
            "",
            "==============================",
            "1. Analysis",
            "==============================",
            analysis_output,
        ]
        if include_followups and followups:
            header += [
                "",
                "==============================",
                "Appendix: Follow-up Q&A",
                "==============================",
            ]
            for i, (q, a) in enumerate(followups, start=1):
                header.append(f"[Q{i}] {q}")
                header.append(f"[A{i}] {a}")
                header.append("")
    return clean_report_text("\n".join(header))


def build_docx_bytes(text: str) -> bytes:
    """Build a reasonably-formatted DOCX from plain/markdown-like text.

    Goal: make the downloaded report closely resemble the Step 8 deliverable
    rendering (headings, bullets, numbered lists), without changing any
    analysis content.
    """

    import re

    def _add_runs_with_bold(paragraph, s: str):
        # Minimal **bold** support (does not try to fully implement Markdown).
        parts = re.split(r"(\*\*[^*]+\*\*)", s)
        for part in parts:
            if part.startswith("**") and part.endswith("**") and len(part) >= 4:
                paragraph.add_run(part[2:-2]).bold = True
            else:
                paragraph.add_run(part)

    doc = Document()

    lines = text.split("\n")
    first_nonempty = next((i for i, l in enumerate(lines) if l.strip()), None)

    for i, raw in enumerate(lines):
        line = raw.rstrip("\r")

        if not line.strip():
            doc.add_paragraph("")
            continue

        # Title line: first non-empty line only
        if first_nonempty is not None and i == first_nonempty:
            p = doc.add_paragraph(line.strip())
            p.style = "Title"
            continue

        s = line.lstrip()

        # Headings (markdown-like)
        if s.startswith("### "):
            p = doc.add_paragraph(s[4:].strip())
            p.style = "Heading 3"
            continue
        if s.startswith("## "):
            p = doc.add_paragraph(s[3:].strip())
            p.style = "Heading 2"
            continue
        if s.startswith("# "):
            p = doc.add_paragraph(s[2:].strip())
            p.style = "Heading 1"
            continue

        # Underline-style headings (e.g., ======)
        if set(s) <= {"=", "-"} and len(s) >= 5:
            # Skip separator lines; the surrounding text will remain.
            continue

        # Bullet list
        m_bullet = re.match(r"^[-*\u2022]\s+(.*)$", s)
        if m_bullet:
            p = doc.add_paragraph(style="List Bullet")
            _add_runs_with_bold(p, m_bullet.group(1).strip())
            continue

        # Numbered list
        m_num = re.match(r"^(\d+)[\.)]\s+(.*)$", s)
        if m_num:
            p = doc.add_paragraph(style="List Number")
            _add_runs_with_bold(p, m_num.group(2).strip())
            continue

        # Default paragraph
        p = doc.add_paragraph()
        _add_runs_with_bold(p, s)

    buf = BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.getvalue()


def build_pdf_bytes(text: str) -> bytes:
    buf = BytesIO()
    ensure_pdf_font()
    c = canvas.Canvas(buf, pagesize=letter)
    width, height = letter

    margin_x = 40
    margin_y = 40
    line_height = 14
    max_width = width - 2 * margin_x

    try:
        c.setFont(PDF_FONT_NAME, 11)
    except Exception:
        c.setFont("Helvetica", 11)

    y = height - margin_y

    for raw_line in text.split("\n"):
        safe_line = raw_line.replace("\t", "    ")
        if not safe_line:
            y -= line_height
            if y < margin_y:
                c.showPage()
                try:
                    c.setFont(PDF_FONT_NAME, 11)
                except Exception:
                    c.setFont("Helvetica", 11)
                y = height - margin_y
            continue

        line = safe_line
        while line:
            try:
                if pdfmetrics.stringWidth(line, PDF_FONT_NAME, 11) <= max_width:
                    segment = line
                    line = ""
                else:
                    cut = len(line)
                    while cut > 0 and pdfmetrics.stringWidth(line[:cut], PDF_FONT_NAME, 11) > max_width:
                        cut -= 1
                    space_pos = line.rfind(" ", 0, cut)
                    if space_pos > 0:
                        cut = space_pos
                    segment = line[:cut].rstrip()
                    line = line[cut:].lstrip()
            except Exception:
                segment = line[:120]
                line = line[120:]

            c.drawString(margin_x, y, segment)
            y -= line_height
            if y < margin_y:
                c.showPage()
                try:
                    c.setFont(PDF_FONT_NAME, 11)
                except Exception:
                    c.setFont("Helvetica", 11)
                y = height - margin_y

    c.save()
    buf.seek(0)
    return buf.getvalue()


def build_pptx_bytes(text: str) -> bytes:
    try:
        from pptx import Presentation
    except Exception:
        return build_docx_bytes("404: Not Found")

    prs = Presentation()
    title_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_layout)
    if slide.shapes.title is not None:
        slide.shapes.title.text = "404: Not Found"
    if len(slide.placeholders) > 1:
        try:
            slide.placeholders[1].text = "PPTX export is not available in this version."
        except Exception:
            pass

    buf = BytesIO()
    prs.save(buf)
    buf.seek(0)
    return buf.getvalue()





# =========================
# Dashboards (unchanged)
# =========================

def company_admin_dashboard():
    companies = load_companies()
    code = st.session_state.get("company_code")
    email = st.session_state.get("user_email")

    if not code or code not in companies:
        lang = st.session_state.get("lang", "zh")
        st.error(zh("æ‰¾ä¸åˆ°å…¬å¸ä»£ç¢¼ï¼Œè«‹è¯çµ¡ç³»çµ±ç®¡ç†å“¡", "æ‰¾ä¸åˆ°å…¬å¸ä»£ç ï¼Œè¯·è”ç³»ç³»ç»Ÿç®¡ç†å‘˜") if lang == "zh" else "Company code not found. Please contact system admin.")
        return

    entry = companies[code]
    admins = entry.get("admins", [])
    if email not in admins:
        lang = st.session_state.get("lang", "zh")
        st.error(zh("æ‚¨æ²’æœ‰æ­¤å…¬å¸çš„ç®¡ç†è€…æ¬Šé™", "æ‚¨æ²¡æœ‰æ­¤å…¬å¸çš„ç®¡ç†è€…æƒé™") if lang == "zh" else "You are not an admin for this company.")
        return

    lang = st.session_state.get("lang", "zh")
    company_name = entry.get("company_name") or code
    content_access = entry.get("content_access", False)

    st.title((zh(f"å…¬å¸ç®¡ç†å¾Œå° - {company_name}", f"å…¬å¸ç®¡ç†åå° - {company_name}") if lang == "zh" else f"Company Admin Dashboard - {company_name}"))
    st.markdown("---")

    st.subheader(zh("å…¬å¸è³‡è¨Š", "å…¬å¸ä¿¡æ¯") if lang == "zh" else "Company Info")
    st.write((zh("å…¬å¸ä»£ç¢¼ï¼š", "å…¬å¸ä»£ç ï¼š") if lang == "zh" else "Company Code: ") + code)
    if lang == "zh":
        st.write(zh("å¯æŸ¥çœ‹å…§å®¹ï¼š", "å¯æŸ¥çœ‹å†…å®¹ï¼š") + ("æ˜¯" if content_access else "å¦"))
    else:
        st.write("Can view content: " + ("Yes" if content_access else "No"))

    st.markdown("---")
    st.subheader(zh("å­¸ç”Ÿ / ä½¿ç”¨è€…åˆ—è¡¨", "å­¦å‘˜ / ç”¨æˆ·åˆ—è¡¨") if lang == "zh" else "Users in this company")

    users = entry.get("users", [])
    doc_tracking = load_doc_tracking()
    usage_stats = load_usage_stats()

    if not users:
        st.info(zh("ç›®å‰å°šæœªæœ‰ä»»ä½•å­¸ç”Ÿè¨»å†Š", "ç›®å‰å°šæœªæœ‰ä»»ä½•å­¦å‘˜æ³¨å†Œ") if lang == "zh" else "No users registered for this company yet.")
    else:
        for u in users:
            docs = doc_tracking.get(u, [])
            st.markdown(f"**{u}**")
            st.write((zh("ä¸Šå‚³æ–‡ä»¶æ•¸ï¼š", "ä¸Šä¼ æ–‡ä»¶æ•°ï¼š") if lang == "zh" else "Uploaded documents: ") + str(len(docs)))

            u_stats = usage_stats.get(u)
            if not u_stats:
                st.caption(zh("å°šç„¡åˆ†æè¨˜éŒ„", "å°šæ— åˆ†æè®°å½•") if lang == "zh" else "No analysis usage recorded yet.")
            else:
                if content_access:
                    st.write((zh("æœ€å¾Œä½¿ç”¨æ™‚é–“ï¼š", "æœ€åä½¿ç”¨æ—¶é—´ï¼š") if lang == "zh" else "Last used: ") + u_stats.get("last_used", "-"))
                    fw_map = u_stats.get("frameworks", {})
                    for fw_key, fw_data in fw_map.items():
                        fw_name = FRAMEWORKS.get(fw_key, {}).get("name_zh", fw_key) if lang == "zh" else FRAMEWORKS.get(fw_key, {}).get("name_en", fw_key)
                        if lang == "zh":
                            st.markdown(
                                f"- {fw_name}ï¼šåˆ†æ {fw_data.get('analysis_runs', 0)} æ¬¡ï¼Œè¿½å• {fw_data.get('followups', 0)} æ¬¡ï¼Œä¸‹è¼‰ {fw_data.get('downloads', 0)} æ¬¡"
                            )
                        else:
                            st.markdown(
                                f"- {fw_name}: analysis {fw_data.get('analysis_runs', 0)} times, follow-ups {fw_data.get('followups', 0)} times, downloads {fw_data.get('downloads', 0)} times"
                            )
                else:
                    st.caption(zh("ï¼ˆåƒ…é¡¯ç¤ºä½¿ç”¨é‡ç¸½æ•¸ï¼Œæœªå•Ÿç”¨å…§å®¹æª¢è¦–æ¬Šé™ï¼‰", "ï¼ˆä»…æ˜¾ç¤ºä½¿ç”¨é‡æ€»æ•°ï¼Œæœªå¯ç”¨å†…å®¹æŸ¥çœ‹æƒé™ï¼‰") if lang == "zh" else "(Only aggregate usage visible; content access disabled.)")

            st.markdown("---")


def admin_dashboard():
    lang = st.session_state.get("lang", "zh")
    st.title("Admin Dashboard â€” Error-FreeÂ®")
    st.markdown("---")

    st.subheader(zh("ğŸ“Œ Guest å¸³è™Ÿåˆ—è¡¨", "ğŸ“Œ Guest è´¦å·åˆ—è¡¨") if lang == "zh" else "ğŸ“Œ Guest accounts")
    guests = load_guest_accounts()
    if not guests:
        st.info(zh("ç›®å‰æ²’æœ‰ Guest å¸³è™Ÿã€‚", "ç›®å‰æ²¡æœ‰ Guest è´¦å·ã€‚") if lang == "zh" else "No guest accounts yet.")
    else:
        for email, acc in guests.items():
            st.markdown(f"**{email}** â€” password: `{acc.get('password')}` (role: {acc.get('role')})")
            st.markdown("---")

    st.subheader(zh("ğŸ“ Guest æ–‡ä»¶ä½¿ç”¨ç‹€æ³", "ğŸ“ Guest æ–‡ä»¶ä½¿ç”¨æƒ…å†µ") if lang == "zh" else "ğŸ“ Guest document usage")
    doc_tracking = load_doc_tracking()
    if not doc_tracking:
        st.info(zh("å°šç„¡ Guest ä¸Šå‚³è¨˜éŒ„ã€‚", "å°šæ—  Guest ä¸Šä¼ è®°å½•ã€‚") if lang == "zh" else "No guest uploads recorded yet.")
    else:
        for email, docs in doc_tracking.items():
            st.markdown(f"**{email}** â€” {zh('ä¸Šå‚³æ–‡ä»¶æ•¸ï¼š', 'ä¸Šä¼ æ–‡ä»¶æ•°ï¼š')}{len(docs)} / 3" if lang == "zh" else f"**{email}** â€” uploaded documents: {len(docs)} / 3")
            for d in docs:
                st.markdown(f"- {d}")
            st.markdown("---")

    st.subheader(zh("ğŸ§© æ¨¡çµ„åˆ†æèˆ‡è¿½å•ç‹€æ³ (Session-based)", "ğŸ§© æ¨¡å—åˆ†æä¸è¿½é—®æƒ…å†µ (Session-based)") if lang == "zh" else "ğŸ§© Framework state (current session)")
    fs = st.session_state.get("framework_states", {})
    if not fs:
        st.info(zh("å°šç„¡ Framework åˆ†æè¨˜éŒ„", "å°šæ—  Framework åˆ†æè®°å½•") if lang == "zh" else "No framework analysis yet.")
    else:
        for fw_key, state in fs.items():
            fw_name = FRAMEWORKS.get(fw_key, {}).get("name_zh", fw_key) if lang == "zh" else FRAMEWORKS.get(fw_key, {}).get("name_en", fw_key)
            st.markdown(f"### â–¶ {fw_name}")
            st.write(f"{zh('åˆ†æå®Œæˆï¼š', 'åˆ†æå®Œæˆï¼š')}{state.get('analysis_done')}" if lang == "zh" else f"Analysis done: {state.get('analysis_done')}")
            st.write(f"{zh('è¿½å•æ¬¡æ•¸ï¼š', 'è¿½é—®æ¬¡æ•°ï¼š')}{len(state.get('followup_history', []))}" if lang == "zh" else f"Follow-up count: {len(state.get('followup_history', []))}")
            st.write(f"{zh('å·²ä¸‹è¼‰å ±å‘Šï¼š', 'å·²ä¸‹è½½æŠ¥å‘Šï¼š')}{state.get('download_used')}" if lang == "zh" else f"Downloaded report: {state.get('download_used')}")
            st.markdown("---")

    st.subheader(zh("ğŸ¢ å…¬å¸ä½¿ç”¨é‡ç¸½è¦½", "ğŸ¢ å…¬å¸ä½¿ç”¨é‡æ€»è§ˆ") if lang == "zh" else "ğŸ¢ Company usage overview")
    companies = load_companies()
    usage_stats = load_usage_stats()

    if not companies:
        st.info(zh("ç›®å‰å°šæœªå»ºç«‹ä»»ä½•å…¬å¸ã€‚", "ç›®å‰å°šæœªå»ºç«‹ä»»ä½•å…¬å¸ã€‚") if lang == "zh" else "No companies registered yet.")
    else:
        doc_tracking = load_doc_tracking()
        for code, entry in companies.items():
            company_name = entry.get("company_name") or code
            users = entry.get("users", [])
            content_access = entry.get("content_access", False)

            total_docs = 0
            total_analysis = 0
            total_followups = 0
            total_downloads = 0

            for u in users:
                total_docs += len(doc_tracking.get(u, []))
                u_stats = usage_stats.get(u, {})
                fw_map = u_stats.get("frameworks", {})
                for fw_data in fw_map.values():
                    total_analysis += fw_data.get("analysis_runs", 0)
                    total_followups += fw_data.get("followups", 0)
                    total_downloads += fw_data.get("downloads", 0)

            st.markdown(f"### {company_name} (code: {code})")
            st.write(f"{zh('å­¸ç”Ÿ / ä½¿ç”¨è€…æ•¸ï¼š', 'å­¦å‘˜ / ç”¨æˆ·æ•°ï¼š')}{len(users)}" if lang == "zh" else f"Users: {len(users)}")
            st.write(f"{zh('ç¸½ä¸Šå‚³æ–‡ä»¶æ•¸ï¼š', 'æ€»ä¸Šä¼ æ–‡ä»¶æ•°ï¼š')}{total_docs}" if lang == "zh" else f"Total uploaded documents: {total_docs}")
            st.write(f"{zh('ç¸½åˆ†ææ¬¡æ•¸ï¼š', 'æ€»åˆ†ææ¬¡æ•°ï¼š')}{total_analysis}" if lang == "zh" else f"Total analysis runs: {total_analysis}")
            st.write(f"{zh('ç¸½è¿½å•æ¬¡æ•¸ï¼š', 'æ€»è¿½é—®æ¬¡æ•°ï¼š')}{total_followups}" if lang == "zh" else f"Total follow-ups: {total_followups}")
            st.write(f"{zh('ç¸½ä¸‹è¼‰æ¬¡æ•¸ï¼š', 'æ€»ä¸‹è½½æ¬¡æ•°ï¼š')}{total_downloads}" if lang == "zh" else f"Total downloads: {total_downloads}")
            st.write((zh("content_accessï¼š", "content_accessï¼š") if lang == "zh" else "content_access: ") + ("å•Ÿç”¨" if content_access else "é—œé–‰") if lang == "zh" else "content_access: " + ("enabled" if content_access else "disabled"))
            st.markdown("---")

    st.subheader(zh("ğŸ” å…¬å¸å…§å®¹æª¢è¦–æ¬Šé™è¨­å®š", "ğŸ” å…¬å¸å†…å®¹æŸ¥çœ‹æƒé™è®¾ç½®") if lang == "zh" else "ğŸ” Company content access settings")
    if not companies:
        st.info(zh("å°šç„¡å…¬å¸å¯è¨­å®šã€‚", "å°šæ— å…¬å¸å¯è®¾ç½®ã€‚") if lang == "zh" else "No companies to configure.")
    else:
        for code, entry in companies.items():
            label = f"{entry.get('company_name') or code} ({code})"
            key = f"content_access_{code}"
            current_val = entry.get("content_access", False)
            st.checkbox(label + (zh(" â€” å¯æª¢è¦–å­¸ç”Ÿåˆ†æä½¿ç”¨é‡", " â€” å¯æŸ¥çœ‹å­¦å‘˜åˆ†æä½¿ç”¨é‡") if lang == "zh" else " â€” can view user usage details"), value=current_val, key=key)

        if st.button(zh("å„²å­˜å…¬å¸æ¬Šé™è¨­å®š", "ä¿å­˜å…¬å¸æƒé™è®¾ç½®") if lang == "zh" else "Save company access settings"):
            for code, entry in companies.items():
                key = f"content_access_{code}"
                new_val = bool(st.session_state.get(key, entry.get("content_access", False)))
                entry["content_access"] = new_val
                companies[code] = entry
            save_companies(companies)
            st.success(zh("å·²æ›´æ–°å…¬å¸æ¬Šé™è¨­å®šã€‚", "å·²æ›´æ–°å…¬å¸æƒé™è®¾ç½®ã€‚") if lang == "zh" else "Company settings updated.")



if "show_admin" not in st.session_state:
    st.session_state.show_admin = False


def admin_router() -> bool:
    if st.session_state.show_admin:
        role = st.session_state.get("user_role")
        if role == "company_admin":
            company_admin_dashboard()
        else:
            admin_dashboard()
        if st.button("Back to analysis" if st.session_state.get("lang", "zh") == "en" else zh("è¿”å›åˆ†æé é¢", "è¿”å›åˆ†æé¡µé¢")):
            st.session_state.show_admin = False
            save_state_to_disk()
            st.rerun()
        return True
    return False





# =========================
# Branding
# =========================

BRAND_TITLE_EN = "Error-FreeÂ® Intelligence Engine"
BRAND_TAGLINE_EN = "An AI-enhanced intelligence engine that helps organizations analyze risks, prevent errors, and make better decisions."
BRAND_SUBTITLE_EN = "Pioneered and refined by Dr. Chiuâ€™s Error-FreeÂ® team since 1987."

BRAND_TITLE_ZH = zh("é›¶éŒ¯èª¤æ™ºèƒ½å¼•æ“", "é›¶é”™è¯¯æ™ºèƒ½å¼•æ“")
BRAND_TAGLINE_ZH = zh("ä¸€å¥— AI å¼·åŒ–çš„æ™ºèƒ½å¼•æ“ï¼Œå”åŠ©å…¬å¸æˆ–çµ„ç¹”é€²è¡Œé¢¨éšªåˆ†æã€é é˜²éŒ¯èª¤ï¼Œä¸¦æå‡æ±ºç­–å“è³ªã€‚", "ä¸€å¥— AI å¼ºåŒ–çš„æ™ºèƒ½å¼•æ“ï¼ŒååŠ©å…¬å¸æˆ–ç»„ç»‡è¿›è¡Œé£é™©åˆ†æã€é¢„é˜²é”™è¯¯ï¼Œå¹¶æå‡å†³ç­–å“è´¨ã€‚")
BRAND_SUBTITLE_ZH = zh("é‚±åšå£«é›¶éŒ¯èª¤åœ˜éšŠè‡ª 1987 å¹´èµ·é ˜å…ˆç ”ç™¼ä¸¦æŒçºŒæ·±åŒ–è‡³ä»Šã€‚", "é‚±åšå£«é›¶é”™è¯¯å›¢é˜Ÿè‡ª 1987 å¹´èµ·é¢†å…ˆç ”å‘å¹¶æŒç»­æ·±åŒ–è‡³ä»Šã€‚")

LOGO_PATH = "assets/errorfree_logo.png"

# =========================
# Portal-driven Language Lock + Logout UX
# =========================

def _get_query_param_any(keys):
    """Best-effort read query params across Streamlit versions."""
    # Streamlit newer: st.query_params (dict-like)
    try:
        qp = dict(st.query_params)
        for k in keys:
            v = qp.get(k)
            if v is None:
                continue
            if isinstance(v, list):
                if v:
                    return v[0]
            else:
                return v
    except Exception:
        pass

    # Streamlit older: st.experimental_get_query_params()
    try:
        qp = st.experimental_get_query_params()
        for k in keys:
            v = qp.get(k)
            if not v:
                continue
            if isinstance(v, list):
                return v[0]
            return v
    except Exception:
        pass

    return None


def apply_portal_language_lock():
    """
    Portal å·²ç¶“é¸å¥½èªè¨€ï¼ŒAnalyzer ç«¯åªæ¥å—å®ƒï¼Œä¸¦é–å®šä¸è®“ä½¿ç”¨è€…åœ¨ Analyzer å…§åˆ‡æ›ã€‚
    - æ”¯æ´ query: ?lang=en|zh|zh-tw|zh-cn / ?language=...
    """
    # åªè¦ Portal SSO æœ‰è·‘éï¼ˆä½ å‰é¢å·²å®Œæˆ try_portal_sso_login æµç¨‹ï¼‰ï¼Œå°±é–èªè¨€
    if st.session_state.get("_portal_sso_checked"):
        st.session_state["_lang_locked"] = True

    # è‹¥å·²ç¶“é–äº†ï¼Œå„ªå…ˆç”¨ querystring ä¾†è¨­å®šä¸€æ¬¡
    if st.session_state.get("_lang_locked"):
        raw = (_get_query_param_any(["lang", "language", "ui_lang", "locale"]) or "").strip().lower()

        # å¸¸è¦‹æ˜ å°„
        if raw in ["en", "eng", "english"]:
            st.session_state["lang"] = "en"
        elif raw in ["zh", "zh-tw", "zh_tw", "tw", "traditional", "zh-hant"]:
            st.session_state["lang"] = "zh"
            st.session_state["zh_variant"] = "tw"
        elif raw in ["zh-cn", "zh_cn", "cn", "simplified", "zh-hans"]:
            st.session_state["lang"] = "zh"
            st.session_state["zh_variant"] = "cn"
        # raw ç©ºæˆ–æœªçŸ¥ï¼šä¸è¦†è“‹æ—¢æœ‰ langï¼ˆä¿ç•™ä½ åŸæœ¬é è¨­ï¼‰


def render_logged_out_page():
    """
    ç™»å‡ºå¾Œé¡¯ç¤ºä¸€å€‹ä¹¾æ·¨çš„é é¢ï¼Œä¸å›åˆ°èˆŠç™»å…¥/èˆŠä»‹é¢ï¼Œé¿å…æ··æ·†ã€‚
    """
    portal_base = (os.getenv("PORTAL_BASE_URL", "") or "").rstrip("/")
    lang = st.session_state.get("lang", "en")
    zhv = st.session_state.get("zh_variant", "tw")

    is_zh = (lang == "zh")
    if is_zh:
        lang_q = "zh" if zhv == "tw" else "zh"  # Portal ç«¯è‹¥åªåƒ zh/enï¼Œå°±çµ¦ zh
        title = "å·²ç™»å‡º"
        msg = "ä½ å·²æˆåŠŸç™»å‡º Analyzerã€‚è«‹å›åˆ° Portal é‡æ–°é€²å…¥ï¼ˆPortal æœƒé‡æ–°ç”¢ç”ŸçŸ­æ•ˆ tokenï¼‰ã€‚"
        btn1 = "å›åˆ° Portal"
        btn2 = "é‡æ–°ç™»å…¥ï¼ˆå› Portalï¼‰"
    else:
        lang_q = "en"
        title = "Signed out"
        msg = "You have signed out from Analyzer. Please return to Portal to sign in again (Portal will issue a new short-lived token)."
        btn1 = "Back to Portal"
        btn2 = "Sign in again (via Portal)"

    st.title(title)
    st.info(msg)

    if portal_base:
        # å»ºè­°å›åˆ° Portal çš„ catalogï¼ˆå¦‚æœä½ çš„ Portal æœ‰ /catalog å°±ç”¨å®ƒï¼›æ²’æœ‰ä¹Ÿæ²’é—œä¿‚ï¼Œå›é¦–é ä¹Ÿå¯ï¼‰
        portal_url_candidates = [
            f"{portal_base}/catalog?lang={lang_q}",
            f"{portal_base}/?lang={lang_q}",
            f"{portal_base}",
        ]
        # å…ˆæ”¾æœ€å¯èƒ½çš„
        st.link_button(btn1, portal_url_candidates[0])
        st.link_button(btn2, portal_url_candidates[1])
        st.caption(f"Portal: {portal_base}")
    else:
        st.warning("PORTAL_BASE_URL is not set. Please set it in Railway Variables so the logout page can link back to Portal.")

    st.markdown("---")
    st.caption("You can close this tab/window after returning to Portal." if not is_zh else "å›åˆ° Portal å¾Œå¯ç›´æ¥é—œé–‰æ­¤åˆ†é /è¦–çª—ã€‚")

def language_selector():
    """
    Analyzer ç«¯èªè¨€ï¼šè‹¥ Portal SSO æµç¨‹å·²å•Ÿç”¨ï¼Œå‰‡é–å®šèªè¨€ï¼Œä¸æä¾›åˆ‡æ›ï¼Œé¿å…æ··æ·†ã€‚
    """
    # å…ˆå¥—ç”¨ Portal lock
    apply_portal_language_lock()

    lang = st.session_state.get("lang", "zh")
    zhv = st.session_state.get("zh_variant", "tw")

    if st.session_state.get("_lang_locked"):
        # åªé¡¯ç¤ºï¼Œä¸å…è¨±æ›´æ”¹
        if lang == "en":
            st.sidebar.caption("Language: English (locked by Portal)")
        else:
            label = "èªè¨€ï¼šä¸­æ–‡ç¹é«”ï¼ˆç”± Portal é–å®šï¼‰" if zhv == "tw" else "è¯­è¨€ï¼šä¸­æ–‡ç®€ä½“ï¼ˆç”± Portal é”å®šï¼‰"
            st.sidebar.caption(label)
        return

    # fallbackï¼šå¦‚æœæœªèµ° Portal SSOï¼ˆä¾‹å¦‚æœªä¾†ä½ è¦ä¿ç•™ç´” Analyzer ç™»å…¥ï¼‰ï¼Œæ‰å…è¨±åˆ‡æ›
    st.sidebar.markdown("### Language / èªè¨€")
    choice = st.sidebar.radio(
        "Language",
        options=["English", "ä¸­æ–‡ç®€ä½“", "ä¸­æ–‡ç¹é«”"],
        label_visibility="collapsed",
        index=0 if lang == "en" else (1 if (lang == "zh" and zhv == "cn") else 2),
    )
    if choice == "English":
        st.session_state["lang"] = "en"
    elif choice == "ä¸­æ–‡ç®€ä½“":
        st.session_state["lang"] = "zh"
        st.session_state["zh_variant"] = "cn"
    else:
        st.session_state["lang"] = "zh"
        st.session_state["zh_variant"] = "tw"





# =========================
# UI helper (NEW, minimal)
# =========================

def inject_ui_css():
    """Make Results section more prominent + normalize Step heading sizes (UI-only)."""
    st.markdown(
        """
<style>
/* Make analysis step titles match RESULTS step titles */
.stMarkdown h2, .stSubheader, .stHeader {
  font-size: 24px !important;
}

/* Strong "RESULTS" banner */
.ef-results-banner {
  padding: 14px 16px;
  border-radius: 12px;
  border: 1px solid rgba(49, 51, 63, 0.20);
  background: rgba(49, 51, 63, 0.04);
  margin: 12px 0 14px 0;
}
.ef-results-banner .title {
  font-size: 28px;
  font-weight: 800;
  letter-spacing: 0.5px;
  margin-bottom: 4px;
}
.ef-results-banner .subtitle {
  font-size: 14px;
  opacity: 0.80;
}

/* Normalize our Step headers (we render as markdown h3 inside a wrapper) */
.ef-step-title {
  font-size: 24px;
  font-weight: 800;
  margin: 4px 0 6px 0;
}

/* Keep analysis content headings from becoming larger than the Step title.
   (LLM outputs often include markdown H1/H2 which Streamlit renders huge.) */
div[data-testid="stExpander"] .stMarkdown h1 { font-size: 22px; }
div[data-testid="stExpander"] .stMarkdown h2 { font-size: 20px; }
div[data-testid="stExpander"] .stMarkdown h3 { font-size: 18px; }
div[data-testid="stExpander"] .stMarkdown h4 { font-size: 13px; }
div[data-testid="stExpander"] .stMarkdown h5 { font-size: 12px; }
div[data-testid="stExpander"] .stMarkdown h6 { font-size: 12px; }

/* Make expander header look cleaner */
div[data-testid="stExpander"] details summary p {
  font-weight: 700;
}

/* Large, obvious "running" indicator (separate from Streamlit's tiny top-right icon) */
.ef-running {
  margin: 10px 0 14px 0;
  padding: 14px 16px;
  border-radius: 12px;
  border: 1px solid rgba(255, 75, 75, 0.25);
  background: rgba(255, 75, 75, 0.06);
}
.ef-running .row { display: flex; align-items: center; gap: 12px; }
.ef-running .label { font-size: 16px; font-weight: 800; }
.ef-spinner {
  width: 22px; height: 22px;
  border-radius: 999px;
  border: 3px solid rgba(49, 51, 63, 0.20);
  border-top-color: rgba(255, 75, 75, 0.80);
  animation: efspin 0.9s linear infinite;
}
@keyframes efspin { to { transform: rotate(360deg); } }

/* Download link styled like a button (avoids 404s from reverse-proxy paths) */
.ef-download-btn {
  display: inline-block;
  padding: 10px 16px;
  border-radius: 10px;
  border: 1px solid rgba(49, 51, 63, 0.25);
  text-decoration: none !important;
  font-weight: 700;
}
</style>
        """,
        unsafe_allow_html=True,
    )


def build_data_download_link(data: bytes, filename: str, mime: str, label: str) -> str:
    """Return an HTML download button without navigating away.

    Uses an inline JS Blob download to avoid Streamlit's download endpoint (which can
    return 404 behind certain reverse proxies) *and* prevent the page from navigating
    to a data: URL after click.
    """
    b64 = base64.b64encode(data).decode("ascii")
    # Note: onclick returns false to prevent navigation.
    return f"""<a class='ef-download-btn' href='#' onclick="(function(){{
  try {{
    const b64 = '{b64}';
    const byteChars = atob(b64);
    const byteNums = new Array(byteChars.length);
    for (let i = 0; i < byteChars.length; i++) byteNums[i] = byteChars.charCodeAt(i);
    const byteArray = new Uint8Array(byteNums);
    const blob = new Blob([byteArray], {{ type: '{mime}' }});
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = '{filename}';
    document.body.appendChild(a);
    a.click();
    a.remove();
    setTimeout(() => URL.revokeObjectURL(url), 1000);
  }} catch (e) {{
    console.error('download failed', e);
  }}
  return false;
}})();" >{label}</a>"""



def show_running_banner(text: str):
    """Show a large, obvious 'running' indicator and return a placeholder handle."""
    ph = st.empty()
    ph.markdown(
        f"""
<div class="ef-running">
  <div class="row">
    <div class="ef-spinner"></div>
    <div class="label">{text}</div>
  </div>
</div>
        """,
        unsafe_allow_html=True,
    )
    return ph


def render_step_block(title: str, body_markdown: str, expanded: bool = False):
    """Render a Step section with consistent title and collapsible body."""
    st.markdown(f'<div class="ef-step-title">{title}</div>', unsafe_allow_html=True)
    if body_markdown and body_markdown.strip():
        with st.expander("Show / Hide" if st.session_state.get("lang", "zh") == "en" else zh("å±•é–‹ / æ”¶èµ·", "å±•å¼€ / æ”¶èµ·"), expanded=expanded):
            st.markdown(body_markdown)
    else:
        st.info("No content yet." if st.session_state.get("lang", "zh") == "en" else zh("å°šç„¡å…§å®¹ã€‚", "å°šæ— å†…å®¹ã€‚"))


def render_followup_history_chat(followup_history: List, lang: str):
    """Render follow-up Q&A history in a compact, click-to-view format.
    Supports both legacy tuple items: (question, answer) and dict items.
    """
    if not followup_history:
        st.info("No follow-up yet." if lang == "en" else zh("å°šç„¡è¿½å•ã€‚", "æš‚æ— è¿½é—®ã€‚"))
        return

    with st.expander("Follow-up history (click to view)" if lang == "en" else zh("è¿½å•æ­·å²ï¼ˆé»æ“ŠæŸ¥çœ‹ï¼‰", "è¿½é—®å†å²ï¼ˆç‚¹å‡»æŸ¥çœ‹ï¼‰"), expanded=False):
        for idx, item in enumerate(followup_history, start=1):
            q = ""
            a = ""
            if isinstance(item, dict):
                q = (item.get("question") or item.get("q") or "").strip()
                a = (item.get("answer") or item.get("a") or "").strip()
            elif isinstance(item, (list, tuple)):
                if len(item) >= 1:
                    q = str(item[0]).strip() if item[0] is not None else ""
                if len(item) >= 2:
                    a = str(item[1]).strip() if item[1] is not None else ""
            else:
                # Fallback: render as string
                q = str(item).strip()

            title = q if q else (f"Q{idx}")
            if len(title) > 120:
                title = title[:117] + "..."

            with st.expander(f"{idx}. {title}", expanded=False):
                if q:
                    st.chat_message("user").markdown(q)
                if a:
                    st.chat_message("assistant").markdown(a)
                if (not q) and (not a):
                    st.info("No content." if lang == "en" else zh("å°šç„¡å…§å®¹ã€‚", "æš‚æ— å†…å®¹ã€‚"))
def _reset_whole_document():
    st.session_state.framework_states = {}
    st.session_state.last_doc_text = ""
    st.session_state.last_doc_name = ""
    st.session_state.document_type = None
    st.session_state.current_doc_id = None

    # Step 3 references (æ›´æ­£2)
    st.session_state.upstream_reference = None
    st.session_state.quote_current = None
    st.session_state.quote_history = []
    st.session_state.quote_upload_nonce = 0

    # Clear Streamlit uploader widget states so UI is truly reset
    for _k in list(st.session_state.keys()):
        if _k.startswith("quote_uploader_"):
            del st.session_state[_k]
        if _k.startswith("review_doc_uploader_"):
            del st.session_state[_k]
        if _k.startswith("upstream_uploader_"):
            del st.session_state[_k]
    # also clear legacy single-key uploaders (older deployments)
    for _legacy in ["review_doc_uploader", "upstream_uploader"]:
        if _legacy in st.session_state:
            del st.session_state[_legacy]
    st.session_state["quote_upload_nonce"] = int(st.session_state.get("quote_upload_nonce", 0)) + 1
    st.session_state["review_upload_nonce"] = int(st.session_state.get("review_upload_nonce", 0)) + 1
    st.session_state["upstream_upload_nonce"] = int(st.session_state.get("upstream_upload_nonce", 0)) + 1
    st.session_state.quote_upload_finalized = False
    st.session_state.upstream_step6_done = False
    st.session_state.upstream_step6_output = ""
    st.session_state.quote_step6_done_current = False

    st.session_state.step7_history = []

    # Follow-up clear flag (fix)
    st.session_state._pending_clear_followup_key = None
   
    # Portal SSO: allow re-check on next entry
    st.session_state["_portal_sso_checked"] = False
    save_state_to_disk()


def main():
    st.set_page_config(page_title=BRAND_TITLE_EN, layout="wide")
    restore_state_from_disk()

    inject_ui_css()

    defaults = [
        ("user_email", None),
        ("user_role", None),
        ("is_authenticated", False),
        ("lang", "zh"),
        ("zh_variant", "tw"),
        ("usage_date", None),
        ("usage_count", 0),
        ("last_doc_text", ""),
        ("last_doc_name", ""),
        ("document_type", None),
        ("framework_states", {}),
        ("selected_framework_key", None),
        ("current_doc_id", None),
        ("company_code", None),
        ("show_admin", False),

        # Step 3 split references (æ›´æ­£2)
        ("upstream_reference", None),         # dict or None
        ("quote_current", None),              # dict or None (single upload slot)
        ("quote_history", []),                # list of analyzed quote relevance records
        ("quote_upload_nonce", 0),            # reset uploader key to allow unlimited quote ref uploads
        ("quote_upload_finalized", False),    # user confirmed no more quote refs will be uploaded
        ("upstream_step6_done", False),
        ("upstream_step6_output", ""),
        ("quote_step6_done_current", False),

        # Step 7 history (keep old integration outputs when re-running)
        ("step7_history", []),

        # Follow-up clear flag (fix StreamlitAPIException)
        ("_pending_clear_followup_key", None),
    ]
    for k, v in defaults:
        if k not in st.session_state:
            st.session_state[k] = v

    if st.session_state.selected_framework_key is None and FRAMEWORKS:
        st.session_state.selected_framework_key = list(FRAMEWORKS.keys())[0]

    doc_tracking = load_doc_tracking()
        # -------------------------
    # Portal SSO MUST run early
    # -------------------------
    # Critical: run SSO right after session defaults are ready,
    # and BEFORE any login UI is rendered.
    try_portal_sso_login()

    with st.sidebar:
        language_selector()
        lang = st.session_state.lang

        if st.session_state.is_authenticated and st.session_state.user_role in ["admin", "pro", "company_admin"]:
            if st.button("Admin Dashboard"):
                st.session_state.show_admin = True
                save_state_to_disk()
                st.rerun()

        st.markdown("---")
        if st.session_state.is_authenticated:
            st.subheader("Account" if lang == "en" else zh("å¸³è™Ÿè³‡è¨Š", "è´¦å·ä¿¡æ¯"))
            st.write(f"Email: {st.session_state.user_email}" if lang == "en" else f"Emailï¼š{st.session_state.user_email}")
            if st.button("Logout" if st.session_state.get("lang", "zh") == "en" else "ç™»å‡º"):
    # æ¸…æ‰ç™»å…¥ç‹€æ…‹
    st.session_state["is_authenticated"] = False

    # å»ºè­°ï¼šæ¸…æ‰ user è³‡è¨Šï¼Œé¿å…å›åˆ°èˆŠä»‹é¢æ®˜ç•™
    for k in ["user_email", "user_role", "company_code", "selected_framework_key", "show_admin"]:
        if k in st.session_state:
            st.session_state[k] = None

    # æ¸…æ‰ portal cookieï¼ˆå¦‚æœä½ å…ˆå‰æœ‰åš cookie å¯«å…¥ï¼‰
    # â€» å¦‚æœä½ åŸæœ¬æœ‰ clear cookie çš„å‡½å¼ï¼Œä¿ç•™å‘¼å«å³å¯
    try:
        clear_portal_cookie()  # è‹¥ä½ æœ‰é€™å€‹å‡½å¼
    except Exception:
        pass

    # æ¸…æ‰ querystringï¼ˆé¿å…æ®˜ç•™é€ æˆèª¤æœƒï¼‰
    try:
        st.query_params.clear()
    except Exception:
        try:
            st.experimental_set_query_params()
        except Exception:
            pass

    # å­˜æª”ï¼ˆè‹¥ä½ åŸæœ¬å°±æœ‰ï¼‰
    try:
        save_state_to_disk()
    except Exception:
        pass

    # ç›´æ¥é¡¯ç¤ºã€Œç™»å‡ºå®Œæˆé ã€ï¼Œä¸è¦å›èˆŠç™»å…¥ä»‹é¢
    render_logged_out_page()
    st.stop()
                st.session_state.user_email = None
                st.session_state.user_role = None
                st.session_state.is_authenticated = False
                    st.session_state["_portal_sso_checked"] = False
                _reset_whole_document()
                save_state_to_disk()
                st.rerun()
        else:
            st.subheader("Not Logged In" if lang == "en" else zh("å°šæœªç™»å…¥", "å°šæœªç™»å½•"))
            if lang == "zh":
                st.markdown(
                    "- " + zh("ä¸Šæ–¹ï¼šå…§éƒ¨å“¡å·¥ / æœƒå“¡ç™»å…¥ã€‚", "ä¸Šæ–¹ï¼šå†…éƒ¨å‘˜å·¥ / ä¼šå‘˜ç™»å½•ã€‚") + "\n"
                    "- " + zh("ä¸­é–“ï¼šå…¬å¸ç®¡ç†è€…ï¼ˆä¼æ¥­ç«¯çª—å£ï¼‰ç™»å…¥ / è¨»å†Šã€‚", "ä¸­é—´ï¼šå…¬å¸ç®¡ç†è€…ï¼ˆä¼ä¸šç«¯çª—å£ï¼‰ç™»å½• / æ³¨å†Œã€‚") + "\n"
                    "- " + zh("ä¸‹æ–¹ï¼šå­¸ç”Ÿ / å®¢æˆ¶çš„ Guest è©¦ç”¨ç™»å…¥ / è¨»å†Šã€‚", "ä¸‹æ–¹ï¼šå­¦å‘˜ / å®¢æˆ·çš„ Guest è¯•ç”¨ç™»å½• / æ³¨å†Œã€‚")
                )
            else:
                st.markdown(
                    "- Top: internal Error-Free employees / members.\n"
                    "- Middle: Company Admins for each client company.\n"
                    "- Bottom: students / end-users using Guest trial accounts."
                )

    # ======= Login screen =======
    if not st.session_state.is_authenticated:
        lang = st.session_state.lang

        if Path(LOGO_PATH).exists():
            st.image(LOGO_PATH, width=260)

        title = BRAND_TITLE_ZH if lang == "zh" else BRAND_TITLE_EN
        tagline = BRAND_TAGLINE_ZH if lang == "zh" else BRAND_TAGLINE_EN
        subtitle = BRAND_SUBTITLE_ZH if lang == "zh" else BRAND_SUBTITLE_EN

        st.title(title)
        st.write(tagline)
        st.caption(subtitle)
        st.markdown("---")

        if lang == "zh":
            st.markdown(
                zh(
                    "æœ¬ç³»çµ±é‹ç”¨ AI æå‡å¯©é–±æµç¨‹çš„é€Ÿåº¦èˆ‡å»£åº¦ï¼Œå”åŠ©åœ˜éšŠæ›´æ—©ä¸”æ›´æœ‰æ•ˆåœ°è­˜åˆ¥æ½›åœ¨é¢¨éšªèˆ‡ä¸å¯æ¥å—çš„éŒ¯èª¤ï¼Œé™ä½ä¼æ¥­æå¤±çš„å¯èƒ½æ€§ã€‚æœ€çµ‚æ±ºç­–ä»ç”±å…·å‚™å°ˆæ¥­çŸ¥è­˜ã€ç¶“é©—èˆ‡æƒ…å¢ƒåˆ¤æ–·èƒ½åŠ›çš„äººå“¡è² è²¬ï¼›AI çš„è§’è‰²åœ¨æ–¼è¼”åŠ©ã€å¼·åŒ–èˆ‡æé†’ï¼Œè€Œéå–ä»£äººé¡çš„åˆ¤æ–·ã€‚",
                    "æœ¬ç³»ç»Ÿè¿ç”¨ AI æå‡å®¡é˜…æµç¨‹çš„é€Ÿåº¦ä¸å¹¿åº¦ï¼ŒååŠ©å›¢é˜Ÿæ›´æ—©ä¸”æ›´æœ‰æ•ˆåœ°è¯†åˆ«æ½œåœ¨é£é™©ä¸ä¸å¯æ¥å—çš„é”™è¯¯ï¼Œé™ä½ä¼ä¸šæŸå¤±çš„å¯èƒ½æ€§ã€‚æœ€ç»ˆå†³ç­–ä»ç”±å…·å¤‡ä¸“ä¸šçŸ¥è¯†ã€ç»éªŒä¸æƒ…å¢ƒåˆ¤æ–­èƒ½åŠ›çš„äººå‘˜è´Ÿè´£ï¼›AI çš„è§’è‰²åœ¨äºè¾…åŠ©ã€å¼ºåŒ–ä¸æé†’ï¼Œè€Œéå–ä»£äººç±»çš„åˆ¤æ–­ã€‚",
                )
            )
        else:
            st.markdown(
                "AI is used to enhance the speed and breadth of the review processâ€”helping teams identify potential risks and unacceptable errors earlier and more efficiently. "
                "Final decisions, however, remain the responsibility of human experts, who apply professional judgment, experience, and contextual understanding. "
                "The role of AI is to assist, augment, and alertâ€”not to replace human decision-making."
            )

        st.markdown("---")

        st.markdown("### Internal Employee / Member Login" if lang == "en" else "### " + zh("å…§éƒ¨å“¡å·¥ / æœƒå“¡ç™»å…¥", "å†…éƒ¨å‘˜å·¥ / ä¼šå‘˜ç™»å½•"))
        emp_email = st.text_input("Email", key="emp_email")
        emp_pw = st.text_input("Password" if lang == "en" else zh("å¯†ç¢¼", "å¯†ç "), type="password", key="emp_pw")
        if st.button("Login" if lang == "en" else zh("ç™»å…¥", "ç™»å½•"), key="emp_login_btn"):
            account = ACCOUNTS.get(emp_email)
            if account and account["password"] == emp_pw:
                st.session_state.user_email = emp_email
                st.session_state.user_role = account["role"]
                st.session_state.is_authenticated = True
                save_state_to_disk()
                st.rerun()
            else:
                st.error("Invalid email or password" if lang == "en" else zh("å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤", "è´¦å·æˆ–å¯†ç é”™è¯¯"))

        st.markdown("---")

        st.markdown("### Company Admin (Client-side)" if lang == "en" else "### " + zh("å…¬å¸ç®¡ç†è€…ï¼ˆä¼æ¥­çª—å£ï¼‰", "å…¬å¸ç®¡ç†è€…ï¼ˆä¼ä¸šçª—å£ï¼‰"))
        col_ca_signup, col_ca_login = st.columns(2)

        with col_ca_signup:
            st.markdown("**Company Admin Signup**" if lang == "en" else "**" + zh("å…¬å¸ç®¡ç†è€…è¨»å†Š", "å…¬å¸ç®¡ç†è€…æ³¨å†Œ") + "**")
            ca_new_email = st.text_input("Admin signup email" if lang == "en" else zh("ç®¡ç†è€…è¨»å†Š Email", "ç®¡ç†è€…æ³¨å†Œ Email"), key="ca_new_email")
            ca_new_pw = st.text_input("Set admin password" if lang == "en" else zh("è¨­å®šç®¡ç†è€…å¯†ç¢¼", "è®¾ç½®ç®¡ç†è€…å¯†ç "), type="password", key="ca_new_pw")
            ca_company_code = st.text_input("Company Code", key="ca_company_code")

            if st.button("Create Company Admin Account" if lang == "en" else zh("å»ºç«‹ç®¡ç†è€…å¸³è™Ÿ", "å»ºç«‹ç®¡ç†è€…è´¦å·"), key="ca_signup_btn"):
                if not ca_new_email or not ca_new_pw or not ca_company_code:
                    st.error("Please fill all admin signup fields" if lang == "en" else zh("è«‹å®Œæ•´å¡«å¯«ç®¡ç†è€…è¨»å†Šè³‡è¨Š", "è¯·å®Œæ•´å¡«å†™ç®¡ç†è€…æ³¨å†Œä¿¡æ¯"))
                else:
                    companies = load_companies()
                    guests = load_guest_accounts()
                    if ca_company_code not in companies:
                        st.error("Company code not found. Please ask the system admin to create it." if lang == "en" else zh("å…¬å¸ä»£ç¢¼ä¸å­˜åœ¨ï¼Œè«‹å…ˆå‘ç³»çµ±ç®¡ç†å“¡å»ºç«‹å…¬å¸", "å…¬å¸ä»£ç ä¸å­˜åœ¨ï¼Œè¯·å…ˆå‘ç³»ç»Ÿç®¡ç†å‘˜å»ºç«‹å…¬å¸"))
                    elif ca_new_email in ACCOUNTS or ca_new_email in guests:
                        st.error("This email is already in use" if lang == "en" else zh("æ­¤ Email å·²è¢«ä½¿ç”¨", "æ­¤ Email å·²è¢«ä½¿ç”¨"))
                    else:
                        guests[ca_new_email] = {"password": ca_new_pw, "role": "company_admin", "company_code": ca_company_code}
                        save_guest_accounts(guests)

                        entry = companies[ca_company_code]
                        admins = entry.get("admins", [])
                        if ca_new_email not in admins:
                            admins.append(ca_new_email)
                        entry["admins"] = admins
                        entry.setdefault("company_name", "")
                        entry.setdefault("content_access", False)
                        companies[ca_company_code] = entry
                        save_companies(companies)

                        st.success("Company admin account created" if lang == "en" else zh("å…¬å¸ç®¡ç†è€…å¸³è™Ÿå·²å»ºç«‹", "å…¬å¸ç®¡ç†è€…è´¦å·å·²å»ºç«‹"))

        with col_ca_login:
            st.markdown("**Company Admin Login**" if lang == "en" else "**" + zh("å…¬å¸ç®¡ç†è€…ç™»å…¥", "å…¬å¸ç®¡ç†è€…ç™»å½•") + "**")
            ca_email = st.text_input("Admin Email" if lang == "en" else "ç®¡ç†è€… Email", key="ca_email")
            ca_pw = st.text_input("Admin Password" if lang == "en" else zh("ç®¡ç†è€…å¯†ç¢¼", "ç®¡ç†è€…å¯†ç "), type="password", key="ca_pw")
            if st.button("Login as Company Admin" if lang == "en" else zh("ç®¡ç†è€…ç™»å…¥", "ç®¡ç†è€…ç™»å½•"), key="ca_login_btn"):
                guests = load_guest_accounts()
                acc = guests.get(ca_email)
                if acc and acc.get("password") == ca_pw and acc.get("role") == "company_admin":
                    st.session_state.user_email = ca_email
                    st.session_state.user_role = "company_admin"
                    st.session_state.company_code = acc.get("company_code")
                    st.session_state.is_authenticated = True
                    save_state_to_disk()
                    st.rerun()
                else:
                    st.error("Invalid company admin credentials" if lang == "en" else zh("ç®¡ç†è€…å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤", "ç®¡ç†è€…è´¦å·æˆ–å¯†ç é”™è¯¯"))

        st.markdown("---")

        st.markdown("### Guest Trial Accounts" if lang == "en" else "### " + zh("Guest è©¦ç”¨å¸³è™Ÿ", "Guest è¯•ç”¨è´¦å·"))
        col_guest_signup, col_guest_login = st.columns(2)

        with col_guest_signup:
            st.markdown("**Guest Signup**" if lang == "en" else "**" + zh("Guest è©¦ç”¨è¨»å†Š", "Guest è¯•ç”¨æ³¨å†Œ") + "**")
            new_guest_email = st.text_input("Email for signup" if lang == "en" else zh("è¨»å†Š Email", "æ³¨å†Œ Email"), key="new_guest_email")
            guest_company_code = st.text_input("Company Code", key="guest_company_code")

            if st.button("Generate Guest Password" if lang == "en" else zh("å–å¾— Guest å¯†ç¢¼", "è·å– Guest å¯†ç "), key="guest_signup_btn"):
                if not new_guest_email:
                    st.error("Please enter an email" if lang == "en" else zh("è«‹è¼¸å…¥ Email", "è¯·è¾“å…¥ Email"))
                elif not guest_company_code:
                    st.error("Please enter your Company Code" if lang == "en" else zh("è«‹è¼¸å…¥å…¬å¸ä»£ç¢¼", "è¯·è¾“å…¥å…¬å¸ä»£ç "))
                else:
                    guests = load_guest_accounts()
                    companies = load_companies()
                    if guest_company_code not in companies:
                        st.error("Invalid Company Code. Please check with your instructor or admin." if lang == "en" else zh("å…¬å¸ä»£ç¢¼ä¸å­˜åœ¨ï¼Œè«‹å‘è¬›å¸«æˆ–å…¬å¸çª—å£ç¢ºèª", "å…¬å¸ä»£ç ä¸å­˜åœ¨ï¼Œè¯·å‘è®²å¸ˆæˆ–å…¬å¸çª—å£ç¡®è®¤"))
                    elif new_guest_email in guests or new_guest_email in ACCOUNTS:
                        st.error("Email already exists" if lang == "en" else zh("Email å·²å­˜åœ¨", "Email å·²å­˜åœ¨"))
                    else:
                        pw = "".join(secrets.choice("0123456789") for _ in range(8))
                        guests[new_guest_email] = {"password": pw, "role": "free", "company_code": guest_company_code}
                        save_guest_accounts(guests)

                        entry = companies[guest_company_code]
                        users = entry.get("users", [])
                        if new_guest_email not in users:
                            users.append(new_guest_email)
                        entry["users"] = users
                        entry.setdefault("company_name", "")
                        entry.setdefault("content_access", False)
                        companies[guest_company_code] = entry
                        save_companies(companies)

                        st.success(f"Guest account created! Password: {pw}" if lang == "en" else zh(f"Guest å¸³è™Ÿå·²å»ºç«‹ï¼å¯†ç¢¼ï¼š{pw}", f"Guest è´¦å·å·²å»ºç«‹ï¼å¯†ç ï¼š{pw}"))

        with col_guest_login:
            st.markdown("**Guest Login**" if lang == "en" else "**" + zh("Guest è©¦ç”¨ç™»å…¥", "Guest è¯•ç”¨ç™»å½•") + "**")
            g_email = st.text_input("Guest Email", key="g_email")
            g_pw = st.text_input("Password" if lang == "en" else zh("å¯†ç¢¼", "å¯†ç "), type="password", key="g_pw")
            if st.button("Login as Guest" if lang == "en" else zh("ç™»å…¥ Guest", "ç™»å½• Guest"), key="guest_login_btn"):
                guests = load_guest_accounts()
                g_acc = guests.get(g_email)
                if g_acc and g_acc.get("password") == g_pw:
                    st.session_state.company_code = g_acc.get("company_code")
                    st.session_state.user_email = g_email
                    st.session_state.user_role = "free"
                    st.session_state.is_authenticated = True
                    save_state_to_disk()
                    st.rerun()
                else:
                    st.error("Invalid guest credentials" if lang == "en" else zh("å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤", "è´¦å·æˆ–å¯†ç é”™è¯¯"))

        return  # login page end

    # ======= Main app (logged in) =======
    if admin_router():
        return

    lang = st.session_state.lang

    if Path(LOGO_PATH).exists():
        st.image(LOGO_PATH, width=260)

    st.title(BRAND_TITLE_ZH if lang == "zh" else BRAND_TITLE_EN)
    st.write(BRAND_TAGLINE_ZH if lang == "zh" else BRAND_TAGLINE_EN)
    st.caption(BRAND_SUBTITLE_ZH if lang == "zh" else BRAND_SUBTITLE_EN)
    st.markdown("---")

    user_email = st.session_state.user_email
    user_role = st.session_state.user_role
    is_guest = user_role == "free"
    model_name = resolve_model_for_user(user_role)

    # Framework state setup
    if not FRAMEWORKS:
        st.error(zh("å°šæœªåœ¨ frameworks.json ä¸­å®šç¾©ä»»ä½•æ¡†æ¶ã€‚", "å°šæœªåœ¨ frameworks.json ä¸­å®šä¹‰ä»»ä½•æ¡†æ¶ã€‚") if lang == "zh" else "No frameworks defined in frameworks.json.")
        return

    fw_keys = list(FRAMEWORKS.keys())
    fw_labels = [FRAMEWORKS[k]["name_zh"] if lang == "zh" else FRAMEWORKS[k]["name_en"] for k in fw_keys]
    key_to_label = dict(zip(fw_keys, fw_labels))
    label_to_key = dict(zip(fw_labels, fw_keys))

    current_fw_key = st.session_state.selected_framework_key or fw_keys[0]
    if current_fw_key not in fw_keys:
        current_fw_key = fw_keys[0]

    framework_states = st.session_state.framework_states
    if current_fw_key not in framework_states:
        framework_states[current_fw_key] = {
            "analysis_done": False,
            "analysis_output": "",
            "followup_history": [],
            "download_used": False,
            "step5_done": False,
            "step5_output": "",
            "step7_done": False,
            "step7_output": "",
            "step7_history": [],
            "step7_quote_count": 0,
            "integration_history": [],
            # Step 8 (NEW)
            "step8_done": False,
            "step8_output": "",
        }
    else:
        state = framework_states[current_fw_key]
        for k, v in [
            ("analysis_done", False),
            ("analysis_output", ""),
            ("followup_history", []),
            ("download_used", False),
            ("step5_done", False),
            ("step5_output", ""),
            ("step7_done", False),
            ("step7_output", ""),
            ("step7_history", []),
            ("step7_quote_count", 0),
            ("integration_history", []),
            ("step8_done", False),
            ("step8_output", ""),
        ]:
            if k not in state:
                state[k] = v

    current_state = framework_states[current_fw_key]
    step5_done = bool(current_state.get("step5_done", False))

    # Step 1: upload review doc
    st.subheader("Step 1: Upload Review Document" if lang == "en" else zh("æ­¥é©Ÿä¸€ï¼šä¸Šå‚³å¯©é–±æ–‡ä»¶", "æ­¥éª¤ä¸€ï¼šä¸Šä¼ å¯©é–±æ–‡ä»¶"))
    st.caption("Note: Only 1 document can be uploaded for a complete content analysis." if lang == "en" else zh("æé†’ï¼šä¸€æ¬¡åªèƒ½ä¸Šè¼‰ 1 ä»½æ–‡ä»¶é€²è¡Œå®Œæ•´å…§å®¹åˆ†æã€‚", "æé†’ï¼šä¸€æ¬¡åªèƒ½ä¸Šä¼  1 ä»½æ–‡ä»¶è¿›è¡Œå®Œæ•´å†…å®¹åˆ†æã€‚"))

    doc_locked = bool(st.session_state.get("last_doc_text"))

    if not doc_locked:
        uploaded = st.file_uploader(
            "Upload PDF / DOCX / TXT / Image" if lang == "en" else zh("è«‹ä¸Šå‚³ PDF / DOCX / TXT / åœ–ç‰‡", "è¯·ä¸Šä¼  PDF / DOCX / TXT / å›¾ç‰‡"),
            type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
            key=f"review_doc_uploader_{st.session_state.get('review_upload_nonce', 0)}",
        )

        if uploaded is not None:
            doc_text = read_file_to_text(uploaded)
            if doc_text:
                if is_guest:
                    docs = doc_tracking.get(user_email, [])
                    if len(docs) >= 3 and st.session_state.current_doc_id not in docs:
                        st.error("Trial accounts may upload up to 3 documents only" if lang == "en" else zh("è©¦ç”¨å¸³è™Ÿæœ€å¤šä¸Šå‚³ 3 ä»½æ–‡ä»¶", "è¯•ç”¨è´¦å·æœ€å¤šä¸Šä¼  3 ä»½æ–‡ä»¶"))
                    else:
                        if st.session_state.current_doc_id not in docs:
                            new_id = f"doc_{datetime.datetime.now().timestamp()}"
                            docs.append(new_id)
                            doc_tracking[user_email] = docs
                            st.session_state.current_doc_id = new_id
                            save_doc_tracking(doc_tracking)
                        st.session_state.last_doc_text = doc_text
                        st.session_state.last_doc_name = uploaded.name
                        save_state_to_disk()
                else:
                    st.session_state.current_doc_id = f"doc_{datetime.datetime.now().timestamp()}"
                    st.session_state.last_doc_text = doc_text
                    st.session_state.last_doc_name = uploaded.name
                    save_state_to_disk()
    else:
        shown_name = st.session_state.get("last_doc_name") or ("(uploaded)" if lang == "en" else zh("ï¼ˆå·²ä¸Šå‚³ï¼‰", "ï¼ˆå·²ä¸Šä¼ ï¼‰"))
        st.info(f"Review document uploaded: {shown_name}. To change it, please use Reset Whole Document." if lang == "en" else zh(f"å·²ä¸Šå‚³å¯©é–±æ–‡ä»¶ï¼š{shown_name}ã€‚å¦‚éœ€æ›´æ›æ–‡ä»¶ï¼Œè«‹ä½¿ç”¨ Reset Whole Documentã€‚", f"å·²ä¸Šä¼ å®¡é˜…æ–‡ä»¶ï¼š{shown_name}ã€‚å¦‚éœ€æ›´æ¢æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ Reset Whole Documentã€‚"))

    # Step 2: Document Type Selection (lock after Step 5)
    st.subheader("Step 2: Document Type Selection" if lang == "en" else zh("æ­¥é©ŸäºŒï¼šæ–‡ä»¶é¡å‹é¸æ“‡ï¼ˆå–®é¸ï¼‰", "æ­¥éª¤äºŒï¼šæ–‡ä»¶ç±»å‹é€‰æ‹©ï¼ˆå•é€‰ï¼‰"))
    st.caption("Single selection" if lang == "en" else zh("å–®é¸", "å•é€‰"))

    DOC_TYPES = [
        "Conceptual Design",
        "Preliminary Design",
        "Final Design",
        "Equivalency Engineering Evaluation",
        "Root Cause Analysis",
        "Safety Analysis",
        "Specifications and Requirements",
        "Calculations and Analysis",
    ]

    DOC_TYPE_LABELS_ZH_TW = {
        "Conceptual Design": "æ¦‚å¿µè¨­è¨ˆ",
        "Preliminary Design": "åˆæ­¥è¨­è¨ˆ",
        "Final Design": "æœ€çµ‚è¨­è¨ˆ",
        "Equivalency Engineering Evaluation": "ç­‰æ•ˆå·¥ç¨‹è©•ä¼°",
        "Root Cause Analysis": "æ ¹æœ¬åŸå› åˆ†æ",
        "Safety Analysis": "å®‰å…¨åˆ†æ",
        "Specifications and Requirements": "è¦æ ¼èˆ‡éœ€æ±‚",
        "Calculations and Analysis": "è¨ˆç®—èˆ‡åˆ†æ",
    }
    DOC_TYPE_LABELS_ZH_CN = {
        "Conceptual Design": "æ¦‚å¿µè®¾è®¡",
        "Preliminary Design": "åˆæ­¥è®¾è®¡",
        "Final Design": "æœ€ç»ˆè®¾è®¡",
        "Equivalency Engineering Evaluation": "ç­‰æ•ˆå·¥ç¨‹è¯„ä¼°",
        "Root Cause Analysis": "æ ¹æœ¬åŸå› åˆ†æ",
        "Safety Analysis": "å®‰å…¨åˆ†æ",
        "Specifications and Requirements": "è§„æ ¼ä¸éœ€æ±‚",
        "Calculations and Analysis": "è®¡ç®—ä¸åˆ†æ",
    }

    if st.session_state.get("document_type") not in DOC_TYPES:
        st.session_state.document_type = DOC_TYPES[0]

    if st.session_state.document_type == "Specifications and Requirements" and not step5_done:
        st.warning(
            "After you run Step 5, the document type will be locked until you Reset Whole Document (to avoid confusion)." if lang == "en"
            else zh("æé†’ï¼šä¸€æ—¦æŒ‰ä¸‹æ­¥é©Ÿäº”é–‹å§‹åˆ†æå¾Œï¼Œæ–‡ä»¶é¡å‹æœƒè¢«é–ä½ï¼Œéœ€ Reset Whole Document æ‰èƒ½é‡æ–°é¸æ“‡ï¼Œé¿å…ä¾†å›åˆ‡æ›é€ æˆæ··æ·†ã€‚", "æé†’ï¼šä¸€æ—¦æŒ‰ä¸‹æ­¥éª¤äº”å¼€å§‹åˆ†æåï¼Œæ–‡ä»¶ç±»å‹ä¼šè¢«é”ä½ï¼Œéœ€ Reset Whole Document æ‰èƒ½é‡æ–°é€‰æ‹©ï¼Œé¿å…æ¥å›åˆ‡æ¢é€ æˆæ··æ·†ã€‚")
        )

    doc_type_disabled = step5_done

    if lang == "zh":
        mapping = DOC_TYPE_LABELS_ZH_CN if st.session_state.get("zh_variant", "tw") == "cn" else DOC_TYPE_LABELS_ZH_TW
        labels = [mapping.get(x, x) for x in DOC_TYPES]
        label_to_value = {mapping.get(x, x): x for x in DOC_TYPES}
        value_to_label = {x: mapping.get(x, x) for x in DOC_TYPES}
        current_label = value_to_label.get(st.session_state.document_type, labels[0])

        picked_label = st.selectbox(
            zh("é¸æ“‡æ–‡ä»¶é¡å‹", "é€‰æ‹©æ–‡ä»¶ç±»å‹"),
            labels,
            index=labels.index(current_label) if current_label in labels else 0,
            key="document_type_select_zh",
            disabled=doc_type_disabled,
        )
        st.session_state.document_type = label_to_value.get(picked_label, DOC_TYPES[0])
    else:
        st.session_state.document_type = st.selectbox(
            "Select document type",
            DOC_TYPES,
            index=DOC_TYPES.index(st.session_state.document_type),
            key="document_type_select",
            disabled=doc_type_disabled,
        )
    save_state_to_disk()

    # Step 3: Reference docs split (æ›´æ­£2)
    st.subheader("Step 3: Upload Reference Documents (optional)" if lang == "en" else zh("æ­¥é©Ÿä¸‰ï¼šä¸Šå‚³åƒè€ƒæ–‡ä»¶ï¼ˆé¸å¡«ï¼‰", "æ­¥éª¤ä¸‰ï¼šä¸Šä¼ å‚è€ƒæ–‡ä»¶ï¼ˆé€‰å¡«ï¼‰"))

    # 3-1 Upstream (main reference) â€” upload once
    st.markdown("### 3-1 Upload Upstream Reference Document (optional)" if lang == "en" else "### 3-1 ä¸Šå‚³ä¸»è¦åƒè€ƒæ–‡ä»¶ï¼ˆé¸å¡«ï¼‰")
    upstream_ref = st.session_state.get("upstream_reference")
    upstream_locked = bool(upstream_ref)

    if upstream_locked:
        st.info(
            f"Upstream reference uploaded: {upstream_ref.get('name','(unknown)')}. This section is locked until Reset Whole Document." if lang == "en"
            else zh(f"ä¸»è¦åƒè€ƒæ–‡ä»¶å·²ä¸Šå‚³ï¼š{upstream_ref.get('name','(unknown)')}ã€‚æ­¤å€å·²é–å®šï¼Œéœ€ Reset Whole Document æ‰èƒ½é‡ç½®ã€‚", f"ä¸»è¦å‚è€ƒæ–‡ä»¶å·²ä¸Šä¼ ï¼š{upstream_ref.get('name','(unknown)')}ã€‚æ­¤åŒºå·²é”å®šï¼Œéœ€ Reset Whole Document æ‰èƒ½é‡ç½®ã€‚")
        )

    upstream_file = st.file_uploader(
        "Upload upstream reference (PDF / DOCX / TXT / Image)" if lang == "en" else "ä¸Šå‚³ä¸»è¦åƒè€ƒæ–‡ä»¶ï¼ˆPDF / DOCX / TXT / åœ–ç‰‡ï¼‰",
        type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
        key=f"upstream_uploader_{st.session_state.get('upstream_upload_nonce', 0)}",
        disabled=upstream_locked,
    )

    if upstream_file is not None and not upstream_locked:
        ref_text = read_file_to_text(upstream_file)
        if ref_text:
            st.session_state.upstream_reference = {
                "name": upstream_file.name,
                "ext": Path(upstream_file.name).suffix.lstrip("."),
                "text": ref_text,
                "uploaded_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            }
            save_state_to_disk()
            st.rerun()

    # 3-2 Quote reference â€” upload one at a time, can reset to upload another
    st.markdown("### 3-2 Upload Quote Reference Document (optional)" if lang == "en" else "### 3-2 ä¸Šå‚³æ¬¡è¦åƒè€ƒæ–‡ä»¶ï¼ˆé¸å¡«ï¼‰")

    quote_current = st.session_state.get("quote_current")
    quote_locked = bool(quote_current)
    quote_finalized = bool(st.session_state.get("quote_upload_finalized", False))
    quote_nonce = int(st.session_state.get("quote_upload_nonce", 0))

    if quote_locked:
        st.info(
            f"Quote reference uploaded: {quote_current.get('name','(unknown)')}. To upload another, use Reset Quote Reference below." if lang == "en"
            else zh(f"æ¬¡è¦åƒè€ƒæ–‡ä»¶å·²ä¸Šå‚³ï¼š{quote_current.get('name','(unknown)')}ã€‚å¦‚éœ€ä¸Šå‚³æ–°çš„æ¬¡è¦åƒè€ƒæ–‡ä»¶ï¼Œè«‹ä½¿ç”¨ä¸‹æ–¹ Reset Quote Referenceã€‚", f"æ¬¡è¦å‚è€ƒæ–‡ä»¶å·²ä¸Šä¼ ï¼š{quote_current.get('name','(unknown)')}ã€‚å¦‚éœ€ä¸Šä¼ æ–°çš„æ¬¡è¦å‚è€ƒæ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ä¸‹æ–¹ Reset Quote Referenceã€‚")
        )

    quote_file = st.file_uploader(
        "Upload quote reference (PDF / DOCX / TXT / Image)" if lang == "en" else "ä¸Šå‚³æ¬¡è¦åƒè€ƒæ–‡ä»¶ï¼ˆPDF / DOCX / TXT / åœ–ç‰‡ï¼‰",
        type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
        key=f"quote_uploader_{quote_nonce}",
        disabled=quote_locked or quote_finalized,
    )

    if quote_file is not None and not quote_locked:
        q_text = read_file_to_text(quote_file)
        if q_text:
            st.session_state.quote_current = {
                "name": quote_file.name,
                "ext": Path(quote_file.name).suffix.lstrip("."),
                "text": q_text,
                "uploaded_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            }
            st.session_state.quote_step6_done_current = False
            save_state_to_disk()
            st.rerun()

    col_qr1, col_qr2, col_qr3 = st.columns([1, 2, 3])
    with col_qr1:
        if st.button(
            "Reset quote reference",
            key="reset_quote_ref_btn",
            disabled=quote_finalized,
        ):
            # Allow uploading the next quote reference by switching the uploader widget key.
            st.session_state.quote_current = None
            st.session_state.quote_step6_done_current = False
            st.session_state.quote_upload_nonce = int(st.session_state.get("quote_upload_nonce", 0)) + 1
            # Best-effort clear for the prior uploader widget state
            try:
                old_key = f"quote_uploader_{quote_nonce}"
                if old_key in st.session_state:
                    st.session_state[old_key] = None
            except Exception:
                pass
            save_state_to_disk()
            st.rerun()

    with col_qr2:
        pass


    with col_qr3:
        if st.session_state.get("quote_history"):
            st.markdown("**Quote relevance history:**" if lang == "en" else "**æ¬¡è¦åƒè€ƒæ–‡ä»¶ç›¸é—œæ€§åˆ†æç´€éŒ„ï¼š**")
            for i, h in enumerate(st.session_state.quote_history, start=1):
                st.markdown(f"- {i}. {h.get('name','(unknown)')} â€” {h.get('analyzed_at','')}")

    st.markdown("---")

    # Step 4: select framework (lock after Step 5)
    st.subheader("Step 4: Select Framework" if lang == "en" else zh("æ­¥é©Ÿå››ï¼šé¸æ“‡åˆ†ææ¡†æ¶ï¼ˆåƒ…å–®é¸ï¼‰", "æ­¥éª¤å››ï¼šé€‰æ‹©åˆ†ææ¡†æ¶ï¼ˆä»…å•é€‰ï¼‰"))
    st.caption(
        "Single selection only. After Step 5, the framework will be locked until Reset Whole Document." if lang == "en"
        else zh("åƒ…å–®é¸ã€‚ä¸€æ—¦æŒ‰ä¸‹æ­¥é©Ÿäº”é–‹å§‹åˆ†æå¾Œï¼Œæ¡†æ¶æœƒè¢«é–ä½ï¼Œéœ€ Reset Whole Document æ‰èƒ½é‡æ–°é¸æ“‡ï¼Œé¿å…ä¾†å›åˆ‡æ›é€ æˆæ··æ·†ã€‚", "ä»…å•é€‰ã€‚ä¸€æ—¦æŒ‰ä¸‹æ­¥éª¤äº”å¼€å§‹åˆ†æåï¼Œæ¡†æ¶ä¼šè¢«é”ä½ï¼Œéœ€ Reset Whole Document æ‰èƒ½é‡æ–°é€‰æ‹©ï¼Œé¿å…æ¥å›åˆ‡æ¢é€ æˆæ··æ·†ã€‚")
    )

    current_label = key_to_label.get(current_fw_key, fw_labels[0])
    selected_label = st.selectbox(
        "Select framework" if lang == "en" else zh("é¸æ“‡æ¡†æ¶", "é€‰æ‹©æ¡†æ¶"),
        fw_labels,
        index=fw_labels.index(current_label) if current_label in fw_labels else 0,
        key="framework_selectbox",
        disabled=step5_done,
    )
    selected_key = label_to_key[selected_label]
    st.session_state.selected_framework_key = selected_key

    if selected_key != current_fw_key:
        if selected_key not in framework_states:
            framework_states[selected_key] = {
                "analysis_done": False,
                "analysis_output": "",
                "followup_history": [],
                "download_used": False,
                "step5_done": False,
                "step5_output": "",
                "step7_done": False,
                "step7_output": "",
                "step7_history": [],
                "step7_quote_count": 0,
                "integration_history": [],
                "step8_done": False,
                "step8_output": "",
            }
        current_state = framework_states[selected_key]
        step5_done = bool(current_state.get("step5_done", False))
        current_fw_key = selected_key

    save_state_to_disk()

    st.markdown("---")

    # Step 5: main analysis
    st.subheader("Step 5: Analyze MAIN document first (fast)" if lang == "en" else zh("æ­¥é©Ÿäº”ï¼šå…ˆåˆ†æä¸»è¦æ–‡ä»¶ï¼ˆå¿«é€Ÿï¼‰", "æ­¥éª¤äº”ï¼šå…ˆåˆ†æä¸»è¦æ–‡ä»¶ï¼ˆå¿«é€Ÿï¼‰"))
    st.caption(
        "This step analyzes ONLY the main document (no references) to produce a fast first result." if lang == "en"
        else zh("æ­¤æ­¥é©Ÿåªåˆ†æä¸»è¦æ–‡ä»¶ï¼Œä¸è™•ç†åƒè€ƒæ–‡ä»¶ï¼Œå…ˆå¿«é€Ÿç”¢ç”Ÿç¬¬ä¸€ä»½åˆ†æçµæœã€‚", "æ­¤æ­¥éª¤åªåˆ†æä¸»è¦æ–‡ä»¶ï¼Œä¸å¤„ç†å‚è€ƒæ–‡ä»¶ï¼Œå…ˆå¿«é€Ÿäº§ç”Ÿç¬¬ä¸€ä»½åˆ†æç»“æœã€‚")
    )

    run_step5 = st.button(
        "Run analysis (main only)" if lang == "en" else zh("Run analysisï¼ˆä¸»æ–‡ä»¶ï¼‰", "Run analysisï¼ˆä¸»æ–‡ä»¶ï¼‰"),
        key="run_step5_btn",
        disabled=step5_done,
    )

    if run_step5:
        if not st.session_state.last_doc_text:
            st.error("Please upload a review document first (Step 1)." if lang == "en" else zh("è«‹å…ˆä¸Šå‚³å¯©é–±æ–‡ä»¶ï¼ˆStep 1ï¼‰", "è¯·å…ˆä¸Šä¼ å®¡é˜…æ–‡ä»¶ï¼ˆStep 1ï¼‰"))
        elif not st.session_state.get("document_type"):
            st.error("Please select a document type first (Step 2)." if lang == "en" else zh("è«‹å…ˆé¸æ“‡æ–‡ä»¶é¡å‹ï¼ˆStep 2ï¼‰", "è¯·å…ˆé€‰æ‹©æ–‡ä»¶ç±»å‹ï¼ˆStep 2ï¼‰"))
        else:
            banner = show_running_banner(
                "Analyzing... (main only)" if lang == "en" else zh("åˆ†æä¸­...ï¼ˆåƒ…ä¸»æ–‡ä»¶ï¼‰", "åˆ†æä¸­...ï¼ˆä»…ä¸»æ–‡ä»¶ï¼‰")
            )
            try:
                with st.spinner(" "):
                    main_analysis_text = run_llm_analysis(selected_key, lang, st.session_state.last_doc_text, model_name) or ""
            finally:
                banner.empty()

            if is_openai_error_output(main_analysis_text):
                render_openai_error(lang)
                save_state_to_disk()
                st.stop()

            current_state["step5_done"] = True
            current_state["step5_output"] = clean_report_text(main_analysis_text)
            save_state_to_disk()
            record_usage(user_email, selected_key, "analysis")
            st.success("Step 5 completed. Main analysis generated." if lang == "en" else zh("æ­¥é©Ÿäº”å®Œæˆï¼å·²ç”¢å‡ºä¸»æ–‡ä»¶ç¬¬ä¸€ä»½åˆ†æã€‚", "æ­¥éª¤äº”å®Œæˆï¼å·²äº§å‡ºä¸»æ–‡ä»¶ç¬¬ä¸€ä»½åˆ†æã€‚"))
            st.rerun()

    st.markdown("---")

    # Step 6: relevance analysis buttons (æ›´æ­£2)
    st.subheader("Step 6: Reference relevance analysis" if lang == "en" else zh("æ­¥é©Ÿå…­ï¼šåƒè€ƒæ–‡ä»¶ç›¸é—œæ€§åˆ†æ", "æ­¥éª¤å…­ï¼šå‚è€ƒæ–‡ä»¶ç›¸å…³æ€§åˆ†æ"))
    st.caption(
        "Run upstream relevance once (if uploaded). Run quote relevance multiple times by uploading quote references one at a time." if lang == "en"
        else zh(
            "ä¸Šæ¸¸ä¸»è¦åƒè€ƒæ–‡ä»¶ï¼šåªèƒ½åˆ†æä¸€æ¬¡ï¼›æ¬¡è¦åƒè€ƒæ–‡ä»¶ï¼šå¯é€éå¤šæ¬¡ä¸Šå‚³é€æ¬¡åˆ†æï¼ˆä¸€æ¬¡ä¸€ä»½ï¼‰ã€‚",
            "ä¸Šæ¸¸ä¸»è¦å‚è€ƒæ–‡ä»¶ï¼šåªèƒ½åˆ†æä¸€æ¬¡ï¼›æ¬¡è¦å‚è€ƒæ–‡ä»¶ï¼šå¯é€è¿‡å¤šæ¬¡ä¸Šä¼ é€æ¬¡åˆ†æï¼ˆä¸€æ¬¡ä¸€ä»½ï¼‰ã€‚",
        )
    )

    upstream_exists = bool(st.session_state.get("upstream_reference"))
    quote_exists = bool(st.session_state.get("quote_current"))

    upstream_done = bool(st.session_state.get("upstream_step6_done", False))
    quote_done_current = bool(st.session_state.get("quote_step6_done_current", False))

    quote_gate = (not upstream_exists) or upstream_done

    col_s6a, col_s6b = st.columns(2)

    with col_s6a:
        run_upstream = st.button(
            "Run Analysis (upstream relevance)" if lang == "en" else "Run analysisï¼ˆä¸Šæ¸¸ç›¸é—œæ€§ï¼‰",
            key="run_upstream_btn",
            disabled=(not step5_done) or (not upstream_exists) or upstream_done,
        )
    with col_s6b:
        run_quote = st.button(
            "Run Analysis (quote relevance)" if lang == "en" else "Run Analysisï¼ˆå¼•ç”¨ä¸€è‡´æ€§ï¼‰",
            key="run_quote_btn",
            disabled=(not step5_done) or (not quote_exists) or quote_done_current or (not quote_gate),
        )

    if upstream_exists and (not upstream_done) and step5_done:
        st.info(
            "Upstream relevance can be run once. After completion it will be locked until Reset Whole Document." if lang == "en"
            else zh("ä¸Šæ¸¸ç›¸é—œæ€§åˆ†æåªèƒ½åŸ·è¡Œä¸€æ¬¡ï¼›å®Œæˆå¾Œæœƒé–å®šï¼Œéœ€ Reset Whole Document æ‰èƒ½é‡ç½®ã€‚", "ä¸Šæ¸¸ç›¸å…³æ€§åˆ†æåªèƒ½æ‰§è¡Œä¸€æ¬¡ï¼›å®Œæˆåä¼šé”å®šï¼Œéœ€ Reset Whole Document æ‰èƒ½é‡ç½®ã€‚")
        )

    if upstream_exists and (not upstream_done) and quote_exists and step5_done:
        st.info(
            "To avoid long runtime, please run upstream relevance first; quote relevance will be enabled afterwards." if lang == "en"
            else zh("ç‚ºé¿å…ç­‰å¾…éä¹…ï¼Œå»ºè­°å…ˆå®Œæˆä¸Šæ¸¸ç›¸é—œæ€§åˆ†æï¼Œå®Œæˆå¾Œæ‰æœƒé–‹æ”¾å¼•ç”¨ä¸€è‡´æ€§åˆ†æã€‚", "ä¸ºé¿å…ç­‰å¾…è¿‡ä¹…ï¼Œå»ºè®®å…ˆå®Œæˆä¸Šæ¸¸ç›¸å…³æ€§åˆ†æï¼Œå®Œæˆåæ‰ä¼šå¼€æ”¾å¼•ç”¨ä¸€è‡´æ€§åˆ†æã€‚")
        )

    if run_upstream:
        banner = show_running_banner(
            "Analyzing... (upstream relevance)" if lang == "en" else zh("åˆ†æä¸­...ï¼ˆä¸Šæ¸¸ç›¸é—œæ€§ï¼‰", "åˆ†æä¸­...ï¼ˆä¸Šæ¸¸ç›¸å…³æ€§ï¼‰")
        )
        try:
            with st.spinner(" "):
                upstream_text = st.session_state.upstream_reference.get("text", "") if st.session_state.upstream_reference else ""
                out = run_upstream_relevance(lang, st.session_state.last_doc_text or "", upstream_text, model_name)
        finally:
            banner.empty()
        st.session_state.upstream_step6_done = True
        if is_openai_error_output(out):
            render_openai_error(lang)
            save_state_to_disk()
            st.stop()

        st.session_state.upstream_step6_output = clean_report_text(out)
        save_state_to_disk()
        st.success("Upstream relevance completed." if lang == "en" else zh("ä¸Šæ¸¸ç›¸é—œæ€§åˆ†æå®Œæˆã€‚", "ä¸Šæ¸¸ç›¸å…³æ€§åˆ†æå®Œæˆã€‚"))
        st.rerun()

    if run_quote:
        banner = show_running_banner(
            "Analyzing... (quote relevance)" if lang == "en" else zh("åˆ†æä¸­...ï¼ˆå¼•ç”¨ä¸€è‡´æ€§ï¼‰", "åˆ†æä¸­...ï¼ˆå¼•ç”¨ä¸€è‡´æ€§ï¼‰")
        )
        try:
            with st.spinner(" "):
                quote_text = st.session_state.quote_current.get("text", "") if st.session_state.quote_current else ""
                out = run_quote_relevance(lang, st.session_state.last_doc_text or "", quote_text, model_name)
        finally:
            banner.empty()

        if is_openai_error_output(out):
            render_openai_error(lang)
            save_state_to_disk()
            st.stop()

        rec = {
            "name": st.session_state.quote_current.get("name", "(unknown)"),
            "ext": st.session_state.quote_current.get("ext", ""),
            "uploaded_at": st.session_state.quote_current.get("uploaded_at", ""),
            "analyzed_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "output": clean_report_text(out),
        }
        st.session_state.quote_history = (st.session_state.quote_history or []) + [rec]
        st.session_state.quote_step6_done_current = True
        save_state_to_disk()
        st.success("Quote relevance completed." if lang == "en" else zh("å¼•ç”¨ä¸€è‡´æ€§åˆ†æå®Œæˆã€‚", "å¼•ç”¨ä¸€è‡´æ€§åˆ†æå®Œæˆã€‚"))
        st.rerun()

    st.markdown("---")

    # Step 7: Integration analysis (NAME CHANGED ONLY; logic unchanged)
    st.subheader("Step 7: Integration analysis" if lang == "en" else zh("æ­¥é©Ÿä¸ƒï¼šæ•´åˆåˆ†æ", "æ­¥éª¤ä¸ƒï¼šæ•´åˆåˆ†æ"))
    st.caption(
        "Integrate Step 5 and all Step 6 outputs into a formal deliverable report (preferably with tables)." if lang == "en"
        else zh("æ•´åˆæ­¥é©Ÿäº”èˆ‡æ­¥é©Ÿå…­æ‰€æœ‰åˆ†æçµæœï¼Œè¼¸å‡ºæ­£å¼å®Œæ•´å ±å‘Šï¼ˆå»ºè­°ä»¥è¡¨æ ¼å‘ˆç¾é‡é»ï¼‰ã€‚", "æ•´åˆæ­¥éª¤äº”ä¸æ­¥éª¤å…­æ‰€æœ‰åˆ†æç»“æœï¼Œè¾“å‡ºæ­£å¼å®Œæ•´æŠ¥å‘Šï¼ˆå»ºè®®ä»¥è¡¨æ ¼å‘ˆç°é‡ç‚¹ï¼‰ã€‚")
    )

    step7_done = bool(current_state.get("step7_done", False))
    current_quote_count = len(st.session_state.get("quote_history") or [])
    last_step7_quote_count = int(current_state.get("step7_quote_count", 0) or 0)
    step7_needs_refresh = current_quote_count != last_step7_quote_count

    # Step 7 can be re-run whenever Step 6 quote relevance adds new history entries.
    # Keep old Step 7 outputs in history, and always use the latest as the current Step 7 result.
    # Gate Step 7 strictly on Step 6 completion:
    # - If an upstream reference was uploaded, upstream relevance must be done.
    # - If a quote reference is currently uploaded, quote relevance must be done for that upload.
    upstream_ok_for_step7 = (not upstream_exists) or upstream_done
    quote_ok_for_step7 = (not quote_exists) or bool(st.session_state.get("quote_step6_done_current", False))

    step7_can_run = (
        step5_done
        and upstream_ok_for_step7
        and quote_ok_for_step7
        and (not current_state.get("step8_done", False))
        and (not quote_finalized)
        and ((not step7_done) or step7_needs_refresh)
    )

    run_step7 = st.button(
        "Run integration analysis" if lang == "en" else "Run analysisï¼ˆæ•´åˆåˆ†æï¼‰",
        key="run_step7_btn",
        disabled=not step7_can_run,
    )

    if run_step7:
        # Step 7 produces ONE integration analysis per quote reference, and keeps a clean per-quote history.
        # If multiple quote references are pending, we generate the missing ones in order.
        integration_history = current_state.get("integration_history") or []
        quote_hist = st.session_state.get("quote_history") or []
        upstream_text_snapshot = st.session_state.get("upstream_step6_output", "") if st.session_state.get("upstream_step6_done") else ""

        # When there is no quote reference, still allow generating a single integration item.
        total_items_needed = len(quote_hist) if len(quote_hist) > 0 else 1

        start_idx = len(integration_history)
        if start_idx >= total_items_needed:
            st.info("Step 7 is already up to date." if lang == "en" else zh("æ­¥é©Ÿä¸ƒå·²æ˜¯æœ€æ–°ç‹€æ…‹ã€‚", "æ­¥éª¤ä¸ƒå·²æ˜¯æœ€æ–°çŠ¶æ€ã€‚"))
            st.stop()

        banner = show_running_banner(
            "Analyzing... (integration)" if lang == "en" else zh("åˆ†æä¸­...ï¼ˆæ•´åˆï¼‰", "åˆ†æä¸­...ï¼ˆæ•´åˆï¼‰")
        )
        try:
            with st.spinner(" "):
                for item_idx in range(start_idx, total_items_needed):
                    parts: List[str] = []

                # Build per-quote integration input
                if lang != "en":
                    parts.append("[æ•´åˆåˆ†æè¼¸å…¥ï¼ˆæ­¥é©Ÿä¸ƒï¼‰]")
                    parts.append(f"- æ–‡ä»¶é¡å‹ï¼š{st.session_state.document_type or 'ï¼ˆæœªé¸æ“‡ï¼‰'}")
                    parts.append(f"- æ¡†æ¶ï¼š{FRAMEWORKS.get(selected_key, {}).get('name_zh', selected_key)}")
                    parts.append("")
                    parts.append("=====ï¼ˆæ­¥é©Ÿäº”ï¼‰ä¸»æ–‡ä»¶é›¶éŒ¯èª¤æ¡†æ¶åˆ†æçµæœ=====")
                    parts.append(current_state.get("step5_output", ""))

                    if st.session_state.get("upstream_reference"):
                        parts.append("")
                        parts.append("=====ï¼ˆæ­¥é©Ÿå…­-Aï¼‰ä¸Šæ¸¸ä¸»è¦åƒè€ƒæ–‡ä»¶ç›¸é—œæ€§åˆ†æï¼ˆUpstream relevanceï¼‰=====")
                        parts.append(upstream_text_snapshot or "ï¼ˆå°šæœªåŸ·è¡Œä¸Šæ¸¸ç›¸é—œæ€§åˆ†æï¼‰")

                    parts.append("")
                    parts.append("=====ï¼ˆæ­¥é©Ÿå…­-Bï¼‰æ¬¡è¦åƒè€ƒæ–‡ä»¶å¼•ç”¨ä¸€è‡´æ€§åˆ†æï¼ˆQuote relevanceï¼‰=====")
                    if len(quote_hist) > 0:
                        h = quote_hist[item_idx]
                        parts.append(f"--- Quote reference {item_idx+1}: {h.get('name','(unknown)')} ---")
                        parts.append(h.get("output", ""))
                    else:
                        parts.append("ï¼ˆæœªä¸Šå‚³æ¬¡è¦åƒè€ƒæ–‡ä»¶ï¼‰")

                    parts.append("")
                    parts.append("ã€ä»»å‹™ã€‘")
                    parts.append(
                        "è«‹ç”¨åŒä¸€å€‹é›¶éŒ¯èª¤æ¡†æ¶ï¼Œæ•´åˆä¸Šè¿°å…§å®¹ï¼Œè¼¸å‡ºã€æ•´åˆåˆ†æå ±å‘Šã€ï¼Œè¦æ±‚ï¼š\n"
                        "1) å»é‡ã€è£œå¼·ï¼Œä¸è¦æŠŠå…§å®¹é‡è¤‡è²¼ä¸Šã€‚\n"
                        "2) å¿…é ˆæ˜ç¢ºæŒ‡å‡ºï¼šå“ªäº›çµè«–è¢«ä¸Šæ¸¸æ–‡ä»¶æ”¯æŒã€å“ªäº›å­˜åœ¨è¡çªã€å“ªäº›æ˜¯å¼•ç”¨ä¸ä¸€è‡´ï¼ˆreference inconsistency errorï¼‰ã€‚\n"
                        "3) ä»¥è¡¨æ ¼å‘ˆç¾é—œéµå·®ç•°ï¼ˆè‡³å°‘åŒ…å«ï¼šé …ç›®/ä¸»æ–‡ä»¶/åƒè€ƒæ–‡ä»¶/ä¸€è‡´æ€§/å»ºè­°ä¿®æ­£ï¼‰ã€‚\n"
                        "4) ç”¢å‡ºå¯åŸ·è¡Œçš„ä¿®æ­£/è£œä»¶/æ¾„æ¸…å•é¡Œæ¸…å–®ï¼ˆå«å„ªå…ˆé †åºï¼‰ã€‚"
                    )
                else:
                    parts.append("[Integration Analysis Input (Step 7)]")
                    parts.append(f"- Document type: {st.session_state.document_type or '(not selected)'}")
                    parts.append(f"- Framework: {FRAMEWORKS.get(selected_key, {}).get('name_en', selected_key)}")
                    parts.append("")
                    parts.append("===== (Step 5) Main document analysis result =====")
                    parts.append(current_state.get("step5_output", ""))

                    if st.session_state.get("upstream_reference"):
                        parts.append("")
                        parts.append("===== (Step 6-A) Upstream relevance =====")
                        parts.append(upstream_text_snapshot or "(Upstream relevance not run yet)")

                    parts.append("")
                    parts.append("===== (Step 6-B) Quote relevance =====")
                    if len(quote_hist) > 0:
                        h = quote_hist[item_idx]
                        parts.append(f"--- Quote reference {item_idx+1}: {h.get('name','(unknown)')} ---")
                        parts.append(h.get("output", ""))
                    else:
                        parts.append("(No quote reference uploaded)")

                    parts.append("")
                    parts.append("[TASK]")
                    parts.append(
                        "Using the same framework, integrate the above into an 'Integration Analysis Report' with:\n"
                        "1) De-duplicate and strengthen; do not paste repeated content.\n"
                        "2) Explicitly state: what is supported by upstream, what conflicts, and what is reference inconsistency error.\n"
                        "3) Provide a comparison table (at least: item / main doc / reference doc / consistency / recommended fix).\n"
                        "4) Provide an actionable fix / addendum / clarification questions list with priority."
                    )

                final_input = "\n".join(parts)
                final_output = run_llm_analysis(selected_key, lang, final_input, model_name) or ""

                if is_openai_error_output(final_output):
                    render_openai_error(lang)
                    save_state_to_disk()
                    st.stop()

                entry = {
                    "index": item_idx + 1,
                    "quote_name": (quote_hist[item_idx].get("name", "(unknown)") if len(quote_hist) > 0 else "(no quote reference)"),
                    "generated_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "output": clean_report_text(final_output),
                }
                integration_history.append(entry)
        finally:
            banner.empty()

        # Save per-quote integration history
        current_state["integration_history"] = integration_history
        current_state["step7_quote_count"] = len(integration_history)

        # Keep a convenient "latest" output for compatibility (but Results will show per-item history)
        if integration_history:
            current_state["step7_output"] = integration_history[-1].get("output", "")

        current_state["step7_done"] = (len(integration_history) >= total_items_needed)

        save_state_to_disk()
        st.success("Step 7 completed. Integration analysis generated." if lang == "en" else zh("æ­¥é©Ÿä¸ƒå®Œæˆï¼å·²ç”¢å‡ºæ•´åˆåˆ†æçµæœã€‚", "æ­¥éª¤ä¸ƒå®Œæˆï¼å·²äº§å‡ºæ•´åˆåˆ†æç»“æœã€‚"))
        st.rerun()
    st.markdown("---")

    # Step 8: Final Analysis (NEW) â€” this is the final deliverable
    st.subheader("Step 8: Final Analysis" if lang == "en" else zh("æ­¥é©Ÿå…«ï¼šæœ€çµ‚åˆ†æï¼ˆFinal Analysisï¼‰", "æ­¥éª¤å…«ï¼šæœ€ç»ˆåˆ†æï¼ˆFinal Analysisï¼‰"))
    st.caption(
        "Cross-check Step 7 results and produce the FINAL deliverable report." if lang == "en"
        else zh("ä¾ Cross-Checking Analysis æ–¹æ³•ï¼Œå°æ­¥é©Ÿä¸ƒçµæœåšæœ€å¾Œäº¤å‰æ ¸å°ï¼Œç”¢å‡ºæœ€çµ‚äº¤ä»˜å ±å‘Šï¼ˆFinal deliverableï¼‰ã€‚", "ä¾ Cross-Checking Analysis æ–¹æ³•ï¼Œå¯¹æ­¥éª¤ä¸ƒç»“æœåšæœ€åäº¤å‰æ ¸å¯¹ï¼Œäº§å‡ºæœ€ç»ˆäº¤ä»˜æŠ¥å‘Šï¼ˆFinal deliverableï¼‰ã€‚")
    )

    step8_done = bool(current_state.get("step8_done", False))
    quote_finalized = bool(st.session_state.get("quote_upload_finalized", False))
    current_quote_count = len(st.session_state.get("quote_history") or [])
    step7_quote_count = int(current_state.get("step7_quote_count", 0) or 0)

    # Step 8 gate: user must confirm no more quote references (this also locks Step 3-2 reset + Step 7).
    confirm_disabled = (
        step8_done
        or quote_finalized
        or (not bool(current_state.get("step7_done")))
        or (step7_quote_count != current_quote_count)
    )
    confirm_clicked = st.button(
        "Confirm no more quote reference" if lang == "en" else zh("ç¢ºèªå·²ç„¡å…¶ä»–åƒè€ƒæ–‡ä»¶è¦ä¸Šå‚³", "ç¡®è®¤å·²æ— å…¶ä»–å‚è€ƒæ–‡ä»¶è¦ä¸Šä¼ "),
        key="confirm_no_more_quote_btn",
        disabled=confirm_disabled,
    )
    if confirm_clicked:
        st.session_state.quote_upload_finalized = True
        save_state_to_disk()
        st.success("Confirmed. Quote reference upload is now locked." if lang == "en" else zh("å·²ç¢ºèªï¼šæ¬¡è¦åƒè€ƒæ–‡ä»¶ä¸Šå‚³å·²é–å®šã€‚", "å·²ç¡®è®¤ï¼šæ¬¡è¦å‚è€ƒæ–‡ä»¶ä¸Šä¼ å·²é”å®šã€‚"))
        st.rerun()

    if not quote_finalized:
        if step7_quote_count != current_quote_count:
            st.info(
                "Step 7 is not up to date. Please run Step 7 until all quote references are integrated, then confirm." if lang == "en"
                else zh("æ­¥é©Ÿä¸ƒå°šæœªæ›´æ–°è‡³æœ€æ–°ã€‚è«‹å…ˆåŸ·è¡Œæ­¥é©Ÿä¸ƒï¼Œç›´åˆ°æ‰€æœ‰æ¬¡è¦åƒè€ƒæ–‡ä»¶éƒ½å®Œæˆæ•´åˆåˆ†æï¼Œå†æŒ‰ä¸‹ç¢ºèªæŒ‰éµã€‚", "æ­¥éª¤ä¸ƒå°šæœªæ›´æ–°è‡³æœ€æ–°ã€‚è¯·å…ˆæ‰§è¡Œæ­¥éª¤ä¸ƒï¼Œç›´åˆ°æ‰€æœ‰æ¬¡è¦å‚è€ƒæ–‡ä»¶éƒ½å®Œæˆæ•´åˆåˆ†æï¼Œå†æŒ‰ä¸‹ç¡®è®¤æŒ‰é”®ã€‚"),
            )
        else:
            st.info(
                "To enable Step 8, click **Confirm no more quote reference** (after Step 7 is up to date)." if lang == "en"
                else zh("è¦å•Ÿç”¨æ­¥é©Ÿå…«ï¼Œè«‹åœ¨æ­¥é©Ÿä¸ƒæ›´æ–°å®Œæˆå¾Œï¼ŒæŒ‰ä¸‹ã€ç¢ºèªå·²ç„¡å…¶ä»–åƒè€ƒæ–‡ä»¶è¦ä¸Šå‚³ã€ã€‚", "è¦å¯ç”¨æ­¥éª¤å…«ï¼Œè¯·åœ¨æ­¥éª¤ä¸ƒæ›´æ–°å®Œæˆåï¼ŒæŒ‰ä¸‹ã€ç¡®è®¤å·²æ— å…¶ä»–å‚è€ƒæ–‡ä»¶è¦ä¸Šä¼ ã€ã€‚"),
            )
    else:
        st.info("Quote reference upload is locked. Step 8 can run now." if lang == "en" else zh("æ¬¡è¦åƒè€ƒæ–‡ä»¶ä¸Šå‚³å·²é–å®šï¼Œç¾åœ¨å¯é€²è¡Œæ­¥é©Ÿå…«ã€‚", "æ¬¡è¦å‚è€ƒæ–‡ä»¶ä¸Šä¼ å·²é”å®šï¼Œç°åœ¨å¯è¿›è¡Œæ­¥éª¤å…«ã€‚"))
    step8_can_run = bool(current_state.get("step7_done")) and quote_finalized and (step7_quote_count == current_quote_count) and (not step8_done)

    run_step8 = st.button(
        "Run final analysis (Step 8)" if lang == "en" else "Run final analysisï¼ˆæ­¥é©Ÿå…«ï¼‰",
        key="run_step8_btn",
        disabled=not step8_can_run,
    )

    if run_step8:
        banner = show_running_banner(
            "Analyzing... (final analysis)" if lang == "en" else zh("åˆ†æä¸­...ï¼ˆæœ€çµ‚åˆ†æï¼‰", "åˆ†æä¸­...ï¼ˆæœ€ç»ˆåˆ†æï¼‰")
        )
        try:
            with st.spinner(" "):
                fw_name = FRAMEWORKS.get(selected_key, {}).get(
                    "name_zh" if lang == "zh" else "name_en", selected_key
                )

                integration_history = current_state.get("integration_history") or []
                if integration_history:
                    chunks = []
                    for e in integration_history:
                        chunks.append(
                            f"===== Integration #{e.get('index','')}: {e.get('quote_name','')} ({e.get('generated_at','')}) =====\n{e.get('output','')}"
                        )
                    step7_text_all = "\n\n".join(chunks)
                else:
                    step7_text_all = current_state.get("step7_output", "")

                out = run_step8_final_analysis(
                    language=lang,
                    document_type=st.session_state.document_type,
                    framework_name=fw_name,
                    step7_integration_output=step7_text_all,
                    model_name=model_name,
                )
        finally:
            banner.empty()

        if is_openai_error_output(out):
            render_openai_error(lang)
            save_state_to_disk()
            st.stop()

        current_state["step8_done"] = True
        current_state["step8_output"] = clean_report_text(out)

        # Build final analysis bundle (this becomes analysis_output / final deliverable)
        if lang == "zh":
            prefix_lines = [
                "### åˆ†æç´€éŒ„ï¼ˆå¿…è®€ï¼‰",
                f"- æ–‡ä»¶é¡å‹ï¼ˆDocument Typeï¼‰ï¼š{st.session_state.document_type}",
                f"- æ¡†æ¶ï¼ˆFrameworkï¼‰ï¼š{FRAMEWORKS.get(selected_key, {}).get('name_zh', selected_key)}",
            ]
            if st.session_state.get("upstream_reference"):
                prefix_lines.append(f"- ä¸»è¦åƒè€ƒæ–‡ä»¶ï¼ˆUpstreamï¼‰ï¼š{st.session_state.upstream_reference.get('name','(unknown)')}")
            else:
                prefix_lines.append("- ä¸»è¦åƒè€ƒæ–‡ä»¶ï¼ˆUpstreamï¼‰ï¼šï¼ˆæœªä¸Šå‚³ï¼‰")

            if st.session_state.get("quote_history"):
                prefix_lines.append("- æ¬¡è¦åƒè€ƒæ–‡ä»¶ï¼ˆQuote Referencesï¼‰åˆ†æç´€éŒ„ï¼š")
                for i, h in enumerate(st.session_state.quote_history, start=1):
                    prefix_lines.append(f"  {i}. {h.get('name','(unknown)')} ({h.get('analyzed_at','')})")
            else:
                prefix_lines.append("- æ¬¡è¦åƒè€ƒæ–‡ä»¶ï¼ˆQuote Referencesï¼‰ï¼šï¼ˆæœªä¸Šå‚³ï¼‰")

            prefix = "\n".join(prefix_lines) + "\n\n"
            final_bundle = [
                "==============================",
                "ï¼ˆæ­¥é©Ÿå…«ï¼‰æœ€çµ‚äº¤ä»˜å ±å‘Šï¼ˆFinal deliverableï¼‰",
                "==============================",
                current_state.get("step8_output", ""),
            ]
        else:
            prefix_lines = [
                "### Analysis Record",
                f"- Document Type: {st.session_state.document_type}",
                f"- Framework: {FRAMEWORKS.get(selected_key, {}).get('name_en', selected_key)}",
            ]
            if st.session_state.get("upstream_reference"):
                prefix_lines.append(f"- Upstream reference: {st.session_state.upstream_reference.get('name','(unknown)')}")
            else:
                prefix_lines.append("- Upstream reference: (none)")

            if st.session_state.get("quote_history"):
                prefix_lines.append("- Quote reference analysis log:")
                for i, h in enumerate(st.session_state.quote_history, start=1):
                    prefix_lines.append(f"  {i}. {h.get('name','(unknown)')} ({h.get('analyzed_at','')})")
            else:
                prefix_lines.append("- Quote references: (none)")

            prefix = "\n".join(prefix_lines) + "\n\n"
            final_bundle = [
                "==============================",
                "(Step 8) Final deliverable report",
                "==============================",
                current_state.get("step8_output", ""),
            ]

        current_state["analysis_done"] = True
        current_state["analysis_output"] = clean_report_text(prefix + "\n".join(final_bundle))
        save_state_to_disk()
        st.success("Step 8 completed. Final deliverable generated." if lang == "en" else zh("æ­¥é©Ÿå…«å®Œæˆï¼å·²ç”¢å‡ºæœ€çµ‚äº¤ä»˜æˆå“ã€‚", "æ­¥éª¤å…«å®Œæˆï¼å·²äº§å‡ºæœ€ç»ˆäº¤ä»˜æˆå“ã€‚"))
        st.rerun()

    # =========================
    # Ensure current_state exists even before a framework is selected
    try:
        _ = current_state
    except NameError:
        current_state = {}

    # RESULTS area (clean + collapsible)
    # =========================
    st.markdown("---")
    st.markdown(
        f"""
<div class="ef-results-banner">
  <div class="title">{'RESULTS' if lang == 'en' else zh('çµæœç¸½è¦½', 'ç»“æœæ€»è§ˆ')}</div>
  <div class="subtitle">{'All outputs are grouped below by steps.' if lang == 'en' else zh('æ‰€æœ‰è¼¸å‡ºä¾æ­¥é©Ÿæ•´ç†åœ¨æ­¤å€ï¼Œé»é¸å¯å±•é–‹ / æ”¶èµ·ã€‚', 'æ‰€æœ‰è¾“å‡ºä¾æ­¥éª¤æ•´ç†åœ¨æ­¤åŒºï¼Œç‚¹é€‰å¯å±•å¼€ / æ”¶èµ·ã€‚')}</div>
</div>
        """,
        unsafe_allow_html=True,
    )

    if current_state.get("step5_done"):
        render_step_block(
            "Step 5 â€” Main analysis result" if lang == "en" else "Step 5 â€” ä¸»æ–‡ä»¶åˆ†æçµæœ",
            current_state.get("step5_output", ""),
            expanded=False,
        )

    if st.session_state.get("upstream_reference"):
        if st.session_state.get("upstream_step6_done"):
            render_step_block(
                "Step 6-A â€” Upstream relevance" if lang == "en" else "Step 6-A â€” ä¸Šæ¸¸ç›¸é—œæ€§",
                st.session_state.get("upstream_step6_output", ""),
                expanded=False,
            )
        else:
            render_step_block(
                "Step 6-A â€” Upstream relevance" if lang == "en" else "Step 6-A â€” ä¸Šæ¸¸ç›¸é—œæ€§",
                "",
                expanded=False,
            )

    if st.session_state.get("quote_history"):
        st.markdown(f'<div class="ef-step-title">{"Step 6-B â€” Quote relevance (history)" if lang == "en" else "Step 6-B â€” å¼•ç”¨ä¸€è‡´æ€§ï¼ˆæ­·å²ï¼‰"}</div>', unsafe_allow_html=True)
        with st.expander("Show / Hide" if lang == "en" else zh("å±•é–‹ / æ”¶èµ·", "å±•å¼€ / æ”¶èµ·"), expanded=False):
            for i, h in enumerate(st.session_state.quote_history, start=1):
                qname = (h.get("quote_name") or h.get("name") or f"Quote reference #{i}") if isinstance(h, dict) else (getattr(h, "quote_name", None) or getattr(h, "name", None) or f"Quote reference #{i}")
                analyzed_at = (h.get("analyzed_at") or "") if isinstance(h, dict) else (getattr(h, "analyzed_at", "") or "")
                out = (h.get("output") or h.get("text") or "") if isinstance(h, dict) else (getattr(h, "output", "") or getattr(h, "text", "") or "")
                label = f"{i}. {qname}" + (f" â€” {analyzed_at}" if analyzed_at else "")
                with st.expander(label, expanded=False):
                    if out:
                        st.markdown(out)
                    else:
                        st.info("No content yet." if lang == "en" else zh("å°šç„¡å…§å®¹ã€‚", "æš‚æ— å†…å®¹ã€‚"))
    # Step 7 (Integration analysis) â€” single section, history nested inside
    st.markdown('<div class="ef-step-title">Step 7 â€” Integration analysis</div>', unsafe_allow_html=True)
    with st.expander("Show / Hide", expanded=False):
        integration_history = current_state.get("integration_history") or []
        if integration_history:
            for e in integration_history:
                label = f"{e.get('index','')}. {e.get('quote_name','')} â€” {e.get('generated_at','')}".strip()
                with st.expander(label if label else "(integration)", expanded=False):
                    st.markdown(e.get("output", ""))
        else:
            st.markdown("_No Step 7 output yet._")
# Step 8 (NEW)


    if current_state.get("step8_done"):
        render_step_block(
            "Step 8 â€” Final Analysis (Final deliverable)" if lang == "en" else "Step 8 â€” æœ€çµ‚åˆ†æï¼ˆæœ€çµ‚äº¤ä»˜ï¼‰",
            current_state.get("step8_output", ""),
            expanded=False,
        )
    else:
        render_step_block(
            "Step 8 â€” Final Analysis (Final deliverable)" if lang == "en" else "Step 8 â€” æœ€çµ‚åˆ†æï¼ˆæœ€çµ‚äº¤ä»˜ï¼‰",
            "",
            expanded=False,
        )

    # Follow-up history after results
    st.markdown("---")
    st.subheader("Follow-up (Q&A)" if lang == "en" else zh("å¾ŒçºŒæå•ï¼ˆQ&Aï¼‰", "åç»­æé—®ï¼ˆQ&Aï¼‰"))
    render_followup_history_chat(current_state.get("followup_history", []), lang)

    # =========================
    # Download (3) choose include follow-ups
    # =========================
    st.markdown("---")
    st.subheader("Download report" if lang == "en" else zh("ä¸‹è¼‰å ±å‘Š", "ä¸‹è½½æŠ¥å‘Š"))

    if current_state.get("analysis_done") and current_state.get("analysis_output"):
        if is_guest and current_state.get("download_used"):
            st.error("Download limit reached (1 time)." if lang == "en" else zh("å·²é”ä¸‹è¼‰æ¬¡æ•¸ä¸Šé™ï¼ˆ1 æ¬¡ï¼‰", "å·²è¾¾ä¸‹è½½æ¬¡æ•°ä¸Šé™ï¼ˆ1 æ¬¡ï¼‰"))
        else:
            now_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            with st.expander("Download"):
                include_qa = st.checkbox(
                    "Include follow-up Q&A replies (optional)" if lang == "en" else zh("æ˜¯å¦åŒ…å«è¿½å•å›è¦†ç´€éŒ„ï¼ˆé¸å¡«ï¼‰", "æ˜¯å¦åŒ…å«è¿½é—®å›å¤è®°å½•ï¼ˆé€‰å¡«ï¼‰"),
                    value=True,
                    key=f"include_qa_{selected_key}",
                )
                # Select format (PDF/PPTX temporarily disabled)
                fmt = st.selectbox(
                    "Select format" if lang == "en" else zh("é¸æ“‡æ ¼å¼", "é€‰æ‹©æ ¼å¼"),
                    ["Word (DOCX)"],
                    key=f"fmt_{selected_key}",
                )
                st.markdown(
                    "<div style='color:#9aa0a6; margin-top:6px;'>"
                    + ("PDF (temporarily unavailable)\n" if lang == "en" else zh("PDFï¼ˆæš«ä¸é–‹æ”¾ï¼‰\n", "PDFï¼ˆæš‚ä¸å¼€æ”¾ï¼‰\n"))
                    + ("PowerPoint (PPTX) (temporarily unavailable)" if lang == "en" else zh("PowerPointï¼ˆPPTXï¼‰ï¼ˆæš«ä¸é–‹æ”¾ï¼‰", "PowerPointï¼ˆPPTXï¼‰ï¼ˆæš‚ä¸å¼€æ”¾ï¼‰"))
                    + "</div>",
                    unsafe_allow_html=True,
                )

                report = build_full_report(lang, selected_key, current_state, include_followups=include_qa)

                # PDF/PPTX are temporarily disabled (formatting not stable yet)
                if fmt.startswith("PDF") or fmt.startswith("PowerPoint"):
                    st.info(
                        "PDF/PPTX download is temporarily unavailable." if lang == "en" else zh("PDF / PPTX ä¸‹è¼‰æš«ä¸é–‹æ”¾ã€‚", "PDF / PPTX ä¸‹è½½æš‚ä¸å¼€æ”¾ã€‚")
                    )
                else:
                    # Download (DOCX)
                    data = build_docx_bytes(report)
                    mime = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"

                    now_ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    framework_key = (selected_key or "unknown").replace("/", "-")
                    filename = f"Error-FreeÂ® IER {framework_key} {now_ts}" + (" +Q&A" if include_qa else "") + ".docx"


                    # Download (DOCX) â€” use Streamlit native download_button (supports browser save-location prompt).
                    st.download_button(
                        label=("Download" if lang == "en" else zh("é–‹å§‹ä¸‹è¼‰", "å¼€å§‹ä¸‹è½½")),
                        data=data,
                        file_name=filename,
                        mime=mime,
                        key=f"download_{framework_key}_{now_ts}",
                    )
                    

                    st.caption(
                        "Tip: If you want a 'Save As' location prompt, enable 'Ask where to save each file' in your browser settings."
                        if lang == "en"
                        else zh("æç¤ºï¼šè‹¥ä½ å¸Œæœ›æ¯æ¬¡éƒ½è·³å‡ºã€é¸æ“‡ä¸‹è¼‰ä½ç½®ã€è¦–çª—ï¼Œè«‹åœ¨ç€è¦½å™¨ä¸‹è¼‰è¨­å®šä¸­é–‹å•Ÿã€æ¯æ¬¡ä¸‹è¼‰å‰è©¢å•å„²å­˜ä½ç½®ã€ã€‚", "æç¤ºï¼šè‹¥ä½ å¸Œæœ›æ¯æ¬¡éƒ½è·³å‡ºã€é€‰æ‹©ä¸‹è½½ä½ç½®ã€è§†çª—ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸‹è½½è®¾ç½®ä¸­å¼€å¯ã€æ¯æ¬¡ä¸‹è½½å‰è¯¢é—®ä¿å­˜ä½ç½®ã€ã€‚")
                    )
    else:
        st.info("Complete Step 8 to enable downloads." if lang == "en" else zh("è«‹å…ˆå®Œæˆæ­¥é©Ÿå…«ï¼Œç”¢å‡ºæœ€çµ‚äº¤ä»˜å ±å‘Šå¾Œæ‰èƒ½ä¸‹è¼‰ã€‚", "è¯·å…ˆå®Œæˆæ­¥éª¤å…«ï¼Œäº§å‡ºæœ€ç»ˆäº¤ä»˜æŠ¥å‘Šåæ‰èƒ½ä¸‹è½½ã€‚"))

    # =========================
    # Follow-up input (FIXED: no StreamlitAPIException)
    # =========================
    st.markdown("---")
    st.subheader("Ask a follow-up question" if lang == "en" else zh("æå‡ºè¿½å•", "æå‡ºè¿½é—®"))
    # Hint: follow-up results will appear in the Follow-up (Q&A) section above
    _followup_hint = (
        "Your follow-up question and replies will appear in the Follow-up (Q&A) section above."
        if lang == "en" else
        "ä½ é€å‡ºçš„è¿½å•èˆ‡å›è¦†ï¼Œå°‡é¡¯ç¤ºåœ¨ä¸Šæ–¹çš„ Follow-upï¼ˆQ&Aï¼‰å€å¡Šä¸­ã€‚"
    )
    _followup_hint_safe = _followup_hint.replace('"', "&quot;")
    st.markdown(
        f"<span style='color:#1a73e8; font-weight:600; cursor:help;' title=\"{_followup_hint_safe}\">{_followup_hint}</span>",
        unsafe_allow_html=True,
    )


    if not current_state.get("analysis_output"):
        st.info("Please complete Step 8 before asking follow-up questions." if lang == "en" else zh("è«‹å…ˆå®Œæˆæ­¥é©Ÿå…«ï¼Œç”¢å‡ºæœ€çµ‚äº¤ä»˜æˆå“å¾Œå†é€²è¡Œè¿½å•ã€‚", "è¯·å…ˆå®Œæˆæ­¥éª¤å…«ï¼Œäº§å‡ºæœ€ç»ˆäº¤ä»˜æˆå“åå†è¿›è¡Œè¿½é—®ã€‚"))
    else:
        if is_guest and len(current_state.get("followup_history", [])) >= 3:
            st.error("Follow-up limit reached (3 times)." if lang == "en" else zh("å·²é”è¿½å•ä¸Šé™ï¼ˆ3 æ¬¡ï¼‰", "å·²è¾¾è¿½é—®ä¸Šé™ï¼ˆ3 æ¬¡ï¼‰"))
        else:
            followup_key = f"followup_input_{selected_key}"

            # ---- FIX: clear follow-up input on the next rerun (must be BEFORE the widget is instantiated) ----
            _pending_clear = st.session_state.get("_pending_clear_followup_key")
            if _pending_clear == followup_key:
                st.session_state[followup_key] = ""
                st.session_state["_pending_clear_followup_key"] = None
            # ---- END FIX ----

            col_text, col_file = st.columns([3, 1])

            with col_text:
                prompt = st.text_area(
                    "Ask a follow-up question" if lang == "en" else zh("è«‹è¼¸å…¥ä½ çš„è¿½å•", "è¯·è¾“å…¥ä½ çš„è¿½é—®"),
                    key=followup_key,
                    height=140,
                    placeholder="Type your question here..." if lang == "en" else zh("åœ¨æ­¤è¼¸å…¥å•é¡Œâ€¦", "åœ¨æ­¤è¾“å…¥é—®é¢˜â€¦"),
                )

            with col_file:
                extra_file = st.file_uploader(
                    "Attach image/document (optional)" if lang == "en" else zh("ğŸ“ ä¸Šå‚³åœ–ç‰‡/æ–‡ä»¶ï¼ˆé¸å¡«ï¼‰", "ğŸ“ ä¸Šä¼ å›¾ç‰‡/æ–‡ä»¶ï¼ˆé€‰å¡«ï¼‰"),
                    type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
                    key=f"extra_{selected_key}",
                )
            extra_text = read_file_to_text(extra_file) if extra_file else ""

            if st.button("Send follow-up" if lang == "en" else zh("é€å‡ºè¿½å•", "é€å‡ºè¿½é—®"), key=f"followup_btn_{selected_key}"):
                if prompt and prompt.strip():
                    with st.spinner("Thinking..." if lang == "en" else zh("æ€è€ƒä¸­...", "æ€è€ƒä¸­...")):
                        answer = run_followup_qa(
                            selected_key,
                            lang,
                            st.session_state.last_doc_text or "",
                            current_state.get("analysis_output", ""),
                            prompt,
                            model_name,
                            extra_text,
                        )
                    current_state["followup_history"].append((prompt, clean_report_text(answer)))

                    # FIX: DO NOT modify widget state after instantiation; clear on next rerun
                    st.session_state["_pending_clear_followup_key"] = followup_key

                    save_state_to_disk()
                    record_usage(user_email, selected_key, "followup")
                    st.rerun()
                else:
                    st.warning("Please enter a question first." if lang == "en" else zh("è«‹å…ˆè¼¸å…¥è¿½å•å…§å®¹ã€‚", "è¯·å…ˆè¾“å…¥è¿½é—®å†…å®¹ã€‚"))

    # Reset Whole Document (æ›´æ­£2)
    st.markdown("---")
    st.subheader("Reset Whole Document" if lang == "en" else "Reset Whole Documentï¼ˆå…¨éƒ¨é‡ç½®ï¼‰")
    st.warning(
        "Reminder: Please make sure you have downloaded your report. We do not retain your documents. Reset will remove the current review session." if lang == "en"
        else zh("æº«é¦¨æç¤ºï¼šè«‹ç¢ºèªæ‚¨å·²ç¶“ä¸‹è¼‰è³‡æ–™ã€‚æˆ‘å€‘ä¸ç•™å­˜ä½ å€‘çš„è³‡æ–™ï¼›æŒ‰ä¸‹é‡ç½®å¾Œï¼Œæœ¬æ¬¡å¯©æŸ¥çš„æ–‡ä»¶èˆ‡åˆ†æç´€éŒ„å°‡æœƒæ¸…ç©ºã€‚", "æ¸©é¦¨æç¤ºï¼šè¯·ç¡®è®¤æ‚¨å·²ç»ä¸‹è½½èµ„æ–™ã€‚æˆ‘ä»¬ä¸ç•™å­˜ä½ ä»¬çš„èµ„æ–™ï¼›æŒ‰ä¸‹é‡ç½®åï¼Œæœ¬æ¬¡å¯©æŸ¥çš„æ–‡ä»¶ä¸åˆ†æçºªå½•å°†ä¼šæ¸…ç©ºã€‚")
    )
    confirm = st.checkbox("I understand and want to reset." if lang == "en" else zh("æˆ‘å·²ç¢ºèªè¦é‡ç½®ã€‚", "æˆ‘å·²ç¡®è®¤è¦é‡ç½®ã€‚"), key="reset_confirm")
    if st.button("Reset Whole Document" if lang == "en" else "Reset Whole Document", key="reset_whole_btn", disabled=not confirm):
        _reset_whole_document()
        st.rerun()

    save_state_to_disk()


if __name__ == "__main__":
    main()
